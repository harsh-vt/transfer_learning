{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNczjUB/UZ7NTgAtOXLBC25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-vt/transfer_learning/blob/master/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAdVC-s1kkjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb5ZIr2Olgmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('training_data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56-6kkoHs02f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "444a35f5-344e-483b-d0d1-ba8de7af1aa4"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>AA</th>\n",
              "      <th>AB</th>\n",
              "      <th>AC</th>\n",
              "      <th>AD</th>\n",
              "      <th>AE</th>\n",
              "      <th>AF</th>\n",
              "      <th>AG</th>\n",
              "      <th>AH</th>\n",
              "      <th>AI</th>\n",
              "      <th>AK</th>\n",
              "      <th>AL</th>\n",
              "      <th>AM</th>\n",
              "      <th>AN</th>\n",
              "      <th>AO</th>\n",
              "      <th>AP</th>\n",
              "      <th>AQ</th>\n",
              "      <th>AR</th>\n",
              "      <th>AS</th>\n",
              "      <th>AT</th>\n",
              "      <th>AU</th>\n",
              "      <th>...</th>\n",
              "      <th>BD</th>\n",
              "      <th>BE</th>\n",
              "      <th>BF</th>\n",
              "      <th>BG</th>\n",
              "      <th>BH</th>\n",
              "      <th>BI</th>\n",
              "      <th>BJ</th>\n",
              "      <th>BK</th>\n",
              "      <th>BL</th>\n",
              "      <th>BM</th>\n",
              "      <th>BN</th>\n",
              "      <th>BO</th>\n",
              "      <th>BP</th>\n",
              "      <th>BQ</th>\n",
              "      <th>BR</th>\n",
              "      <th>BS</th>\n",
              "      <th>BT</th>\n",
              "      <th>BU</th>\n",
              "      <th>BV</th>\n",
              "      <th>BW</th>\n",
              "      <th>BX</th>\n",
              "      <th>BY</th>\n",
              "      <th>BZ</th>\n",
              "      <th>CA</th>\n",
              "      <th>CB</th>\n",
              "      <th>CC</th>\n",
              "      <th>CD</th>\n",
              "      <th>CE</th>\n",
              "      <th>CF</th>\n",
              "      <th>CG</th>\n",
              "      <th>CH</th>\n",
              "      <th>CI</th>\n",
              "      <th>CJ</th>\n",
              "      <th>CK</th>\n",
              "      <th>CL</th>\n",
              "      <th>CM</th>\n",
              "      <th>CN</th>\n",
              "      <th>CO</th>\n",
              "      <th>CP</th>\n",
              "      <th>CQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>305</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 88 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   A  B  C  D  E  F  G  H  I  J  ...  CH  CI  CJ   CK   CL  CM  CN  CO   CP  CQ\n",
              "0  0  1  0  0  0  0  1  0  0  0  ...   0   0   0  420  0.0   7  35   0  200   1\n",
              "1  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   40  0.0  11   5   0   20   1\n",
              "2  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   40  0.0  12   5   0  305   1\n",
              "3  0  1  0  0  0  0  1  0  0  0  ...   0   0   0  420  0.0  17  35   0  110   1\n",
              "4  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   85  0.0  19  20   0   75   5\n",
              "\n",
              "[5 rows x 88 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGw4qcSulrIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDE4zEpTmN9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xy = np.array(train_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axabB0RwmUYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "bc50a91f-6ccd-4170-f42a-5574cc3af111"
      },
      "source": [
        "print(xy)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.   1.   0. ...   0. 200.   1.]\n",
            " [  0.   1.   0. ...   0.  20.   1.]\n",
            " [  0.   1.   0. ...   0. 305.   1.]\n",
            " ...\n",
            " [  1.   0.   0. ...   0.  13.   4.]\n",
            " [  1.   0.   0. ...   0.   0.   4.]\n",
            " [  0.   0.   1. ...   0.   0.   2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi_lCYjGmmxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(xy)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cJczYnVnAna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "cc4b1488-f436-4db7-c35a-8edd4b286138"
      },
      "source": [
        "y = xy[:, -1:]\n",
        "x = xy[:, 0:-1]\n",
        "print(y)\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.]\n",
            " [2.]\n",
            " [4.]\n",
            " ...\n",
            " [4.]\n",
            " [4.]\n",
            " [5.]]\n",
            "[[  0.   0.   1. ...  20.   0. 505.]\n",
            " [  0.   0.   1. ...  14.   0.   0.]\n",
            " [  0.   0.   1. ...   9.   0.   0.]\n",
            " ...\n",
            " [  0.   0.   1. ...   5.   0.  10.]\n",
            " [  0.   0.   1. ...   5.   0.  25.]\n",
            " [  0.   0.   1. ...  10.   0.   0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKJHyyUcNuk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=x/x.max(axis=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGNOKtuKjGtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66c16168-61f4-4fb2-e52e-e0e077ea1135"
      },
      "source": [
        "x.shape "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3668, 87)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu8i1uLNRjmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training data split - 70& for training, 10% for validation, 20% for testing\n",
        "k = 2568\n",
        "l = 367\n",
        "x_train = x[0:k,:]\n",
        "y_train = y[0:k,:]\n",
        "x_val = x[k:k+l,:]\n",
        "y_val = y[k:k+l,:]\n",
        "x_test = x[k+l:,:]\n",
        "y_test = y[k+l:,:] "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRnk5wJvSZ6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1c081de0-7123-4bdb-bbf1-a206b2878dd9"
      },
      "source": [
        "print(x_train.shape)\n",
        "# print(x_train)\n",
        "print()\n",
        "print(y_train.shape)\n",
        "# print(y_train)\n",
        "print()\n",
        "print(x_val.shape)\n",
        "# print(x_val)\n",
        "print()\n",
        "print(y_val.shape)\n",
        "# print(y_val)\n",
        "print()\n",
        "print(x_test.shape)\n",
        "# print(x_test)\n",
        "print()\n",
        "print(y_test.shape)\n",
        "# print(y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2568, 87)\n",
            "\n",
            "(2568, 1)\n",
            "\n",
            "(367, 87)\n",
            "\n",
            "(367, 1)\n",
            "\n",
            "(733, 87)\n",
            "\n",
            "(733, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aYidakSVWzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_model():\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(87, input_dim=input_shape, activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(124, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(7,activation='softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Pl7cxMHH-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de28b1cd-a708-4844-8806-278f7ce95a7e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "input_shape = x_train.shape[1]\n",
        "\n",
        "model = baseline_model()\n",
        "\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "hist = model.fit(x_train, y_train, epochs=200,  validation_data=(x_val, y_val), callbacks=[cp_callback])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.show\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.legend([\"val_loss\", \"loss\"], loc =\"best\") \n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.show\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.legend([\"accuracy\", \"val_accuracy\"], loc =\"best\") \n",
        "plt.show()\n",
        "print(input_shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 2.1618 - accuracy: 0.2216\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 2.1485 - accuracy: 0.2239 - val_loss: 1.7685 - val_accuracy: 0.3515\n",
            "Epoch 2/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.7253 - accuracy: 0.3707\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.7253 - accuracy: 0.3707 - val_loss: 1.6348 - val_accuracy: 0.2970\n",
            "Epoch 3/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 1.5909 - accuracy: 0.4021\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.5894 - accuracy: 0.4019 - val_loss: 1.6263 - val_accuracy: 0.3106\n",
            "Epoch 4/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 1.4494 - accuracy: 0.4308\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.4518 - accuracy: 0.4319 - val_loss: 1.5475 - val_accuracy: 0.3379\n",
            "Epoch 5/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 1.4129 - accuracy: 0.4383\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.4127 - accuracy: 0.4377 - val_loss: 1.4429 - val_accuracy: 0.3869\n",
            "Epoch 6/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 1.3374 - accuracy: 0.4523\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.3365 - accuracy: 0.4533 - val_loss: 1.3709 - val_accuracy: 0.4251\n",
            "Epoch 7/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 1.3110 - accuracy: 0.4755\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.3134 - accuracy: 0.4727 - val_loss: 1.3165 - val_accuracy: 0.4687\n",
            "Epoch 8/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 1.2746 - accuracy: 0.4909\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.2741 - accuracy: 0.4922 - val_loss: 1.2703 - val_accuracy: 0.4877\n",
            "Epoch 9/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 1.2549 - accuracy: 0.5024\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.2600 - accuracy: 0.4992 - val_loss: 1.2511 - val_accuracy: 0.4823\n",
            "Epoch 10/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 1.2461 - accuracy: 0.4818\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.2461 - accuracy: 0.4844 - val_loss: 1.2213 - val_accuracy: 0.4986\n",
            "Epoch 11/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 1.2230 - accuracy: 0.5017\n",
            "Epoch 00011: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.2289 - accuracy: 0.4961 - val_loss: 1.2339 - val_accuracy: 0.4850\n",
            "Epoch 12/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 1.1996 - accuracy: 0.5095\n",
            "Epoch 00012: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.1964 - accuracy: 0.5105 - val_loss: 1.1989 - val_accuracy: 0.5068\n",
            "Epoch 13/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 1.1694 - accuracy: 0.5115\n",
            "Epoch 00013: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.1708 - accuracy: 0.5125 - val_loss: 1.1541 - val_accuracy: 0.5232\n",
            "Epoch 14/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 1.1630 - accuracy: 0.5246\n",
            "Epoch 00014: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1612 - accuracy: 0.5249 - val_loss: 1.1643 - val_accuracy: 0.5204\n",
            "Epoch 15/200\n",
            "64/81 [======================>.......] - ETA: 0s - loss: 1.1257 - accuracy: 0.5356\n",
            "Epoch 00015: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1346 - accuracy: 0.5378 - val_loss: 1.1220 - val_accuracy: 0.5613\n",
            "Epoch 16/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 1.1498 - accuracy: 0.5267\n",
            "Epoch 00016: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1395 - accuracy: 0.5319 - val_loss: 1.1161 - val_accuracy: 0.5368\n",
            "Epoch 17/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1191 - accuracy: 0.5491\n",
            "Epoch 00017: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.1191 - accuracy: 0.5491 - val_loss: 1.1107 - val_accuracy: 0.5668\n",
            "Epoch 18/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 1.1098 - accuracy: 0.5473\n",
            "Epoch 00018: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1093 - accuracy: 0.5475 - val_loss: 1.1009 - val_accuracy: 0.5586\n",
            "Epoch 19/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 1.1122 - accuracy: 0.5398\n",
            "Epoch 00019: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1141 - accuracy: 0.5382 - val_loss: 1.1161 - val_accuracy: 0.5477\n",
            "Epoch 20/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 1.1004 - accuracy: 0.5509\n",
            "Epoch 00020: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0992 - accuracy: 0.5487 - val_loss: 1.0907 - val_accuracy: 0.5695\n",
            "Epoch 21/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 1.0571 - accuracy: 0.5745\n",
            "Epoch 00021: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.0565 - accuracy: 0.5744 - val_loss: 1.0906 - val_accuracy: 0.5804\n",
            "Epoch 22/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 1.0674 - accuracy: 0.5625\n",
            "Epoch 00022: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0617 - accuracy: 0.5615 - val_loss: 1.0668 - val_accuracy: 0.5886\n",
            "Epoch 23/200\n",
            "61/81 [=====================>........] - ETA: 0s - loss: 1.0836 - accuracy: 0.5569\n",
            "Epoch 00023: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0817 - accuracy: 0.5611 - val_loss: 1.1000 - val_accuracy: 0.5477\n",
            "Epoch 24/200\n",
            "62/81 [=====================>........] - ETA: 0s - loss: 1.0417 - accuracy: 0.5716\n",
            "Epoch 00024: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0395 - accuracy: 0.5717 - val_loss: 1.0891 - val_accuracy: 0.5422\n",
            "Epoch 25/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 1.0407 - accuracy: 0.5791\n",
            "Epoch 00025: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0411 - accuracy: 0.5790 - val_loss: 1.0714 - val_accuracy: 0.5640\n",
            "Epoch 26/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 1.0332 - accuracy: 0.5757\n",
            "Epoch 00026: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.0381 - accuracy: 0.5720 - val_loss: 1.0976 - val_accuracy: 0.5504\n",
            "Epoch 27/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 1.0057 - accuracy: 0.5878\n",
            "Epoch 00027: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0068 - accuracy: 0.5872 - val_loss: 1.0627 - val_accuracy: 0.6022\n",
            "Epoch 28/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 1.0096 - accuracy: 0.5913\n",
            "Epoch 00028: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0122 - accuracy: 0.5900 - val_loss: 1.0471 - val_accuracy: 0.5940\n",
            "Epoch 29/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 1.0094 - accuracy: 0.5897\n",
            "Epoch 00029: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.5942 - val_loss: 1.0531 - val_accuracy: 0.5722\n",
            "Epoch 30/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 1.0073 - accuracy: 0.5848\n",
            "Epoch 00030: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 1.0104 - accuracy: 0.5818 - val_loss: 1.0617 - val_accuracy: 0.5777\n",
            "Epoch 31/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.9791 - accuracy: 0.6060\n",
            "Epoch 00031: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.9779 - accuracy: 0.6067 - val_loss: 1.0428 - val_accuracy: 0.5940\n",
            "Epoch 32/200\n",
            "55/81 [===================>..........] - ETA: 0s - loss: 0.9990 - accuracy: 0.5960\n",
            "Epoch 00032: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.9916 - accuracy: 0.5985 - val_loss: 1.0572 - val_accuracy: 0.5858\n",
            "Epoch 33/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.9617 - accuracy: 0.6058\n",
            "Epoch 00033: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9637 - accuracy: 0.6055 - val_loss: 1.0522 - val_accuracy: 0.5831\n",
            "Epoch 34/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.9479 - accuracy: 0.6070\n",
            "Epoch 00034: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9537 - accuracy: 0.6051 - val_loss: 1.0520 - val_accuracy: 0.5777\n",
            "Epoch 35/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.9353 - accuracy: 0.6340\n",
            "Epoch 00035: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9362 - accuracy: 0.6328 - val_loss: 0.9951 - val_accuracy: 0.6076\n",
            "Epoch 36/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.9401 - accuracy: 0.6266\n",
            "Epoch 00036: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.6242 - val_loss: 1.0218 - val_accuracy: 0.6022\n",
            "Epoch 37/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.9521 - accuracy: 0.6184\n",
            "Epoch 00037: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.9521 - accuracy: 0.6168 - val_loss: 1.0160 - val_accuracy: 0.6158\n",
            "Epoch 38/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.9142 - accuracy: 0.6268\n",
            "Epoch 00038: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9214 - accuracy: 0.6207 - val_loss: 1.0121 - val_accuracy: 0.6185\n",
            "Epoch 39/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.9101 - accuracy: 0.6300\n",
            "Epoch 00039: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9096 - accuracy: 0.6340 - val_loss: 1.0157 - val_accuracy: 0.6022\n",
            "Epoch 40/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.8797 - accuracy: 0.6446\n",
            "Epoch 00040: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8875 - accuracy: 0.6437 - val_loss: 1.0138 - val_accuracy: 0.6158\n",
            "Epoch 41/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.8685 - accuracy: 0.6530\n",
            "Epoch 00041: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.8694 - accuracy: 0.6515 - val_loss: 0.9906 - val_accuracy: 0.6322\n",
            "Epoch 42/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.8827 - accuracy: 0.6357\n",
            "Epoch 00042: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8846 - accuracy: 0.6316 - val_loss: 1.0176 - val_accuracy: 0.6104\n",
            "Epoch 43/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.8715 - accuracy: 0.6480\n",
            "Epoch 00043: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8691 - accuracy: 0.6464 - val_loss: 1.0045 - val_accuracy: 0.6049\n",
            "Epoch 44/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.8449 - accuracy: 0.6579\n",
            "Epoch 00044: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8419 - accuracy: 0.6604 - val_loss: 0.9944 - val_accuracy: 0.6049\n",
            "Epoch 45/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.8563 - accuracy: 0.6555\n",
            "Epoch 00045: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.8558 - accuracy: 0.6558 - val_loss: 0.9979 - val_accuracy: 0.6322\n",
            "Epoch 46/200\n",
            "66/81 [=======================>......] - ETA: 0s - loss: 0.8487 - accuracy: 0.6596\n",
            "Epoch 00046: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8417 - accuracy: 0.6659 - val_loss: 0.9945 - val_accuracy: 0.6349\n",
            "Epoch 47/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.8441 - accuracy: 0.6581\n",
            "Epoch 00047: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8423 - accuracy: 0.6628 - val_loss: 0.9809 - val_accuracy: 0.6267\n",
            "Epoch 48/200\n",
            "62/81 [=====================>........] - ETA: 0s - loss: 0.8227 - accuracy: 0.6754\n",
            "Epoch 00048: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8305 - accuracy: 0.6710 - val_loss: 0.9627 - val_accuracy: 0.6349\n",
            "Epoch 49/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.8294 - accuracy: 0.6615\n",
            "Epoch 00049: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8384 - accuracy: 0.6577 - val_loss: 0.9475 - val_accuracy: 0.6403\n",
            "Epoch 50/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.7987 - accuracy: 0.6769\n",
            "Epoch 00050: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8060 - accuracy: 0.6776 - val_loss: 0.9467 - val_accuracy: 0.6294\n",
            "Epoch 51/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.8131 - accuracy: 0.6859\n",
            "Epoch 00051: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.6865 - val_loss: 0.9396 - val_accuracy: 0.6540\n",
            "Epoch 52/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.7929 - accuracy: 0.6772\n",
            "Epoch 00052: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7983 - accuracy: 0.6752 - val_loss: 0.9307 - val_accuracy: 0.6594\n",
            "Epoch 53/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.7914 - accuracy: 0.6839\n",
            "Epoch 00053: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.7901 - accuracy: 0.6830 - val_loss: 0.9641 - val_accuracy: 0.6567\n",
            "Epoch 54/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.7927 - accuracy: 0.6813\n",
            "Epoch 00054: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7904 - accuracy: 0.6822 - val_loss: 0.9705 - val_accuracy: 0.6376\n",
            "Epoch 55/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.7751 - accuracy: 0.6919\n",
            "Epoch 00055: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.7765 - accuracy: 0.6908 - val_loss: 0.9707 - val_accuracy: 0.6322\n",
            "Epoch 56/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.7742 - accuracy: 0.6930\n",
            "Epoch 00056: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.7719 - accuracy: 0.6939 - val_loss: 0.9580 - val_accuracy: 0.6431\n",
            "Epoch 57/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.7785 - accuracy: 0.6850\n",
            "Epoch 00057: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7766 - accuracy: 0.6869 - val_loss: 0.9475 - val_accuracy: 0.6403\n",
            "Epoch 58/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.7640 - accuracy: 0.7083\n",
            "Epoch 00058: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7620 - accuracy: 0.7079 - val_loss: 0.9116 - val_accuracy: 0.6540\n",
            "Epoch 59/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.7259 - accuracy: 0.7155\n",
            "Epoch 00059: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.7142 - val_loss: 0.9286 - val_accuracy: 0.6621\n",
            "Epoch 60/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.7468 - accuracy: 0.6953\n",
            "Epoch 00060: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.6974 - val_loss: 0.9417 - val_accuracy: 0.6621\n",
            "Epoch 61/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.7140 - accuracy: 0.7252\n",
            "Epoch 00061: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.7231 - val_loss: 0.9047 - val_accuracy: 0.6485\n",
            "Epoch 62/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.7004 - accuracy: 0.7229\n",
            "Epoch 00062: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.7231 - val_loss: 0.9339 - val_accuracy: 0.6567\n",
            "Epoch 63/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.7184 - accuracy: 0.7175\n",
            "Epoch 00063: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.7204 - val_loss: 0.9279 - val_accuracy: 0.6431\n",
            "Epoch 64/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.6677 - accuracy: 0.7500\n",
            "Epoch 00064: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.7496 - val_loss: 0.9210 - val_accuracy: 0.6676\n",
            "Epoch 65/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.6786 - accuracy: 0.7266\n",
            "Epoch 00065: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7239 - val_loss: 0.8915 - val_accuracy: 0.6785\n",
            "Epoch 66/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.6988 - accuracy: 0.7265\n",
            "Epoch 00066: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.7270 - val_loss: 0.9046 - val_accuracy: 0.6921\n",
            "Epoch 67/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.6968 - accuracy: 0.7215\n",
            "Epoch 00067: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.7247 - val_loss: 0.9123 - val_accuracy: 0.6703\n",
            "Epoch 68/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.6909 - accuracy: 0.7289\n",
            "Epoch 00068: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.7321 - val_loss: 0.9011 - val_accuracy: 0.6757\n",
            "Epoch 69/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.6845 - accuracy: 0.7312\n",
            "Epoch 00069: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7305 - val_loss: 0.9042 - val_accuracy: 0.6812\n",
            "Epoch 70/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.6622 - accuracy: 0.7348\n",
            "Epoch 00070: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.7383 - val_loss: 0.8928 - val_accuracy: 0.6594\n",
            "Epoch 71/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.6612 - accuracy: 0.7332\n",
            "Epoch 00071: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.7301 - val_loss: 0.8746 - val_accuracy: 0.6812\n",
            "Epoch 72/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.6756 - accuracy: 0.7418\n",
            "Epoch 00072: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.7407 - val_loss: 0.9034 - val_accuracy: 0.6785\n",
            "Epoch 73/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.6455 - accuracy: 0.7521\n",
            "Epoch 00073: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.7496 - val_loss: 0.8821 - val_accuracy: 0.6676\n",
            "Epoch 74/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.6330 - accuracy: 0.7451\n",
            "Epoch 00074: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.7391 - val_loss: 0.8670 - val_accuracy: 0.6894\n",
            "Epoch 75/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.6431 - accuracy: 0.7505\n",
            "Epoch 00075: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.7465 - val_loss: 0.8716 - val_accuracy: 0.6975\n",
            "Epoch 76/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.6182 - accuracy: 0.7448\n",
            "Epoch 00076: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7438 - val_loss: 0.8851 - val_accuracy: 0.6921\n",
            "Epoch 77/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.6138 - accuracy: 0.7541\n",
            "Epoch 00077: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.7555 - val_loss: 0.8970 - val_accuracy: 0.6866\n",
            "Epoch 78/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.6260 - accuracy: 0.7546\n",
            "Epoch 00078: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.7570 - val_loss: 0.9108 - val_accuracy: 0.6839\n",
            "Epoch 79/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.6097 - accuracy: 0.7586\n",
            "Epoch 00079: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7551 - val_loss: 0.8938 - val_accuracy: 0.6866\n",
            "Epoch 80/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.6180 - accuracy: 0.7554\n",
            "Epoch 00080: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.7539 - val_loss: 0.8638 - val_accuracy: 0.6975\n",
            "Epoch 81/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.6133 - accuracy: 0.7587\n",
            "Epoch 00081: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.7562 - val_loss: 0.8944 - val_accuracy: 0.6812\n",
            "Epoch 82/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.6155 - accuracy: 0.7638\n",
            "Epoch 00082: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.7605 - val_loss: 0.8940 - val_accuracy: 0.6839\n",
            "Epoch 83/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.5744 - accuracy: 0.7803\n",
            "Epoch 00083: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7780 - val_loss: 0.8961 - val_accuracy: 0.6894\n",
            "Epoch 84/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.5917 - accuracy: 0.7646\n",
            "Epoch 00084: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7640 - val_loss: 0.8834 - val_accuracy: 0.6812\n",
            "Epoch 85/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.5550 - accuracy: 0.7817\n",
            "Epoch 00085: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7835 - val_loss: 0.8818 - val_accuracy: 0.7030\n",
            "Epoch 86/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5807 - accuracy: 0.7656\n",
            "Epoch 00086: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7667 - val_loss: 0.8559 - val_accuracy: 0.6948\n",
            "Epoch 87/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.5739 - accuracy: 0.7808\n",
            "Epoch 00087: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7749 - val_loss: 0.8755 - val_accuracy: 0.7084\n",
            "Epoch 88/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5704 - accuracy: 0.7817\n",
            "Epoch 00088: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7769 - val_loss: 0.8913 - val_accuracy: 0.7057\n",
            "Epoch 89/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.5662 - accuracy: 0.7794\n",
            "Epoch 00089: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7819 - val_loss: 0.8801 - val_accuracy: 0.7112\n",
            "Epoch 90/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5651 - accuracy: 0.7843\n",
            "Epoch 00090: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7831 - val_loss: 0.8859 - val_accuracy: 0.7057\n",
            "Epoch 91/200\n",
            "66/81 [=======================>......] - ETA: 0s - loss: 0.5532 - accuracy: 0.7860\n",
            "Epoch 00091: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7886 - val_loss: 0.8894 - val_accuracy: 0.7139\n",
            "Epoch 92/200\n",
            "64/81 [======================>.......] - ETA: 0s - loss: 0.5715 - accuracy: 0.7871\n",
            "Epoch 00092: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7889 - val_loss: 0.8818 - val_accuracy: 0.7166\n",
            "Epoch 93/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5461 - accuracy: 0.7901\n",
            "Epoch 00093: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7878 - val_loss: 0.9095 - val_accuracy: 0.7057\n",
            "Epoch 94/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5362 - accuracy: 0.7956\n",
            "Epoch 00094: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7917 - val_loss: 0.8798 - val_accuracy: 0.7084\n",
            "Epoch 95/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.5214 - accuracy: 0.7962\n",
            "Epoch 00095: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7987 - val_loss: 0.9149 - val_accuracy: 0.7193\n",
            "Epoch 96/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.5407 - accuracy: 0.7892\n",
            "Epoch 00096: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7862 - val_loss: 0.8906 - val_accuracy: 0.7248\n",
            "Epoch 97/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.5455 - accuracy: 0.7939\n",
            "Epoch 00097: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7913 - val_loss: 0.9254 - val_accuracy: 0.6948\n",
            "Epoch 98/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.5480 - accuracy: 0.7901\n",
            "Epoch 00098: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7882 - val_loss: 0.8916 - val_accuracy: 0.7193\n",
            "Epoch 99/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.5342 - accuracy: 0.7853\n",
            "Epoch 00099: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7858 - val_loss: 0.8928 - val_accuracy: 0.7112\n",
            "Epoch 100/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5034 - accuracy: 0.8150\n",
            "Epoch 00100: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8127 - val_loss: 0.9012 - val_accuracy: 0.7084\n",
            "Epoch 101/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.5332 - accuracy: 0.7971\n",
            "Epoch 00101: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.8006 - val_loss: 0.9086 - val_accuracy: 0.7139\n",
            "Epoch 102/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.5178 - accuracy: 0.8006\n",
            "Epoch 00102: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.8030 - val_loss: 0.9143 - val_accuracy: 0.7302\n",
            "Epoch 103/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5257 - accuracy: 0.7960\n",
            "Epoch 00103: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7960 - val_loss: 0.9120 - val_accuracy: 0.7084\n",
            "Epoch 104/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5015 - accuracy: 0.8038\n",
            "Epoch 00104: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8002 - val_loss: 0.9260 - val_accuracy: 0.7193\n",
            "Epoch 105/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5021 - accuracy: 0.8062\n",
            "Epoch 00105: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8037 - val_loss: 0.9307 - val_accuracy: 0.7084\n",
            "Epoch 106/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.4921 - accuracy: 0.8116\n",
            "Epoch 00106: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8096 - val_loss: 0.9146 - val_accuracy: 0.7166\n",
            "Epoch 107/200\n",
            "66/81 [=======================>......] - ETA: 0s - loss: 0.4853 - accuracy: 0.8111\n",
            "Epoch 00107: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.8076 - val_loss: 0.9363 - val_accuracy: 0.7112\n",
            "Epoch 108/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.4785 - accuracy: 0.8099\n",
            "Epoch 00108: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8080 - val_loss: 0.9000 - val_accuracy: 0.7057\n",
            "Epoch 109/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.4751 - accuracy: 0.8112\n",
            "Epoch 00109: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8061 - val_loss: 0.9087 - val_accuracy: 0.7330\n",
            "Epoch 110/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.4899 - accuracy: 0.8142\n",
            "Epoch 00110: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8139 - val_loss: 0.9028 - val_accuracy: 0.7139\n",
            "Epoch 111/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.4698 - accuracy: 0.8201\n",
            "Epoch 00111: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8185 - val_loss: 0.9294 - val_accuracy: 0.7221\n",
            "Epoch 112/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.4923 - accuracy: 0.8056\n",
            "Epoch 00112: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8045 - val_loss: 0.8962 - val_accuracy: 0.7411\n",
            "Epoch 113/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.4816 - accuracy: 0.8129\n",
            "Epoch 00113: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8135 - val_loss: 0.9129 - val_accuracy: 0.7302\n",
            "Epoch 114/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4858 - accuracy: 0.8149\n",
            "Epoch 00114: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.8146 - val_loss: 0.8774 - val_accuracy: 0.7439\n",
            "Epoch 115/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.4814 - accuracy: 0.8109\n",
            "Epoch 00115: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.8115 - val_loss: 0.9100 - val_accuracy: 0.7384\n",
            "Epoch 116/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.4624 - accuracy: 0.8201\n",
            "Epoch 00116: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.8193 - val_loss: 0.8842 - val_accuracy: 0.7357\n",
            "Epoch 117/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.4944 - accuracy: 0.8051\n",
            "Epoch 00117: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8045 - val_loss: 0.8745 - val_accuracy: 0.7520\n",
            "Epoch 118/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.4593 - accuracy: 0.8242\n",
            "Epoch 00118: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8193 - val_loss: 0.8492 - val_accuracy: 0.7548\n",
            "Epoch 119/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.4398 - accuracy: 0.8336\n",
            "Epoch 00119: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8337 - val_loss: 0.8932 - val_accuracy: 0.7411\n",
            "Epoch 120/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.4474 - accuracy: 0.8222\n",
            "Epoch 00120: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8193 - val_loss: 0.8831 - val_accuracy: 0.7330\n",
            "Epoch 121/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4441 - accuracy: 0.8350\n",
            "Epoch 00121: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8333 - val_loss: 0.8767 - val_accuracy: 0.7384\n",
            "Epoch 122/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.4635 - accuracy: 0.8174\n",
            "Epoch 00122: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8166 - val_loss: 0.9082 - val_accuracy: 0.7221\n",
            "Epoch 123/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4633 - accuracy: 0.8180\n",
            "Epoch 00123: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8185 - val_loss: 0.8980 - val_accuracy: 0.7275\n",
            "Epoch 124/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4502 - accuracy: 0.8228\n",
            "Epoch 00124: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8232 - val_loss: 0.9020 - val_accuracy: 0.7384\n",
            "Epoch 125/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.4230 - accuracy: 0.8421\n",
            "Epoch 00125: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8407 - val_loss: 0.9096 - val_accuracy: 0.7330\n",
            "Epoch 126/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8344\n",
            "Epoch 00126: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8341 - val_loss: 0.9137 - val_accuracy: 0.7330\n",
            "Epoch 127/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.4526 - accuracy: 0.8237\n",
            "Epoch 00127: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8259 - val_loss: 0.9090 - val_accuracy: 0.7275\n",
            "Epoch 128/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4059 - accuracy: 0.8418\n",
            "Epoch 00128: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8407 - val_loss: 0.9234 - val_accuracy: 0.7248\n",
            "Epoch 129/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.4205 - accuracy: 0.8395\n",
            "Epoch 00129: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8407 - val_loss: 0.8927 - val_accuracy: 0.7520\n",
            "Epoch 130/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.4508 - accuracy: 0.8217\n",
            "Epoch 00130: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.8217 - val_loss: 0.9258 - val_accuracy: 0.7466\n",
            "Epoch 131/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.4409 - accuracy: 0.8313\n",
            "Epoch 00131: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8294 - val_loss: 0.9002 - val_accuracy: 0.7302\n",
            "Epoch 132/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.4164 - accuracy: 0.8307\n",
            "Epoch 00132: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8290 - val_loss: 0.9021 - val_accuracy: 0.7357\n",
            "Epoch 133/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.4170 - accuracy: 0.8460\n",
            "Epoch 00133: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8415 - val_loss: 0.9206 - val_accuracy: 0.7193\n",
            "Epoch 134/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.4019 - accuracy: 0.8481\n",
            "Epoch 00134: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8435 - val_loss: 0.9216 - val_accuracy: 0.7330\n",
            "Epoch 135/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3950 - accuracy: 0.8400\n",
            "Epoch 00135: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8407 - val_loss: 0.9477 - val_accuracy: 0.7302\n",
            "Epoch 136/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.3989 - accuracy: 0.8506\n",
            "Epoch 00136: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8462 - val_loss: 0.9188 - val_accuracy: 0.7384\n",
            "Epoch 137/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.3784 - accuracy: 0.8516\n",
            "Epoch 00137: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8477 - val_loss: 0.9294 - val_accuracy: 0.7548\n",
            "Epoch 138/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.4181 - accuracy: 0.8428\n",
            "Epoch 00138: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8423 - val_loss: 0.9456 - val_accuracy: 0.7221\n",
            "Epoch 139/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.4057 - accuracy: 0.8393\n",
            "Epoch 00139: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8419 - val_loss: 0.9330 - val_accuracy: 0.7330\n",
            "Epoch 140/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8540\n",
            "Epoch 00140: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8544 - val_loss: 0.9457 - val_accuracy: 0.7411\n",
            "Epoch 141/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4111 - accuracy: 0.8422\n",
            "Epoch 00141: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8415 - val_loss: 0.9662 - val_accuracy: 0.7330\n",
            "Epoch 142/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.4023 - accuracy: 0.8385\n",
            "Epoch 00142: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8388 - val_loss: 0.9483 - val_accuracy: 0.7411\n",
            "Epoch 143/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8441\n",
            "Epoch 00143: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8435 - val_loss: 0.9590 - val_accuracy: 0.7384\n",
            "Epoch 144/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.4045 - accuracy: 0.8369\n",
            "Epoch 00144: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8376 - val_loss: 0.9577 - val_accuracy: 0.7357\n",
            "Epoch 145/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.8370\n",
            "Epoch 00145: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8345 - val_loss: 0.9429 - val_accuracy: 0.7439\n",
            "Epoch 146/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3839 - accuracy: 0.8502\n",
            "Epoch 00146: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8493 - val_loss: 0.9279 - val_accuracy: 0.7548\n",
            "Epoch 147/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3955 - accuracy: 0.8518\n",
            "Epoch 00147: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8524 - val_loss: 0.9345 - val_accuracy: 0.7548\n",
            "Epoch 148/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8544\n",
            "Epoch 00148: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8520 - val_loss: 0.9452 - val_accuracy: 0.7520\n",
            "Epoch 149/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3882 - accuracy: 0.8532\n",
            "Epoch 00149: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8544 - val_loss: 0.9409 - val_accuracy: 0.7684\n",
            "Epoch 150/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.4046 - accuracy: 0.8438\n",
            "Epoch 00150: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8454 - val_loss: 0.9366 - val_accuracy: 0.7602\n",
            "Epoch 151/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3779 - accuracy: 0.8525\n",
            "Epoch 00151: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8516 - val_loss: 0.9467 - val_accuracy: 0.7520\n",
            "Epoch 152/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3868 - accuracy: 0.8539\n",
            "Epoch 00152: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8544 - val_loss: 0.9274 - val_accuracy: 0.7466\n",
            "Epoch 153/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8548\n",
            "Epoch 00153: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8548 - val_loss: 0.9627 - val_accuracy: 0.7548\n",
            "Epoch 154/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3768 - accuracy: 0.8577\n",
            "Epoch 00154: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8548 - val_loss: 0.9502 - val_accuracy: 0.7439\n",
            "Epoch 155/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3590 - accuracy: 0.8683\n",
            "Epoch 00155: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8664 - val_loss: 0.9677 - val_accuracy: 0.7439\n",
            "Epoch 156/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3687 - accuracy: 0.8588\n",
            "Epoch 00156: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8606 - val_loss: 0.9528 - val_accuracy: 0.7357\n",
            "Epoch 157/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.4205 - accuracy: 0.8372\n",
            "Epoch 00157: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8396 - val_loss: 0.9455 - val_accuracy: 0.7493\n",
            "Epoch 158/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3632 - accuracy: 0.8619\n",
            "Epoch 00158: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8610 - val_loss: 0.9674 - val_accuracy: 0.7575\n",
            "Epoch 159/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.3678 - accuracy: 0.8607\n",
            "Epoch 00159: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8606 - val_loss: 0.9545 - val_accuracy: 0.7493\n",
            "Epoch 160/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3865 - accuracy: 0.8482\n",
            "Epoch 00160: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8481 - val_loss: 0.9338 - val_accuracy: 0.7657\n",
            "Epoch 161/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.3854 - accuracy: 0.8493\n",
            "Epoch 00161: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8497 - val_loss: 0.9404 - val_accuracy: 0.7738\n",
            "Epoch 162/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3509 - accuracy: 0.8560\n",
            "Epoch 00162: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8548 - val_loss: 0.9581 - val_accuracy: 0.7820\n",
            "Epoch 163/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3603 - accuracy: 0.8712\n",
            "Epoch 00163: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8715 - val_loss: 0.9650 - val_accuracy: 0.7602\n",
            "Epoch 164/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3670 - accuracy: 0.8635\n",
            "Epoch 00164: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8633 - val_loss: 0.9366 - val_accuracy: 0.7684\n",
            "Epoch 165/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.3320 - accuracy: 0.8723\n",
            "Epoch 00165: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8723 - val_loss: 0.9583 - val_accuracy: 0.7520\n",
            "Epoch 166/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3554 - accuracy: 0.8632\n",
            "Epoch 00166: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8621 - val_loss: 0.9730 - val_accuracy: 0.7657\n",
            "Epoch 167/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3729 - accuracy: 0.8502\n",
            "Epoch 00167: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8516 - val_loss: 0.9441 - val_accuracy: 0.7711\n",
            "Epoch 168/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.3567 - accuracy: 0.8609\n",
            "Epoch 00168: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8602 - val_loss: 0.9457 - val_accuracy: 0.7684\n",
            "Epoch 169/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.3670 - accuracy: 0.8603\n",
            "Epoch 00169: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8583 - val_loss: 0.9627 - val_accuracy: 0.7766\n",
            "Epoch 170/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8679\n",
            "Epoch 00170: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8680 - val_loss: 0.9731 - val_accuracy: 0.7602\n",
            "Epoch 171/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8649\n",
            "Epoch 00171: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8649 - val_loss: 0.9590 - val_accuracy: 0.7684\n",
            "Epoch 172/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3535 - accuracy: 0.8622\n",
            "Epoch 00172: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8614 - val_loss: 0.9454 - val_accuracy: 0.7793\n",
            "Epoch 173/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3533 - accuracy: 0.8661\n",
            "Epoch 00173: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8660 - val_loss: 0.9435 - val_accuracy: 0.7575\n",
            "Epoch 174/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3559 - accuracy: 0.8608\n",
            "Epoch 00174: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8610 - val_loss: 0.9757 - val_accuracy: 0.7520\n",
            "Epoch 175/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3505 - accuracy: 0.8766\n",
            "Epoch 00175: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8746 - val_loss: 0.9701 - val_accuracy: 0.7548\n",
            "Epoch 176/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3619 - accuracy: 0.8651\n",
            "Epoch 00176: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8653 - val_loss: 0.9635 - val_accuracy: 0.7629\n",
            "Epoch 177/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3212 - accuracy: 0.8779\n",
            "Epoch 00177: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8727 - val_loss: 0.9489 - val_accuracy: 0.7793\n",
            "Epoch 178/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8833\n",
            "Epoch 00178: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8816 - val_loss: 0.9780 - val_accuracy: 0.7657\n",
            "Epoch 179/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3704 - accuracy: 0.8604\n",
            "Epoch 00179: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8598 - val_loss: 0.9938 - val_accuracy: 0.7657\n",
            "Epoch 180/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3369 - accuracy: 0.8679\n",
            "Epoch 00180: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8676 - val_loss: 0.9658 - val_accuracy: 0.7657\n",
            "Epoch 181/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3219 - accuracy: 0.8823\n",
            "Epoch 00181: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8828 - val_loss: 0.9725 - val_accuracy: 0.7711\n",
            "Epoch 182/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.3246 - accuracy: 0.8773\n",
            "Epoch 00182: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8773 - val_loss: 0.9950 - val_accuracy: 0.7629\n",
            "Epoch 183/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.3363 - accuracy: 0.8797\n",
            "Epoch 00183: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8797 - val_loss: 1.0048 - val_accuracy: 0.7657\n",
            "Epoch 184/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3228 - accuracy: 0.8843\n",
            "Epoch 00184: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8832 - val_loss: 0.9772 - val_accuracy: 0.7738\n",
            "Epoch 185/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3364 - accuracy: 0.8746\n",
            "Epoch 00185: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8746 - val_loss: 0.9706 - val_accuracy: 0.7711\n",
            "Epoch 186/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3670 - accuracy: 0.8618\n",
            "Epoch 00186: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8625 - val_loss: 0.9515 - val_accuracy: 0.7684\n",
            "Epoch 187/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3413 - accuracy: 0.8767\n",
            "Epoch 00187: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8769 - val_loss: 0.9536 - val_accuracy: 0.7602\n",
            "Epoch 188/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3304 - accuracy: 0.8786\n",
            "Epoch 00188: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8793 - val_loss: 0.9586 - val_accuracy: 0.7575\n",
            "Epoch 189/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.8808\n",
            "Epoch 00189: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8808 - val_loss: 0.9700 - val_accuracy: 0.7684\n",
            "Epoch 190/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.2971 - accuracy: 0.8858\n",
            "Epoch 00190: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8851 - val_loss: 0.9593 - val_accuracy: 0.7684\n",
            "Epoch 191/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3231 - accuracy: 0.8825\n",
            "Epoch 00191: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8820 - val_loss: 0.9457 - val_accuracy: 0.7684\n",
            "Epoch 192/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3075 - accuracy: 0.8822\n",
            "Epoch 00192: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8840 - val_loss: 0.9698 - val_accuracy: 0.7548\n",
            "Epoch 193/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3218 - accuracy: 0.8754\n",
            "Epoch 00193: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8719 - val_loss: 0.9680 - val_accuracy: 0.7766\n",
            "Epoch 194/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3220 - accuracy: 0.8865\n",
            "Epoch 00194: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8851 - val_loss: 1.0118 - val_accuracy: 0.7548\n",
            "Epoch 195/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.3160 - accuracy: 0.8772\n",
            "Epoch 00195: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8762 - val_loss: 0.9756 - val_accuracy: 0.7684\n",
            "Epoch 196/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3221 - accuracy: 0.8786\n",
            "Epoch 00196: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8785 - val_loss: 0.9851 - val_accuracy: 0.7575\n",
            "Epoch 197/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3270 - accuracy: 0.8795\n",
            "Epoch 00197: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8793 - val_loss: 1.0060 - val_accuracy: 0.7629\n",
            "Epoch 198/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3224 - accuracy: 0.8771\n",
            "Epoch 00198: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8766 - val_loss: 1.0061 - val_accuracy: 0.7602\n",
            "Epoch 199/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3238 - accuracy: 0.8829\n",
            "Epoch 00199: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8836 - val_loss: 0.9886 - val_accuracy: 0.7657\n",
            "Epoch 200/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3411 - accuracy: 0.8680\n",
            "Epoch 00200: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8660 - val_loss: 0.9665 - val_accuracy: 0.7629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOZO8WoksN-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4642ef3-608c-43a8-abdd-a511114bfc16"
      },
      "source": [
        "testing_predicted = model.evaluate(x_test,y_test) "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 0s 1ms/step - loss: 1.1412 - accuracy: 0.7435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuUdDoAw7tW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b1a62e7a-ff91-4043-ee84-d446b8e277d3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 875       \n",
            "=================================================================\n",
            "Total params: 20,287\n",
            "Trainable params: 19,865\n",
            "Non-trainable params: 422\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku0AbAb-2aO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c436fce8-2b2b-48dc-c9d9-2640b51ea52c"
      },
      "source": [
        "export_path = os.path.abspath(os.getcwd())+'/models/saved_model'\n",
        "model.save(export_path, save_format='tf')\n",
        "export_path"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/models/saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/saved_model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqMI2xGRh2gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8c29d797-984b-4a88-9fc0-473b938d2a89"
      },
      "source": [
        "# testing data split - 30% from training, 70 % for testing\n",
        "test_data = pd.read_csv('testing_data.csv')\n",
        "ab = np.array(train_data)\n",
        "np.random.shuffle(ab)\n",
        "b = ab[:, -1:]\n",
        "a = ab[:, 0:-1]\n",
        "a = a/a.max(axis=0)\n",
        "\n",
        "k = 1100\n",
        "a_train = x[0:k,:]\n",
        "b_train = y[0:k,:]\n",
        "a_test = x[k:,:]\n",
        "b_test = y[k:,:] \n",
        "\n",
        "print(a_train.shape)\n",
        "# print(x_train)\n",
        "print()\n",
        "print(b_train.shape)\n",
        "# print(y_train)\n",
        "print()\n",
        "print(a_test.shape)\n",
        "# print(x_test)\n",
        "print()\n",
        "print(b_test.shape)\n",
        "# print(y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1100, 87)\n",
            "\n",
            "(1100, 1)\n",
            "\n",
            "(2568, 87)\n",
            "\n",
            "(2568, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2U7Ye147VpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "ffc28495-5482-4352-f5a9-2fda5594e507"
      },
      "source": [
        "import_path = os.path.abspath(os.getcwd())+'/models/saved_model'\n",
        "reloaded_model = tf.keras.models.load_model(import_path)\n",
        "reloaded_model.summary()\n",
        "reloaded_model.load_weights(checkpoint_path)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 875       \n",
            "=================================================================\n",
            "Total params: 20,287\n",
            "Trainable params: 19,865\n",
            "Non-trainable params: 422\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff7a7bf28d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6W0kh__TIGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "02531284-3e5f-4bfa-be75-9594a99af750"
      },
      "source": [
        "non_trainable_layers = len(reloaded_model.layers)-1\n",
        "for i in range(1,non_trainable_layers):\n",
        "  reloaded_model.layers[i].trainable = False\n",
        "reloaded_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 875       \n",
            "=================================================================\n",
            "Total params: 20,287\n",
            "Trainable params: 8,531\n",
            "Non-trainable params: 11,756\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT22E6FsT0rO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb59220c-b1e2-4143-c915-ca245b547909"
      },
      "source": [
        "reloaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "reloaded_model.fit(a_train, b_train, epochs=200, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9212\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.9076\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9130\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9193\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9174\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9155\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9220\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9185\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9261\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9226\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9204\n",
            "Epoch 12/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9207\n",
            "Epoch 13/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9248\n",
            "Epoch 14/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9179\n",
            "Epoch 15/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9201\n",
            "Epoch 16/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9223\n",
            "Epoch 17/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9218\n",
            "Epoch 18/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9283\n",
            "Epoch 19/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9269\n",
            "Epoch 20/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9275\n",
            "Epoch 21/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9245\n",
            "Epoch 22/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9250\n",
            "Epoch 23/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9253\n",
            "Epoch 24/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9174\n",
            "Epoch 25/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9294\n",
            "Epoch 26/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9308\n",
            "Epoch 27/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9308\n",
            "Epoch 28/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9278\n",
            "Epoch 29/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9234\n",
            "Epoch 30/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9288\n",
            "Epoch 31/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9253\n",
            "Epoch 32/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9278\n",
            "Epoch 33/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9294\n",
            "Epoch 34/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9215\n",
            "Epoch 35/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9245\n",
            "Epoch 36/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9256\n",
            "Epoch 37/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9288\n",
            "Epoch 38/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9291\n",
            "Epoch 39/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9327\n",
            "Epoch 40/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9294\n",
            "Epoch 41/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9310\n",
            "Epoch 42/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9291\n",
            "Epoch 43/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9335\n",
            "Epoch 44/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9286\n",
            "Epoch 45/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9348\n",
            "Epoch 46/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9327\n",
            "Epoch 47/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9220\n",
            "Epoch 48/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9272\n",
            "Epoch 49/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9261\n",
            "Epoch 50/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9305\n",
            "Epoch 51/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9318\n",
            "Epoch 52/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9288\n",
            "Epoch 53/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9272\n",
            "Epoch 54/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9256\n",
            "Epoch 55/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9297\n",
            "Epoch 56/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9250\n",
            "Epoch 57/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9286\n",
            "Epoch 58/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9340\n",
            "Epoch 59/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9269\n",
            "Epoch 60/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9357\n",
            "Epoch 61/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9278\n",
            "Epoch 62/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9310\n",
            "Epoch 63/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9286\n",
            "Epoch 64/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9324\n",
            "Epoch 65/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9327\n",
            "Epoch 66/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9291\n",
            "Epoch 67/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9411\n",
            "Epoch 68/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9283\n",
            "Epoch 69/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9348\n",
            "Epoch 70/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9299\n",
            "Epoch 71/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9373\n",
            "Epoch 72/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9346\n",
            "Epoch 73/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9384\n",
            "Epoch 74/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9357\n",
            "Epoch 75/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9387\n",
            "Epoch 76/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9340\n",
            "Epoch 77/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9302\n",
            "Epoch 78/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9324\n",
            "Epoch 79/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9368\n",
            "Epoch 80/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9378\n",
            "Epoch 81/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9324\n",
            "Epoch 82/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9357\n",
            "Epoch 83/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9351\n",
            "Epoch 84/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9318\n",
            "Epoch 85/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9318\n",
            "Epoch 86/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9348\n",
            "Epoch 87/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9340\n",
            "Epoch 88/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9321\n",
            "Epoch 89/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9288\n",
            "Epoch 90/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9392\n",
            "Epoch 91/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9376\n",
            "Epoch 92/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9305\n",
            "Epoch 93/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9354\n",
            "Epoch 94/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9373\n",
            "Epoch 95/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9430\n",
            "Epoch 96/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9335\n",
            "Epoch 97/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9376\n",
            "Epoch 98/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9332\n",
            "Epoch 99/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9359\n",
            "Epoch 100/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffa379b0c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgswjGCl74E0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3ed40383-35d9-41f7-98d6-f310ae4ea528"
      },
      "source": [
        "training_predicted = model.evaluate(a_test,b_test) \n",
        "print(\"testing_predicted: \", testing_predicted)\n",
        "print()\n",
        "print(\"training_predicted: \", training_predicted)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81/81 [==============================] - 0s 951us/step - loss: 0.5300 - accuracy: 0.8715\n",
            "testing_predicted:  [1.1412180662155151, 0.7435197830200195]\n",
            "\n",
            "training_predicted:  [0.5299608707427979, 0.8714953064918518]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}