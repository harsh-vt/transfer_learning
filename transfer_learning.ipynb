{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAdVC-s1kkjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb5ZIr2Olgmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('training_data.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56-6kkoHs02f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "be2464ea-54ea-48ed-909e-46b6343146b3"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>AA</th>\n",
              "      <th>AB</th>\n",
              "      <th>AC</th>\n",
              "      <th>AD</th>\n",
              "      <th>AE</th>\n",
              "      <th>AF</th>\n",
              "      <th>AG</th>\n",
              "      <th>AH</th>\n",
              "      <th>AI</th>\n",
              "      <th>AK</th>\n",
              "      <th>AL</th>\n",
              "      <th>AM</th>\n",
              "      <th>AN</th>\n",
              "      <th>AO</th>\n",
              "      <th>AP</th>\n",
              "      <th>AQ</th>\n",
              "      <th>AR</th>\n",
              "      <th>AS</th>\n",
              "      <th>AT</th>\n",
              "      <th>AU</th>\n",
              "      <th>...</th>\n",
              "      <th>BD</th>\n",
              "      <th>BE</th>\n",
              "      <th>BF</th>\n",
              "      <th>BG</th>\n",
              "      <th>BH</th>\n",
              "      <th>BI</th>\n",
              "      <th>BJ</th>\n",
              "      <th>BK</th>\n",
              "      <th>BL</th>\n",
              "      <th>BM</th>\n",
              "      <th>BN</th>\n",
              "      <th>BO</th>\n",
              "      <th>BP</th>\n",
              "      <th>BQ</th>\n",
              "      <th>BR</th>\n",
              "      <th>BS</th>\n",
              "      <th>BT</th>\n",
              "      <th>BU</th>\n",
              "      <th>BV</th>\n",
              "      <th>BW</th>\n",
              "      <th>BX</th>\n",
              "      <th>BY</th>\n",
              "      <th>BZ</th>\n",
              "      <th>CA</th>\n",
              "      <th>CB</th>\n",
              "      <th>CC</th>\n",
              "      <th>CD</th>\n",
              "      <th>CE</th>\n",
              "      <th>CF</th>\n",
              "      <th>CG</th>\n",
              "      <th>CH</th>\n",
              "      <th>CI</th>\n",
              "      <th>CJ</th>\n",
              "      <th>CK</th>\n",
              "      <th>CL</th>\n",
              "      <th>CM</th>\n",
              "      <th>CN</th>\n",
              "      <th>CO</th>\n",
              "      <th>CP</th>\n",
              "      <th>CQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>305</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 88 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   A  B  C  D  E  F  G  H  I  J  ...  CH  CI  CJ   CK   CL  CM  CN  CO   CP  CQ\n",
              "0  0  1  0  0  0  0  1  0  0  0  ...   0   0   0  420  0.0   7  35   0  200   1\n",
              "1  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   40  0.0  11   5   0   20   1\n",
              "2  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   40  0.0  12   5   0  305   1\n",
              "3  0  1  0  0  0  0  1  0  0  0  ...   0   0   0  420  0.0  17  35   0  110   1\n",
              "4  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   85  0.0  19  20   0   75   5\n",
              "\n",
              "[5 rows x 88 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGw4qcSulrIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDE4zEpTmN9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xy = np.array(train_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axabB0RwmUYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "514b60db-5212-4ca7-95ee-16b4a6b5aeb2"
      },
      "source": [
        "print(xy)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.   1.   0. ...   0. 200.   1.]\n",
            " [  0.   1.   0. ...   0.  20.   1.]\n",
            " [  0.   1.   0. ...   0. 305.   1.]\n",
            " ...\n",
            " [  1.   0.   0. ...   0.  13.   4.]\n",
            " [  1.   0.   0. ...   0.   0.   4.]\n",
            " [  0.   0.   1. ...   0.   0.   2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi_lCYjGmmxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(xy)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cJczYnVnAna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "1e329d2b-2fb9-4f47-f4c5-19dc16535fcc"
      },
      "source": [
        "y = xy[:, -1:]\n",
        "x = xy[:, 0:-1]\n",
        "print(y)\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.]\n",
            " [3.]\n",
            " [5.]\n",
            " ...\n",
            " [5.]\n",
            " [2.]\n",
            " [3.]]\n",
            "[[  0.   0.   1. ...  30.   0. 120.]\n",
            " [  0.   0.   0. ...   4.   0.   1.]\n",
            " [  0.   0.   1. ...  14.   0.   0.]\n",
            " ...\n",
            " [  1.   0.   0. ...  15.   0.   5.]\n",
            " [  0.   0.   1. ...  15.   0. 135.]\n",
            " [  1.   0.   0. ...  25.   0. 156.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKJHyyUcNuk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=x/x.max(axis=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu8i1uLNRjmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 3500\n",
        "l = 100\n",
        "x_train = x[0:k,:]\n",
        "y_train = y[0:k,:]\n",
        "x_val = x[k:k+l,:]\n",
        "y_val = y[k:k+l,:]\n",
        "x_test = x[k+l:,:]\n",
        "y_test = y[k+l:,:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRnk5wJvSZ6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "2c7e4fd9-b7a7-422c-f4b9-673a55ce3fc8"
      },
      "source": [
        "print(x_train.shape)\n",
        "# print(x_train)\n",
        "print()\n",
        "print(y_train.shape)\n",
        "# print(y_train)\n",
        "print()\n",
        "print(x_val.shape)\n",
        "# print(x_val)\n",
        "print()\n",
        "print(y_val.shape)\n",
        "# print(y_val)\n",
        "print()\n",
        "print(x_test.shape)\n",
        "# print(x_test)\n",
        "print()\n",
        "print(y_test.shape)\n",
        "# print(y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3500, 87)\n",
            "\n",
            "(3500, 1)\n",
            "\n",
            "(100, 87)\n",
            "\n",
            "(100, 1)\n",
            "\n",
            "(68, 87)\n",
            "\n",
            "(68, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aYidakSVWzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_model():\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(87, input_dim=input_shape, activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(124, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(7,activation='softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Pl7cxMHH-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4c5a73f-063d-40c8-9913-2fa5298298eb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "input_shape = x_train.shape[1]\n",
        "\n",
        "model = baseline_model()\n",
        "\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "hist = model.fit(x_train, y_train, epochs=200,  validation_data=(x_val, y_val), callbacks=[cp_callback])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.show\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.legend([\"val_loss\", \"loss\"], loc =\"best\") \n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.show\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.legend([\"accuracy\", \"val_accuracy\"], loc =\"best\") \n",
        "plt.show()\n",
        "print(input_shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 2.0875 - accuracy: 0.2547\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0424 - accuracy: 0.2666 - val_loss: 1.5866 - val_accuracy: 0.3700\n",
            "Epoch 2/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 1.6284 - accuracy: 0.3847\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.6004 - accuracy: 0.3943 - val_loss: 1.3894 - val_accuracy: 0.5200\n",
            "Epoch 3/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 1.4893 - accuracy: 0.4079\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.4853 - accuracy: 0.4080 - val_loss: 1.2475 - val_accuracy: 0.5100\n",
            "Epoch 4/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 1.3613 - accuracy: 0.4647\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.3742 - accuracy: 0.4569 - val_loss: 1.1858 - val_accuracy: 0.5400\n",
            "Epoch 5/200\n",
            "108/110 [============================>.] - ETA: 0s - loss: 1.3285 - accuracy: 0.4696\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.3269 - accuracy: 0.4711 - val_loss: 1.1484 - val_accuracy: 0.5500\n",
            "Epoch 6/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 1.2926 - accuracy: 0.4799\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.2870 - accuracy: 0.4811 - val_loss: 1.1261 - val_accuracy: 0.5500\n",
            "Epoch 7/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 1.2402 - accuracy: 0.4970\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.2402 - accuracy: 0.4966 - val_loss: 1.1123 - val_accuracy: 0.5600\n",
            "Epoch 8/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 1.2208 - accuracy: 0.5052\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.2151 - accuracy: 0.5066 - val_loss: 1.1014 - val_accuracy: 0.5500\n",
            "Epoch 9/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 1.1836 - accuracy: 0.5166\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1961 - accuracy: 0.5097 - val_loss: 1.0667 - val_accuracy: 0.5700\n",
            "Epoch 10/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 1.1874 - accuracy: 0.5131\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1904 - accuracy: 0.5114 - val_loss: 1.0734 - val_accuracy: 0.5500\n",
            "Epoch 11/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 1.1479 - accuracy: 0.5296\n",
            "Epoch 00011: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1563 - accuracy: 0.5269 - val_loss: 1.0581 - val_accuracy: 0.5600\n",
            "Epoch 12/200\n",
            "107/110 [============================>.] - ETA: 0s - loss: 1.1520 - accuracy: 0.5362\n",
            "Epoch 00012: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1535 - accuracy: 0.5349 - val_loss: 1.0539 - val_accuracy: 0.5600\n",
            "Epoch 13/200\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 1.1399 - accuracy: 0.5366\n",
            "Epoch 00013: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1414 - accuracy: 0.5360 - val_loss: 1.0410 - val_accuracy: 0.5900\n",
            "Epoch 14/200\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 1.1334 - accuracy: 0.5398\n",
            "Epoch 00014: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1296 - accuracy: 0.5409 - val_loss: 1.0230 - val_accuracy: 0.6000\n",
            "Epoch 15/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 1.0955 - accuracy: 0.5657\n",
            "Epoch 00015: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.1036 - accuracy: 0.5606 - val_loss: 1.0121 - val_accuracy: 0.6300\n",
            "Epoch 16/200\n",
            "109/110 [============================>.] - ETA: 0s - loss: 1.0908 - accuracy: 0.5639\n",
            "Epoch 00016: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.5646 - val_loss: 1.0075 - val_accuracy: 0.6200\n",
            "Epoch 17/200\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 1.0861 - accuracy: 0.5542\n",
            "Epoch 00017: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0846 - accuracy: 0.5554 - val_loss: 0.9979 - val_accuracy: 0.6000\n",
            "Epoch 18/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 1.0768 - accuracy: 0.5680\n",
            "Epoch 00018: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0829 - accuracy: 0.5649 - val_loss: 0.9922 - val_accuracy: 0.5800\n",
            "Epoch 19/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 1.0481 - accuracy: 0.5749\n",
            "Epoch 00019: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0580 - accuracy: 0.5766 - val_loss: 0.9773 - val_accuracy: 0.6200\n",
            "Epoch 20/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 1.0381 - accuracy: 0.5788\n",
            "Epoch 00020: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0481 - accuracy: 0.5771 - val_loss: 0.9662 - val_accuracy: 0.6100\n",
            "Epoch 21/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 1.0501 - accuracy: 0.5738\n",
            "Epoch 00021: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0386 - accuracy: 0.5783 - val_loss: 0.9673 - val_accuracy: 0.6100\n",
            "Epoch 22/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 1.0310 - accuracy: 0.5818\n",
            "Epoch 00022: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0276 - accuracy: 0.5811 - val_loss: 0.9833 - val_accuracy: 0.6200\n",
            "Epoch 23/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.9975 - accuracy: 0.5941\n",
            "Epoch 00023: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 1.0016 - accuracy: 0.5923 - val_loss: 0.9649 - val_accuracy: 0.6400\n",
            "Epoch 24/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.9862 - accuracy: 0.5954\n",
            "Epoch 00024: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9990 - accuracy: 0.5926 - val_loss: 0.9509 - val_accuracy: 0.6500\n",
            "Epoch 25/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.9752 - accuracy: 0.6065\n",
            "Epoch 00025: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9789 - accuracy: 0.6060 - val_loss: 0.9105 - val_accuracy: 0.6600\n",
            "Epoch 26/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.9792 - accuracy: 0.6111\n",
            "Epoch 00026: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9763 - accuracy: 0.6106 - val_loss: 0.9266 - val_accuracy: 0.6700\n",
            "Epoch 27/200\n",
            " 89/110 [=======================>......] - ETA: 0s - loss: 0.9640 - accuracy: 0.6141\n",
            "Epoch 00027: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9714 - accuracy: 0.6106 - val_loss: 0.9177 - val_accuracy: 0.6700\n",
            "Epoch 28/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.9494 - accuracy: 0.6196\n",
            "Epoch 00028: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9568 - accuracy: 0.6166 - val_loss: 0.9024 - val_accuracy: 0.7100\n",
            "Epoch 29/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.9494 - accuracy: 0.6153\n",
            "Epoch 00029: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9484 - accuracy: 0.6163 - val_loss: 0.8877 - val_accuracy: 0.6700\n",
            "Epoch 30/200\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.9253 - accuracy: 0.6214\n",
            "Epoch 00030: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9253 - accuracy: 0.6214 - val_loss: 0.9066 - val_accuracy: 0.6700\n",
            "Epoch 31/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.9282 - accuracy: 0.6233\n",
            "Epoch 00031: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9221 - accuracy: 0.6254 - val_loss: 0.8963 - val_accuracy: 0.6600\n",
            "Epoch 32/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.9186 - accuracy: 0.6240\n",
            "Epoch 00032: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9080 - accuracy: 0.6291 - val_loss: 0.9096 - val_accuracy: 0.6700\n",
            "Epoch 33/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.9146 - accuracy: 0.6328\n",
            "Epoch 00033: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9070 - accuracy: 0.6369 - val_loss: 0.8739 - val_accuracy: 0.6500\n",
            "Epoch 34/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.8947 - accuracy: 0.6515\n",
            "Epoch 00034: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.9018 - accuracy: 0.6477 - val_loss: 0.8711 - val_accuracy: 0.6500\n",
            "Epoch 35/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.8807 - accuracy: 0.6384\n",
            "Epoch 00035: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8804 - accuracy: 0.6437 - val_loss: 0.8665 - val_accuracy: 0.6600\n",
            "Epoch 36/200\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.8723 - accuracy: 0.6490\n",
            "Epoch 00036: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8703 - accuracy: 0.6514 - val_loss: 0.8141 - val_accuracy: 0.7200\n",
            "Epoch 37/200\n",
            "102/110 [==========================>...] - ETA: 0s - loss: 0.8573 - accuracy: 0.6480\n",
            "Epoch 00037: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8570 - accuracy: 0.6486 - val_loss: 0.8260 - val_accuracy: 0.7000\n",
            "Epoch 38/200\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.8485 - accuracy: 0.6621\n",
            "Epoch 00038: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8555 - accuracy: 0.6583 - val_loss: 0.8152 - val_accuracy: 0.7000\n",
            "Epoch 39/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.8313 - accuracy: 0.6641\n",
            "Epoch 00039: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8345 - accuracy: 0.6637 - val_loss: 0.8105 - val_accuracy: 0.6800\n",
            "Epoch 40/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.8263 - accuracy: 0.6704\n",
            "Epoch 00040: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8271 - accuracy: 0.6709 - val_loss: 0.8021 - val_accuracy: 0.7000\n",
            "Epoch 41/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.8090 - accuracy: 0.6691\n",
            "Epoch 00041: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8136 - accuracy: 0.6686 - val_loss: 0.7879 - val_accuracy: 0.7000\n",
            "Epoch 42/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.8094 - accuracy: 0.6776\n",
            "Epoch 00042: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.8126 - accuracy: 0.6749 - val_loss: 0.7886 - val_accuracy: 0.7100\n",
            "Epoch 43/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.7803 - accuracy: 0.6888\n",
            "Epoch 00043: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7845 - accuracy: 0.6840 - val_loss: 0.7775 - val_accuracy: 0.6900\n",
            "Epoch 44/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.7805 - accuracy: 0.6982\n",
            "Epoch 00044: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7825 - accuracy: 0.6946 - val_loss: 0.7917 - val_accuracy: 0.6800\n",
            "Epoch 45/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.7895 - accuracy: 0.6828\n",
            "Epoch 00045: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7945 - accuracy: 0.6829 - val_loss: 0.7976 - val_accuracy: 0.6500\n",
            "Epoch 46/200\n",
            " 99/110 [==========================>...] - ETA: 0s - loss: 0.7771 - accuracy: 0.6847\n",
            "Epoch 00046: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7825 - accuracy: 0.6811 - val_loss: 0.7619 - val_accuracy: 0.7100\n",
            "Epoch 47/200\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7634 - accuracy: 0.6958\n",
            "Epoch 00047: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.6949 - val_loss: 0.7234 - val_accuracy: 0.7000\n",
            "Epoch 48/200\n",
            " 99/110 [==========================>...] - ETA: 0s - loss: 0.7454 - accuracy: 0.7071\n",
            "Epoch 00048: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.7011 - val_loss: 0.7310 - val_accuracy: 0.7300\n",
            "Epoch 49/200\n",
            " 99/110 [==========================>...] - ETA: 0s - loss: 0.7363 - accuracy: 0.7036\n",
            "Epoch 00049: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7003 - val_loss: 0.7590 - val_accuracy: 0.6900\n",
            "Epoch 50/200\n",
            " 88/110 [=======================>......] - ETA: 0s - loss: 0.7257 - accuracy: 0.7042\n",
            "Epoch 00050: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.7037 - val_loss: 0.7146 - val_accuracy: 0.7400\n",
            "Epoch 51/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.7403 - accuracy: 0.7105\n",
            "Epoch 00051: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7100 - val_loss: 0.7411 - val_accuracy: 0.7100\n",
            "Epoch 52/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.7355 - accuracy: 0.6995\n",
            "Epoch 00052: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.6989 - val_loss: 0.7620 - val_accuracy: 0.7000\n",
            "Epoch 53/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.7223 - accuracy: 0.7130\n",
            "Epoch 00053: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7131 - val_loss: 0.7421 - val_accuracy: 0.6900\n",
            "Epoch 54/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.7179 - accuracy: 0.7188\n",
            "Epoch 00054: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.7154 - val_loss: 0.7454 - val_accuracy: 0.7100\n",
            "Epoch 55/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.6897 - accuracy: 0.7294\n",
            "Epoch 00055: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.7249 - val_loss: 0.7499 - val_accuracy: 0.7100\n",
            "Epoch 56/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.6861 - accuracy: 0.7261\n",
            "Epoch 00056: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.7249 - val_loss: 0.7369 - val_accuracy: 0.7000\n",
            "Epoch 57/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.6865 - accuracy: 0.7291\n",
            "Epoch 00057: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.7240 - val_loss: 0.7219 - val_accuracy: 0.7300\n",
            "Epoch 58/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.6743 - accuracy: 0.7306\n",
            "Epoch 00058: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.7254 - val_loss: 0.7019 - val_accuracy: 0.7200\n",
            "Epoch 59/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.6861 - accuracy: 0.7329\n",
            "Epoch 00059: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.7343 - val_loss: 0.6773 - val_accuracy: 0.7200\n",
            "Epoch 60/200\n",
            " 88/110 [=======================>......] - ETA: 0s - loss: 0.6645 - accuracy: 0.7333\n",
            "Epoch 00060: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.7323 - val_loss: 0.6911 - val_accuracy: 0.7400\n",
            "Epoch 61/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.6876 - accuracy: 0.7282\n",
            "Epoch 00061: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.7297 - val_loss: 0.7013 - val_accuracy: 0.7300\n",
            "Epoch 62/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.6443 - accuracy: 0.7471\n",
            "Epoch 00062: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7483 - val_loss: 0.6948 - val_accuracy: 0.7200\n",
            "Epoch 63/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.6492 - accuracy: 0.7339\n",
            "Epoch 00063: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.7334 - val_loss: 0.6825 - val_accuracy: 0.7400\n",
            "Epoch 64/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.6573 - accuracy: 0.7417\n",
            "Epoch 00064: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.7417 - val_loss: 0.6760 - val_accuracy: 0.7200\n",
            "Epoch 65/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.6376 - accuracy: 0.7454\n",
            "Epoch 00065: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7443 - val_loss: 0.6668 - val_accuracy: 0.7500\n",
            "Epoch 66/200\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.6313 - accuracy: 0.7433\n",
            "Epoch 00066: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.7443 - val_loss: 0.6840 - val_accuracy: 0.7300\n",
            "Epoch 67/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.6222 - accuracy: 0.7554\n",
            "Epoch 00067: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7517 - val_loss: 0.7201 - val_accuracy: 0.7400\n",
            "Epoch 68/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.6025 - accuracy: 0.7590\n",
            "Epoch 00068: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.7589 - val_loss: 0.6558 - val_accuracy: 0.7600\n",
            "Epoch 69/200\n",
            " 90/110 [=======================>......] - ETA: 0s - loss: 0.5999 - accuracy: 0.7653\n",
            "Epoch 00069: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.7597 - val_loss: 0.6386 - val_accuracy: 0.7400\n",
            "Epoch 70/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.6130 - accuracy: 0.7537\n",
            "Epoch 00070: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7517 - val_loss: 0.6151 - val_accuracy: 0.7600\n",
            "Epoch 71/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.6047 - accuracy: 0.7588\n",
            "Epoch 00071: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7589 - val_loss: 0.6469 - val_accuracy: 0.7500\n",
            "Epoch 72/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.5968 - accuracy: 0.7699\n",
            "Epoch 00072: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7729 - val_loss: 0.6765 - val_accuracy: 0.7400\n",
            "Epoch 73/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.6093 - accuracy: 0.7613\n",
            "Epoch 00073: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.7637 - val_loss: 0.6511 - val_accuracy: 0.7400\n",
            "Epoch 74/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.5669 - accuracy: 0.7819\n",
            "Epoch 00074: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7777 - val_loss: 0.6443 - val_accuracy: 0.7300\n",
            "Epoch 75/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.5727 - accuracy: 0.7731\n",
            "Epoch 00075: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7711 - val_loss: 0.6623 - val_accuracy: 0.7300\n",
            "Epoch 76/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.5437 - accuracy: 0.7930\n",
            "Epoch 00076: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7897 - val_loss: 0.6154 - val_accuracy: 0.7900\n",
            "Epoch 77/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.5735 - accuracy: 0.7754\n",
            "Epoch 00077: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7711 - val_loss: 0.6136 - val_accuracy: 0.7700\n",
            "Epoch 78/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.5740 - accuracy: 0.7833\n",
            "Epoch 00078: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7780 - val_loss: 0.6464 - val_accuracy: 0.7300\n",
            "Epoch 79/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.5466 - accuracy: 0.7826\n",
            "Epoch 00079: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7811 - val_loss: 0.6143 - val_accuracy: 0.7800\n",
            "Epoch 80/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.5518 - accuracy: 0.7779\n",
            "Epoch 00080: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7789 - val_loss: 0.6160 - val_accuracy: 0.7700\n",
            "Epoch 81/200\n",
            " 90/110 [=======================>......] - ETA: 0s - loss: 0.5378 - accuracy: 0.7854\n",
            "Epoch 00081: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7869 - val_loss: 0.6400 - val_accuracy: 0.7300\n",
            "Epoch 82/200\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.5554 - accuracy: 0.7870\n",
            "Epoch 00082: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7866 - val_loss: 0.6737 - val_accuracy: 0.7400\n",
            "Epoch 83/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.5389 - accuracy: 0.7816\n",
            "Epoch 00083: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7800 - val_loss: 0.6389 - val_accuracy: 0.7800\n",
            "Epoch 84/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.5258 - accuracy: 0.7916\n",
            "Epoch 00084: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7923 - val_loss: 0.6517 - val_accuracy: 0.7500\n",
            "Epoch 85/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.5458 - accuracy: 0.7842\n",
            "Epoch 00085: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7831 - val_loss: 0.6524 - val_accuracy: 0.7700\n",
            "Epoch 86/200\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.8025\n",
            "Epoch 00086: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.8017 - val_loss: 0.6677 - val_accuracy: 0.7500\n",
            "Epoch 87/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.5177 - accuracy: 0.7919\n",
            "Epoch 00087: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7949 - val_loss: 0.6336 - val_accuracy: 0.7700\n",
            "Epoch 88/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.5339 - accuracy: 0.7925\n",
            "Epoch 00088: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7943 - val_loss: 0.6613 - val_accuracy: 0.7700\n",
            "Epoch 89/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.5081 - accuracy: 0.7957\n",
            "Epoch 00089: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7940 - val_loss: 0.6565 - val_accuracy: 0.7500\n",
            "Epoch 90/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.5206 - accuracy: 0.8036\n",
            "Epoch 00090: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7969 - val_loss: 0.6541 - val_accuracy: 0.7700\n",
            "Epoch 91/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.5030 - accuracy: 0.7999\n",
            "Epoch 00091: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8009 - val_loss: 0.6633 - val_accuracy: 0.7500\n",
            "Epoch 92/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.5088 - accuracy: 0.8050\n",
            "Epoch 00092: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8049 - val_loss: 0.6160 - val_accuracy: 0.7800\n",
            "Epoch 93/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.5236 - accuracy: 0.7900\n",
            "Epoch 00093: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7943 - val_loss: 0.6142 - val_accuracy: 0.8100\n",
            "Epoch 94/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.4690 - accuracy: 0.8148\n",
            "Epoch 00094: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.8123 - val_loss: 0.6776 - val_accuracy: 0.7800\n",
            "Epoch 95/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.4892 - accuracy: 0.8029\n",
            "Epoch 00095: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8046 - val_loss: 0.7051 - val_accuracy: 0.7600\n",
            "Epoch 96/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.4963 - accuracy: 0.8049\n",
            "Epoch 00096: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8011 - val_loss: 0.6946 - val_accuracy: 0.7800\n",
            "Epoch 97/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.5016 - accuracy: 0.7982\n",
            "Epoch 00097: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7969 - val_loss: 0.6550 - val_accuracy: 0.7900\n",
            "Epoch 98/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.4913 - accuracy: 0.8151\n",
            "Epoch 00098: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8160 - val_loss: 0.6279 - val_accuracy: 0.7800\n",
            "Epoch 99/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.4786 - accuracy: 0.8141\n",
            "Epoch 00099: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8137 - val_loss: 0.6147 - val_accuracy: 0.7700\n",
            "Epoch 100/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.4831 - accuracy: 0.8138\n",
            "Epoch 00100: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.8091 - val_loss: 0.6210 - val_accuracy: 0.7600\n",
            "Epoch 101/200\n",
            "101/110 [==========================>...] - ETA: 0s - loss: 0.4788 - accuracy: 0.8153\n",
            "Epoch 00101: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.5967 - val_accuracy: 0.8000\n",
            "Epoch 102/200\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.8089\n",
            "Epoch 00102: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8089 - val_loss: 0.6082 - val_accuracy: 0.8100\n",
            "Epoch 103/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.4883 - accuracy: 0.8072\n",
            "Epoch 00103: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.8111 - val_loss: 0.6314 - val_accuracy: 0.7900\n",
            "Epoch 104/200\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.8053\n",
            "Epoch 00104: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8031 - val_loss: 0.6280 - val_accuracy: 0.7700\n",
            "Epoch 105/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.4623 - accuracy: 0.8206\n",
            "Epoch 00105: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.8174 - val_loss: 0.6137 - val_accuracy: 0.7900\n",
            "Epoch 106/200\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.8215\n",
            "Epoch 00106: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8223 - val_loss: 0.5977 - val_accuracy: 0.8000\n",
            "Epoch 107/200\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.8197\n",
            "Epoch 00107: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8200 - val_loss: 0.6278 - val_accuracy: 0.7700\n",
            "Epoch 108/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.4733 - accuracy: 0.8146\n",
            "Epoch 00108: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8166 - val_loss: 0.6180 - val_accuracy: 0.8200\n",
            "Epoch 109/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.4523 - accuracy: 0.8200\n",
            "Epoch 00109: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8154 - val_loss: 0.6029 - val_accuracy: 0.7800\n",
            "Epoch 110/200\n",
            " 90/110 [=======================>......] - ETA: 0s - loss: 0.4665 - accuracy: 0.8198\n",
            "Epoch 00110: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8177 - val_loss: 0.6305 - val_accuracy: 0.8200\n",
            "Epoch 111/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.4425 - accuracy: 0.8318\n",
            "Epoch 00111: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8297 - val_loss: 0.6501 - val_accuracy: 0.8100\n",
            "Epoch 112/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.4580 - accuracy: 0.8276\n",
            "Epoch 00112: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8280 - val_loss: 0.6251 - val_accuracy: 0.8300\n",
            "Epoch 113/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.4383 - accuracy: 0.8345\n",
            "Epoch 00113: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8346 - val_loss: 0.6284 - val_accuracy: 0.8100\n",
            "Epoch 114/200\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.8198\n",
            "Epoch 00114: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8211 - val_loss: 0.6216 - val_accuracy: 0.8200\n",
            "Epoch 115/200\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.4356 - accuracy: 0.8228\n",
            "Epoch 00115: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8223 - val_loss: 0.6344 - val_accuracy: 0.8100\n",
            "Epoch 116/200\n",
            "100/110 [==========================>...] - ETA: 0s - loss: 0.4022 - accuracy: 0.8472\n",
            "Epoch 00116: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8440 - val_loss: 0.6103 - val_accuracy: 0.8200\n",
            "Epoch 117/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.4261 - accuracy: 0.8355\n",
            "Epoch 00117: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8337 - val_loss: 0.6299 - val_accuracy: 0.8000\n",
            "Epoch 118/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.4127 - accuracy: 0.8366\n",
            "Epoch 00118: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8320 - val_loss: 0.6079 - val_accuracy: 0.8400\n",
            "Epoch 119/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.4348 - accuracy: 0.8266\n",
            "Epoch 00119: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8251 - val_loss: 0.6217 - val_accuracy: 0.8200\n",
            "Epoch 120/200\n",
            " 90/110 [=======================>......] - ETA: 0s - loss: 0.4424 - accuracy: 0.8326\n",
            "Epoch 00120: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8334 - val_loss: 0.6198 - val_accuracy: 0.8100\n",
            "Epoch 121/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.4323 - accuracy: 0.8293\n",
            "Epoch 00121: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8280 - val_loss: 0.6596 - val_accuracy: 0.8000\n",
            "Epoch 122/200\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.8293\n",
            "Epoch 00122: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8294 - val_loss: 0.6364 - val_accuracy: 0.8300\n",
            "Epoch 123/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.3937 - accuracy: 0.8480\n",
            "Epoch 00123: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8443 - val_loss: 0.6278 - val_accuracy: 0.8500\n",
            "Epoch 124/200\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.4329 - accuracy: 0.8268\n",
            "Epoch 00124: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8266 - val_loss: 0.6253 - val_accuracy: 0.8100\n",
            "Epoch 125/200\n",
            "102/110 [==========================>...] - ETA: 0s - loss: 0.3994 - accuracy: 0.8465\n",
            "Epoch 00125: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8480 - val_loss: 0.6197 - val_accuracy: 0.8100\n",
            "Epoch 126/200\n",
            " 89/110 [=======================>......] - ETA: 0s - loss: 0.4264 - accuracy: 0.8371\n",
            "Epoch 00126: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8386 - val_loss: 0.6145 - val_accuracy: 0.8200\n",
            "Epoch 127/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.3789 - accuracy: 0.8577\n",
            "Epoch 00127: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8503 - val_loss: 0.6153 - val_accuracy: 0.8300\n",
            "Epoch 128/200\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 0.4076 - accuracy: 0.8422\n",
            "Epoch 00128: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8406 - val_loss: 0.6540 - val_accuracy: 0.8300\n",
            "Epoch 129/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3856 - accuracy: 0.8529\n",
            "Epoch 00129: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8514 - val_loss: 0.6462 - val_accuracy: 0.8200\n",
            "Epoch 130/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.3752 - accuracy: 0.8513\n",
            "Epoch 00130: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8494 - val_loss: 0.6334 - val_accuracy: 0.8300\n",
            "Epoch 131/200\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.3976 - accuracy: 0.8467\n",
            "Epoch 00131: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8431 - val_loss: 0.5890 - val_accuracy: 0.8400\n",
            "Epoch 132/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.4132 - accuracy: 0.8353\n",
            "Epoch 00132: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8363 - val_loss: 0.6043 - val_accuracy: 0.8300\n",
            "Epoch 133/200\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.4059 - accuracy: 0.8425\n",
            "Epoch 00133: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8426 - val_loss: 0.6010 - val_accuracy: 0.8300\n",
            "Epoch 134/200\n",
            " 90/110 [=======================>......] - ETA: 0s - loss: 0.3825 - accuracy: 0.8517\n",
            "Epoch 00134: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8494 - val_loss: 0.6357 - val_accuracy: 0.8100\n",
            "Epoch 135/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3764 - accuracy: 0.8501\n",
            "Epoch 00135: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8491 - val_loss: 0.6115 - val_accuracy: 0.8100\n",
            "Epoch 136/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.3913 - accuracy: 0.8457\n",
            "Epoch 00136: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8457 - val_loss: 0.6027 - val_accuracy: 0.8200\n",
            "Epoch 137/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.3788 - accuracy: 0.8579\n",
            "Epoch 00137: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8566 - val_loss: 0.6076 - val_accuracy: 0.8100\n",
            "Epoch 138/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.4011 - accuracy: 0.8477\n",
            "Epoch 00138: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8449 - val_loss: 0.6071 - val_accuracy: 0.8500\n",
            "Epoch 139/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3820 - accuracy: 0.8545\n",
            "Epoch 00139: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8497 - val_loss: 0.6620 - val_accuracy: 0.8000\n",
            "Epoch 140/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3698 - accuracy: 0.8668\n",
            "Epoch 00140: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8643 - val_loss: 0.6122 - val_accuracy: 0.8100\n",
            "Epoch 141/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.3796 - accuracy: 0.8566\n",
            "Epoch 00141: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8569 - val_loss: 0.6459 - val_accuracy: 0.8100\n",
            "Epoch 142/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3791 - accuracy: 0.8594\n",
            "Epoch 00142: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8560 - val_loss: 0.5972 - val_accuracy: 0.8300\n",
            "Epoch 143/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.3833 - accuracy: 0.8575\n",
            "Epoch 00143: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8546 - val_loss: 0.6122 - val_accuracy: 0.8200\n",
            "Epoch 144/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.3524 - accuracy: 0.8604\n",
            "Epoch 00144: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8591 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
            "Epoch 145/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3585 - accuracy: 0.8659\n",
            "Epoch 00145: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8660 - val_loss: 0.6010 - val_accuracy: 0.8200\n",
            "Epoch 146/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.3886 - accuracy: 0.8467\n",
            "Epoch 00146: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8480 - val_loss: 0.7004 - val_accuracy: 0.7900\n",
            "Epoch 147/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.3614 - accuracy: 0.8561\n",
            "Epoch 00147: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8543 - val_loss: 0.6225 - val_accuracy: 0.8300\n",
            "Epoch 148/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3863 - accuracy: 0.8525\n",
            "Epoch 00148: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8540 - val_loss: 0.6333 - val_accuracy: 0.8200\n",
            "Epoch 149/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3566 - accuracy: 0.8652\n",
            "Epoch 00149: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8646 - val_loss: 0.5985 - val_accuracy: 0.8100\n",
            "Epoch 150/200\n",
            " 89/110 [=======================>......] - ETA: 0s - loss: 0.3560 - accuracy: 0.8641\n",
            "Epoch 00150: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8589 - val_loss: 0.5629 - val_accuracy: 0.8600\n",
            "Epoch 151/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.3813 - accuracy: 0.8534\n",
            "Epoch 00151: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8574 - val_loss: 0.6329 - val_accuracy: 0.7900\n",
            "Epoch 152/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3468 - accuracy: 0.8658\n",
            "Epoch 00152: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8643 - val_loss: 0.6075 - val_accuracy: 0.8400\n",
            "Epoch 153/200\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.3668 - accuracy: 0.8635\n",
            "Epoch 00153: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8631 - val_loss: 0.5717 - val_accuracy: 0.8300\n",
            "Epoch 154/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.3653 - accuracy: 0.8602\n",
            "Epoch 00154: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8580 - val_loss: 0.5939 - val_accuracy: 0.8700\n",
            "Epoch 155/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.3640 - accuracy: 0.8647\n",
            "Epoch 00155: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8614 - val_loss: 0.6210 - val_accuracy: 0.8600\n",
            "Epoch 156/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3553 - accuracy: 0.8556\n",
            "Epoch 00156: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8569 - val_loss: 0.5658 - val_accuracy: 0.8700\n",
            "Epoch 157/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3654 - accuracy: 0.8649\n",
            "Epoch 00157: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8609 - val_loss: 0.5998 - val_accuracy: 0.8200\n",
            "Epoch 158/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.3682 - accuracy: 0.8527\n",
            "Epoch 00158: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8574 - val_loss: 0.5959 - val_accuracy: 0.8400\n",
            "Epoch 159/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3627 - accuracy: 0.8599\n",
            "Epoch 00159: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8569 - val_loss: 0.6051 - val_accuracy: 0.8400\n",
            "Epoch 160/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.3597 - accuracy: 0.8637\n",
            "Epoch 00160: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8631 - val_loss: 0.6146 - val_accuracy: 0.8400\n",
            "Epoch 161/200\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.3665 - accuracy: 0.8632\n",
            "Epoch 00161: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8637 - val_loss: 0.6135 - val_accuracy: 0.8600\n",
            "Epoch 162/200\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.3673 - accuracy: 0.8571\n",
            "Epoch 00162: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8597 - val_loss: 0.6079 - val_accuracy: 0.8500\n",
            "Epoch 163/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3579 - accuracy: 0.8639\n",
            "Epoch 00163: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8617 - val_loss: 0.6350 - val_accuracy: 0.8100\n",
            "Epoch 164/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3409 - accuracy: 0.8724\n",
            "Epoch 00164: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8726 - val_loss: 0.6108 - val_accuracy: 0.8500\n",
            "Epoch 165/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3542 - accuracy: 0.8618\n",
            "Epoch 00165: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8646 - val_loss: 0.6090 - val_accuracy: 0.8300\n",
            "Epoch 166/200\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.3406 - accuracy: 0.8727\n",
            "Epoch 00166: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8726 - val_loss: 0.5964 - val_accuracy: 0.8500\n",
            "Epoch 167/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.3497 - accuracy: 0.8628\n",
            "Epoch 00167: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8640 - val_loss: 0.6413 - val_accuracy: 0.8100\n",
            "Epoch 168/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3294 - accuracy: 0.8708\n",
            "Epoch 00168: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8740 - val_loss: 0.6419 - val_accuracy: 0.8700\n",
            "Epoch 169/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.3326 - accuracy: 0.8685\n",
            "Epoch 00169: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8677 - val_loss: 0.6518 - val_accuracy: 0.8600\n",
            "Epoch 170/200\n",
            " 88/110 [=======================>......] - ETA: 0s - loss: 0.3306 - accuracy: 0.8718\n",
            "Epoch 00170: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8711 - val_loss: 0.6547 - val_accuracy: 0.8400\n",
            "Epoch 171/200\n",
            " 89/110 [=======================>......] - ETA: 0s - loss: 0.3275 - accuracy: 0.8820\n",
            "Epoch 00171: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8769 - val_loss: 0.6598 - val_accuracy: 0.8600\n",
            "Epoch 172/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3352 - accuracy: 0.8695\n",
            "Epoch 00172: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8689 - val_loss: 0.6382 - val_accuracy: 0.8400\n",
            "Epoch 173/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.8721\n",
            "Epoch 00173: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8714 - val_loss: 0.6131 - val_accuracy: 0.8600\n",
            "Epoch 174/200\n",
            " 89/110 [=======================>......] - ETA: 0s - loss: 0.3318 - accuracy: 0.8729\n",
            "Epoch 00174: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8749 - val_loss: 0.6544 - val_accuracy: 0.8500\n",
            "Epoch 175/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3381 - accuracy: 0.8737\n",
            "Epoch 00175: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8766 - val_loss: 0.6246 - val_accuracy: 0.8600\n",
            "Epoch 176/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.3342 - accuracy: 0.8688\n",
            "Epoch 00176: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8717 - val_loss: 0.6368 - val_accuracy: 0.8600\n",
            "Epoch 177/200\n",
            " 89/110 [=======================>......] - ETA: 0s - loss: 0.3282 - accuracy: 0.8806\n",
            "Epoch 00177: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8760 - val_loss: 0.5917 - val_accuracy: 0.8500\n",
            "Epoch 178/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3245 - accuracy: 0.8747\n",
            "Epoch 00178: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8757 - val_loss: 0.6352 - val_accuracy: 0.8500\n",
            "Epoch 179/200\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.3310 - accuracy: 0.8727\n",
            "Epoch 00179: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8737 - val_loss: 0.6070 - val_accuracy: 0.8700\n",
            "Epoch 180/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.8721\n",
            "Epoch 00180: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8691 - val_loss: 0.6184 - val_accuracy: 0.8600\n",
            "Epoch 181/200\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.8855\n",
            "Epoch 00181: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8837 - val_loss: 0.5730 - val_accuracy: 0.8700\n",
            "Epoch 182/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3197 - accuracy: 0.8701\n",
            "Epoch 00182: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8723 - val_loss: 0.6042 - val_accuracy: 0.8600\n",
            "Epoch 183/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3136 - accuracy: 0.8822\n",
            "Epoch 00183: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.8789 - val_loss: 0.6326 - val_accuracy: 0.8500\n",
            "Epoch 184/200\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.8753\n",
            "Epoch 00184: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8749 - val_loss: 0.7061 - val_accuracy: 0.8600\n",
            "Epoch 185/200\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.3131 - accuracy: 0.8786\n",
            "Epoch 00185: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8769 - val_loss: 0.6761 - val_accuracy: 0.8600\n",
            "Epoch 186/200\n",
            " 89/110 [=======================>......] - ETA: 0s - loss: 0.3125 - accuracy: 0.8845\n",
            "Epoch 00186: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8823 - val_loss: 0.6492 - val_accuracy: 0.8600\n",
            "Epoch 187/200\n",
            " 91/110 [=======================>......] - ETA: 0s - loss: 0.2998 - accuracy: 0.8884\n",
            "Epoch 00187: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8863 - val_loss: 0.6371 - val_accuracy: 0.8500\n",
            "Epoch 188/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3311 - accuracy: 0.8747\n",
            "Epoch 00188: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8740 - val_loss: 0.6289 - val_accuracy: 0.8500\n",
            "Epoch 189/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.2994 - accuracy: 0.8822\n",
            "Epoch 00189: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8834 - val_loss: 0.6100 - val_accuracy: 0.8600\n",
            "Epoch 190/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3218 - accuracy: 0.8780\n",
            "Epoch 00190: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8783 - val_loss: 0.5991 - val_accuracy: 0.8600\n",
            "Epoch 191/200\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.3042 - accuracy: 0.8811\n",
            "Epoch 00191: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.8826 - val_loss: 0.6455 - val_accuracy: 0.8800\n",
            "Epoch 192/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3027 - accuracy: 0.8849\n",
            "Epoch 00192: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8849 - val_loss: 0.6545 - val_accuracy: 0.8500\n",
            "Epoch 193/200\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.8831\n",
            "Epoch 00193: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8826 - val_loss: 0.6201 - val_accuracy: 0.8300\n",
            "Epoch 194/200\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.3033 - accuracy: 0.8821\n",
            "Epoch 00194: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8777 - val_loss: 0.6091 - val_accuracy: 0.8400\n",
            "Epoch 195/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.3119 - accuracy: 0.8763\n",
            "Epoch 00195: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8777 - val_loss: 0.7206 - val_accuracy: 0.8300\n",
            "Epoch 196/200\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.3224 - accuracy: 0.8766\n",
            "Epoch 00196: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8751 - val_loss: 0.6367 - val_accuracy: 0.8400\n",
            "Epoch 197/200\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.2878 - accuracy: 0.8857\n",
            "Epoch 00197: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8843 - val_loss: 0.7130 - val_accuracy: 0.8500\n",
            "Epoch 198/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.3139 - accuracy: 0.8784\n",
            "Epoch 00198: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8774 - val_loss: 0.7337 - val_accuracy: 0.8500\n",
            "Epoch 199/200\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.2910 - accuracy: 0.8854\n",
            "Epoch 00199: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8837 - val_loss: 0.6688 - val_accuracy: 0.8400\n",
            "Epoch 200/200\n",
            " 87/110 [======================>.......] - ETA: 0s - loss: 0.2783 - accuracy: 0.8912\n",
            "Epoch 00200: saving model to training_1/cp.ckpt\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8900 - val_loss: 0.6354 - val_accuracy: 0.8500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3iUxdqH78lm0ztppJCEHlroJRRBBLGBiIiIHsCKR8XuZzvKUTzFrogKemwocjgoioqCSJXQAlIDhBBIg/Te23x/zG52UyAREiBh7uvi2t15533f2QV+++wzTxFSSjQajUbT+rG52AvQaDQaTfOgBV2j0WjaCFrQNRqNpo2gBV2j0WjaCFrQNRqNpo1ge7Fu7O3tLUNDQy/W7TUajaZVsnv37kwppU9Dxy6aoIeGhhIdHX2xbq/RaDStEiFEwpmOaZeLRqPRtBG0oGs0Gk0boUmCLoSYIIQ4KoSIE0I83cDxECHEb0KI/UKIjUKIoOZfqkaj0WjORqM+dCGEAVgIjAOSgV1CiFVSyhiraa8DX0gpPxdCXAn8E7jjzy6moqKC5ORkSktL/+ypmhbAwcGBoKAgjEbjxV6KRqNpAk3ZFB0MxEkp4wGEEMuASYC1oPcAHjM93wB8dy6LSU5OxtXVldDQUIQQ53IJTTMhpSQrK4vk5GTCwsIu9nI0Gk0TaIrLJRBIsnqdbBqzZh9wk+n5ZMBVCNGu7oWEEPcKIaKFENEZGRn1blRaWkq7du20mF8CCCFo166d/rWk0bQimmtT9AngCiHEH8AVQApQVXeSlHKxlHKglHKgj0+DYZRazC8h9N+FRtO6aIqgpwDBVq+DTGM1SClPSSlvklL2A54zjeU22yo1Go2mDVBdLXnlpxiSsotb5PpNEfRdQBchRJgQwg64FVhlPUEI4S2EMF/rGeCT5l2mRqPRXBwOn86nuLyyWa713oY4Ptpygt/jMpvlenVpVNCllJXAg8Aa4DCwXEp5SAjxkhBiomnaaOCoECIW8ANeaZHVtiEqK5vnH4hGozk3qqslX+1IIL+04ozH3/o1lmve2cLLP6oYkN0JOZzKLQEgs7CMV385wqT3fuejzfEUldX/P73mUCpfbDsJwO/HMnlrXSyT+wVy66DgenObgyb50KWUq6WUXaWUnaSUr5jGXpBSrjI9XyGl7GKac7eUsqxFVnuBuPHGGxkwYAA9e/Zk8eLFAPzyyy/079+fiIgIxo4dC0BhYSGzZ8+md+/e9OnTh2+++QYAFxeXmmutWLGCWbNmATBr1izmzJnDkCFDeOqpp9i5cyfDhg2jX79+REZGcvToUQCqqqp44okn6NWrF3369GHBggWsX7+eG2+8sea6v/76K5MnT74QH4dG0ybZfCyD51YeZNGm4/WOSSn52/cHeee3Y3i72PH93lMcSc1n2qJtTH5/Kz/tP81db/6X5Zv2UFpRzSurDzP5/a1kFlqkL7uonCeW7+OF7w/x5fYE5i77gy6+LrwyuVeL7U9dtFoujfH3Hw4Rcyq/Wa/ZI8CNF2/o2ei8Tz75BC8vL0pKShg0aBCTJk3innvuYfPmzYSFhZGdnQ3Ayy+/jLu7OwcOHAAgJyen0WsnJycTFRWFwWAgPz+fLVu2YGtry7p163j22Wf55ptvWLx4MSdPnmTv3r3Y2tqSnZ2Np6cnf/3rX8nIyMDHx4dPP/2UO++88/w+EI2mlVNSXkV8ZiE9A9xrjZdWVJGQVUw3f9ea17Y2AluDxYZdfeA0AF/vTOLGvoHct2Q3k/oG8tcxnViwPo6vdiRy3xUdGd/DnykfRDHrk13Y2AhKK6p5YOludjrOw6HXKNxmfMbGo+nM+XI3tyzaxqAQL7r5u5KQVURReSVh3s48/91BnO0MfHD7AJzsWk52L1lBv5i8++67rFy5EoCkpCQWL17MqFGjauKxvby8AFi3bh3Lli2rOc/T07PRa0+dOhWDwQBAXl4eM2fO5NixYwghqKioqLnunDlzsLW1rXW/O+64gy+//JLZs2ezbds2vvjii2Z6xxpN62BrXCY92rvh6WxHRVU1d32+i6jjWSy/bxiDw7woLq/ktTVHWRGdTEFZJU9e3Q1bG8Gra45SVS3p6ufC7UNDmDogmLUxaYR5O3Mis4ibP9xGYVklb62L5eMt8RSUVTK5XyBPT+gOQFc/F2LTCpk9PJTJ/QJZuyUK36NZkKd+VY/u5ssnMwfx/PcHWX80nf9Gq0jvKf2DmHNFR+5bspsnr+5GJx+XM7635uCSFfSmWNItwcaNG1m3bh3btm3DycmJ0aNH07dvX44cOdLka1j/nKobx+3s7Fzz/G9/+xtjxoxh5cqVnDx5ktGjR5/1urNnz+aGG27AwcGBqVOn1gi+RnPJUV0NZfng6AFSQmkuODZu8ACk5JZwy4fbmD+5F939XZn5yU4eG9cNf3cH7v94PZ2CA1h6zzBe+P4gUcezcHWw5YXvD/LsteHMW3WIE1lFTO4bSElFFa+tUYJ7VbgfPQPc2Hg0nTe+38GX2xPILa7gzeuDeGVDOsczivhgRn9O55USdTyTqQODuSrcr+b/8l0jwvjnz0e4f3QnfF0d6NMtC44CmcegqhIMtkR29mb946MBiDqeyXd/pNSse/0To1vgQ66PVoQ65OXl4enpiZOTE0eOHGH79u2UlpayefNmTpw4UeNy8fLyYty4cSxcuJC3334bUC4XT09P/Pz8OHz4MN26dWPlypW4urqe8V6BgSpH67PPPqsZHzduHIsWLWLMmDE1LhcvLy8CAgIICAhg/vz5rFu3rsU/C43mnNn7Ffz8f/DADji2Bn55Fh4/Ak5ejZ766e8nSMkt4fmVB+kR4EZsWiHzVh0i3NeOrfZzWXTqekb8u4SsonLmXtmZHgHuzPlyN3/5ZCeBHo4svXsowzq1o6pa8spPh3FxsOWRsV2wsRE82ruM6g9vYE7Gw7jb+zHmhzvoNPJVdrpdzTW92wNw54j6mdHTBnVg6oBgbGxMxlpClHqsroCck+Ddudb8yE7eRHbyPq+P8FzQ1RbrMGHCBCorKwkPD+fpp59m6NCh+Pj4sHjxYm666SYiIiKYNm0aAM8//zw5OTn06tWLiIgINmzYAMC//vUvrr/+eiIjI2nfvv0Z7/XUU0/xzDPP0K9fv1pRL3fffTcdOnSgT58+REREsHTp0ppjM2bMIDg4mPDw8Bb6BDSXG7FpBaTlN5wRHJtWwPULtnA8o7DWuJSSDUfSySu2RIjkFpez4Ug6WYVlkHYQKopg82uw+XWoKoPc+mW8K6uqScktoaRc5SEWlFawbFcSPdq7kZJbwq8xaYzv4UdqfilH4+JxFSU84PALDtVFLJjej8fGd+Pqnn48clUXXri+B789fgXDOqkkdYON4IUbevDYuK4WIT6+HhuqecP3Z94LXIeQVYQceI+p/c78/9RMzTUAEraCuylSJfNoo+deKISU8qLceODAgbJug4vDhw9roWqEBx98kH79+nHXXXddkPvpv5O2TUVVNUP+8RveLnb88NAI7G0NNcfKKqu4cWEUh0/n8/i4rjw0tkvNsa1xmcz4eAf9O3iw9J6h2BlsuO3j7WyPVwEDa/0/pGvu5lr3yrzhC2zDr8HDyQ6ATbEZ3P/lborLq/Bzs2fhbf1ZG5PG4s3xrHpwOP+LTmZPYg7f3B/J48v3kXFsB8tRxV6rr3wRm1GP8adZOg2OrQVZrV4HDYbknXDTR9DnlqZdIy8F3uoBo5+Fjf+AsS/CyHNYyzkihNgtpRzY0DFtobciBgwYwP79+7n99tsv9lI0bYTt8VlkF5UTm1bI+xss4XtSKnfF4dP5eDgZ2VInEWbR5nic7Qx0T/mGuDeu4qUfY9gen82jV3Xl5gFBVGQnkGATTJUUpKDKfLz93RbGvrGJnw+c5lhaAQ8v+4MgT0fWdP6Wlyvf4eYPt7F4czzjevjRJ8iDl2/sxQ8PjsDBaOCNWyL4cHKourmLHzbbF0J1FRz+Ad4bDOXFcHw9vN0b8k9D/EZ42QfmucOqh9R51dWQuA363AruHcDoDNOXgU84bHlDHd/8OszzUOfNc4d3+qprg/KVfzhCiTlA16vBtT1kxrbg39CfQ/vQWxG7d+++2EvQtHLWxaTx4abjLLlrCI52BlYfOI2znYEruvmwYP0x1hxKpV8HT8orq/lmTzJ3jwjDYBB88vsJisoqKSqrJDatkM2xGTx5dTeuPvIZoal7+SzqBFf39Gfu2M5qD/RINt+WD8W151xWnrTls9JH6eVWym47B+7/ag8Arva2LJrRj7D/3E636nxeGngnnfuOrHGZgMXN4WA04CAK1OCA2bDpX5B6AA6tVC6PlGiIWQW5iRC1QFndzj7g1wv2LIHIuVBZBqV50PEKGHw3lOaDczsY+Th8e7fy+//+NgQPho6joawAtr8Pez6HoffDwRXqngNmqeu2jwDvrpBx6bhctKBrNK2YnKJy8ksrCGnn3OhcKSWvrz3KkdQCfth/ipv6BbLmUBpjw/2YP7kXnXxcOJCSx6q9KRSVV3HfqI48fU13tsZlsWhTPP9YfZivdyZSLcHJzsCMIR3wSCgEUc3ymb3o1SkIIQSivACnqgKmjh2G/eh7GZpfSumCvzO1u5HJ10Sy/nA6yTklDOvUjrCqkyoaBvhL5QrofJZkuSLTr4TwG5SgJ0RBwjY1lrBNWd8AOz4EWQXXvQE9boS3esHvb0H7vup4SCR4dLBct+dk5Tr54WHTeW+Cfy917PR+2PqOEvEtb4BvT7juLbAxOTd8usHepSqSp6nJQtXVlvObGS3oGs2lyq8vKAGJmEZBaQW2NjY42hmY/2MMFVXV/H1SL+5dEs2ukzkM7ejFazdHEOzlVHN6ZVU1C9bHkV5QSicfFzr7unAktQCjQeCw7jkOZI8nu8iTa3v74+Zg5PHx3QAor6wmvaCUQA9HhBAMDPXEztaGr3Yk0ivQjVmRYYR5OylfeGE6AIP9BZgTZvKSAbBvFwKAn5sDeAZAUToGW0NNNAkA203RIn1nKAs585hyY3xzF4yfrzYev70bRj0FxZkgDODbQwnyvqVQcEqdf/gHyDgCEdNh3zJw8Ye+t4PRQYnxzsVwdDW4BdUWcwCDLYx4VLlmul5jEXOAUY/DksmwYCDkJ8OU/9QWY++uUF6o3rNHA+n82xbCH1+CwQgTF4BXJ1g0Eq58HnpN+XP/HpqAFnSN5lKkrFCJQccxEDGNmZ/sxN7WwNu39uXTqJNUVUu6t3dj18kcrgr3Y8eJLB5YuocVcyKxs1WC8+5vx3h3fRzeLnZ8XZiEwUbg7WLHnBEhXLvhB1b/nkUnnycZ3c231q3tbG0I8rR8MTgYDQzr2I69Sbl8MGNArS8NClPVY2kuoAScXFP7BGvhdPGFgtT67zNhq/JnD39ECXrKHvAMgdhflEsjZLgS6/YRUJylwh5tbNT4vq/VNcJGwQnTBuyAWWquZ5gSc1AblsVZUFkC3a5r+PPucyukH4GBs2uPdxyj1pZ9HLpfq6x5awL6qceU3fUFvTADfnsZPENVaOP6+RA6ErLjwSO04XWcJ1rQNZoLyPJdSaw+eJr/zByEweYsP9GTd0F1JZkpcTiUVbI3KZdqCY8t30tVtcTJzsCzKw/g6mDLO7f2ZcuxDOZ8uYfX1x7l2WvDiTqeyYINcUwdEMRrUyP4NSaN51Ye4L4rOnFLF7DdWE2gbT5f3zMUB6PhzOsw8frUCEorqmqLeUWJ8kkDlFiVvchLVI/uVgLn4g9ZUbUvKqVyk3QaaxHDvEQwF25NiAJMn1FesnK5OJliu0MilaA7eimf+onNYOugBLbD0Nr3cfGFKR+d/Q3a2sGEf9QfFwLG/f3M57WPAKOTWmvPG2sf2/4+VJbCtCUQ8z2sfxkSdyj/fNCAs6/nHNGCrtFcQL7bm0LU8SzWHkrlGt9siPsNhs+tNy/78Ea8AKeS0+xJyKFagtEg2BqXxaiuPkQEubNgfRy3DemAs70tE3q1Z16PVOK3ruEbv6f49y9HCPN25u+TVMb1uB5+XBXuqzIfTUkxfT3LMLg5NGndPq729QcL0yzPS3LUhmHsL+rXhcEOXPwsx139lDWffxp+e0nFpVeWQVGGEmejo9rEzE2yCLrpSw1Q4xUl4GTaMA0ZbnqMhNAR6nnQILBtYJ0ticGo7psQBUVZys9+xVOAhJ0fKYveuwsMvge2vgtleTDyiRZbjhb088DFxYXCwsLGJ2o0QFW1ZF+S6vvywabjTOi4CrFzkfKlutfu6lh8bIsSdEr5JToGIeCpq7vzyurD/GVoCIM7elFQWsm9IzuqEyrLmZnxOtJ4mnErepFrCOaz2YNrFYKqKUlhcokYrAX5XDD5zwEoyYW9X8P2hcoydwus7Wt28Yeqctj1kfJ9e3VS1m/7COgyXs1xD4Y8K0GvLLVsdOaZ3Di+ppwIr47Q62boPVVZ4P3/AmFXnN/7OVdChsPGf8K6F5S/3M4ZbGyhvEBF0AA4uMNVL8KpPyxfQC2AFvQ2QGVlpa7rcglyPKOQx5bv4+VJPekT5MHR1AKKyqsY2tGL7fHZnJBH6AiQuI3koGtZF5PGHcNCMVSX45N3gFPClwCZzr6DB+ji25u7R4YxtGM7egW6IYRg3kSrekf7lyEKToGw4QnHH8mb8B49AtwaXpjZJVKaq6zkc7VqrX3iJTkWiz0vSfm1rXEx+ekPfqvEfO6e+tdzD4L0w0rQ3TtY1unRQX0JGR0tLhch4Ob/WM6duODc3kNzEBIJSCXmwgZ2LlKP3a6tvcE6qOWTAS9dFfj5afUTrjnx7w3X/OuMh59++mmCg4N54IEHAJg3bx62trZs2LCBnJwcKioqmD9/PpMmTWr0VoWFhUyaNKnB87744gtef/11hBD06dOHJUuWkJaWxpw5c4iPjwfggw8+ICAggOuvv56DBw8C8Prrr1NYWMi8efNqiob9/vvvTJ8+na5duzJ//nzKy8tp164dX331FX5+fhQWFvLQQw8RHR2NEIIXX3yRvLw89u/fX1OD5qOPPiImJoa33nrrvD5ejQoNXHc4nZ6GJBb+uId9GYF8tvUkb07ry55E5Weef2Mvnl15kJKUk2ADhbGbeGxrIDtPZhOXUci9oRl0oJzUkIkEnPyYADLxCvFECEHvIHflhz1p8hkPvEu5N7a8Ce37IkKGM2HHh4iir+BIH+jewCZgrlXP98K02puXidtNvui+Db05FUESfj3Yu9Z2uZTmml4LQCpBtsbVXz3mnIB+dzT84Xl0gGO/miz3PkrAM49C71tgy+tqU9OpXu/5i0/QQLAxKvfQjR/CynvVeAu6Vs7EpSvoF4Fp06bxyCOP1Aj68uXLWbNmDXPnzsXNzY3MzEyGDh3KxIkTGy1Q7+DgwMqVK+udFxMTw/z584mKisLb27umtvrcuXO54oorWLlyJVVVVRQWFjZaX728vBxz+YScnBy2b9+OEIKPP/6YV199lTfeeKPBmu1Go5FXXnmF1157DaPRyKeffsqiRYvO9+PTAKsPpPLA0j0st/s7T4oMjvh/zi+HUplfXskfibl4u9jRyceF5fcNo/KfuVAG6Qc3sLNkAn2DPfhyeyL2u1bzNyO0H347nPyYQJFJeAdTpcKKEvjv7VBkcndUlqqIiZwTMO1LCByI2LdUxWkb7ODpRCWM1uRZCXpBHUH/5m5AKAvaYKx9XtpB+G4OpM+F8S8rC13YKJEtyVGvu4xXER0dhtQ+18Xf8tzs/66Le7AS7aw46HyVMsASoiCwv2WO84UveNUoRkcVAWPvChHT1D5CdWWLbXyejUtX0M9iSbcU/fr1Iz09nVOnTpGRkYGnpyf+/v48+uijbN68GRsbG1JSUkhLS8Pf3/+s15JS8uyzz9Y7b/369UydOhVvb/UP01zrfP369TX1zQ0GA+7u7o0KurlIGKjGGdOmTeP06dOUl5fX1G4/U832K6+8kh9//JHw8HAqKiro3bv3n/y0Ll+klGf8Ql+6M4EwdxsGlB/HICv5xxhXbvy6gF9j0vgjMYd+HZSlTVkBtmV5lNl50rE8iWH+kiVzhvHBxuOMObacqlwv2nfuS5XBkeDqLEv25J4lSsxn/qAyIre9r0TOJ1yF5NnYwJPxSlSWTVfhdHV9tnnJ4BGiimVZW9m5iRax378c+s2ofV6OqbhW9CcqbrswDZx9VYncEpOF3ulKmLG8/gfjYhUaGRLZ8AdrjnSR1Urch/1VvT693zLnUrTQAW6x6k0w9dOLtgxdy6UOU6dOZcWKFfz3v/9l2rRpfPXVV2RkZLB792727t2Ln59fvRrnDXGu51lja2tLdXV1zeuz1VZ/6KGHePDBBzlw4ACLFi1q9F533303n332GZ9++imzZ88+61yNhdS8Uq56cxMT3t7M93tTkHnJKt4YSDp5nLi4Y8ztlotBquiMPlWH6OFewaLv1hGfWcTQAFuVPGNye9j1nQrAO5Gl2BpseGhsF3oZUzH4dgchMHgGM7OHQcWFV5bD1rehwzDlox71JJRkq1oiIx+3bELa2JhE0xLRAij/dFmBunfQIDVWaOUHN8919oXf31S1UkBt5ElpEfvyQpWNWZimhNrRE/JPqYxPV6vIFmvsXVV4X0OJPWaswxzdgxp+fqkK+iWCFvQ6TJs2jWXLlrFixQqmTp1KXl4evr6+GI1GNmzYQEJC/RKgDXGm86688kr+97//kZWVBVDjchk7diwffPABoHqK5uXl4efnR3p6OllZWZSVlfHjjz+e9X7m2uqff/55zbi5ZrsZs9U/ZMgQkpKSWLp0KdOnT2/qx3NZsPrAae7+fBcVVdW1xjMKypj+0XbS8suoqpY8vGwvxxfeTPHKuZSUV1H8v3tYZj+f8U7HAAF2rtgkbeNTl/dZLp7lsZH+3JH+Knw8VrklABE+EYzO+CavVTeRUvmNfbqq1+7B2NRYzcsgPwVGmXyzwYOVRdyuS/2EF0cPtSGXsFW9zk2CD0fC/2Yrt0ZAP7XGAisLPWGrisaY8E/l9ji5RfnUF49W4ZV5yUqUu1+vBD3ruPKNO3pa6pm4nEHQhVBZlZ3HnjlF3joxx/q5oyfYmTr9aEE/K1rQ69CzZ08KCgoIDAykffv2zJgxg+joaHr37s0XX3xB9+7dm3SdM53Xs2dPnnvuOa644goiIiJ47DFVdvOdd95hw4YN9O7dmwEDBhATE4PRaOSFF15g8ODBjBs37qz3njdvHlOnTmXAgAE17hw4c812gFtuuYXhw4c3qXVeWyW3uJyB89dxx392sDshm9KKKl76IYZ1h9NZ+UdKrbmfRZ0gMbuYz+8cxJpHRvH3iT3xLEsh+dg+Iv6+FpfCk4SJVJz3LFbFm8JGwqHv8cvagYssZG7ZYuxif1LJOEd+Uhdt10llNx5YAdknVPJMSQ54qzR8PEyhfFWVauMzoJ9KxDEz7Su45zeVvl6XDpGQtBOqKlQ9kuoKiPtVHfMMVXHf1i6XhCh1TpfxyjeeEAXxm9Sx1P3KJeMepH4NlOap7EkXX3DwUCF6UNtXXpdZP8I1r575uIOHRbitN1WFsFjvl6IP/RLi0vWhX0TMG4gA3t7ebNu2rcF5Z4tBP9t5M2fOZObMmbXG/Pz8+P777+vNnTt3LnPn1k882bhxY63XkyZNajD6xsXFpZbFbs3vv//Oo48+eqa30HaoLCe9oJS/LjvIyzf2Iry9JZxv2/EsMgvL2JtYxS2LtjOmmy+p+aX4uNrzyfoDdPJ24kRWCVP6B/LT/tNEdmrHgBC17zFzSCCszcfNtpIZ/dsTsC8HJErcQiKVGB9draxK3x7KwrZ1VBZyzPcqMsLFHyIfUvHZW99WcdVQy0KnOEuFwuWcgPFf1bZw7awyN+sSEqnOO7AC9nyh6pQc/03Fg3sEK2u6ME25YTKPKau8/1/Awc2yIWmOCc+MVV8s7sFqk7LzVRC3Tq2/osRyzzO5XEC5Xc6GWbhzE+p3NvIIhozD2kJvBG2hX4bk5ubStWtXHB0dGTt2bOMntHa+uYvSZbOITsjh/77ZT1W1panLtvgsnOwM/P5/VzIkzIt1h9MYEubFq9cG81XRvaz76Fme+N8+Xl97lJNZxVxnXViqSPnOjVXFvDjEBiGrLfHXoSNU3Q5QpVfHPKeeD75HJcWUF6hkIhsbcGsP/W5XVfviN6p5Zgvdy5Q4tOZZ9aXQ7dqmv2+zH/27Oco6v/oVFTIoDMqP7eqn3CgfjoSPxljWDSoSJXmX+gPKpZKbZHGFjHpSPXoE1+4VeiaXS1Np18mSdFRrvLMS8wudCdrKaJKFLoSYALwDGICPpZT/qnO8A/A54GGa87SUcnUzr/WS5MCBA9xxR+24Wnt7e3bs2HGRVtQ4Hh4exMZeOkX5W4rc4nJ+PpjKrUk7cC8px85wD/uT8/h06wnuNmVYbo/PYmCoF+5ORj6ZNYgPNx3nhogAOh5cgBAF3OETyybhxsINx7G1EVzd08qlUNDAhuKIR5XYhYxQYj3rJwgeokIAZ62GwAFqIzM7vvYm4PCHYffnyjVidLZsBHa/HqZ+rhKAggf/ubKrLr7KzZGXogS8XSdVwTDiViXCLv7KygbVfSegLwSYQgRDIlUtElBZn+mH1S8L85o7DIW7flWW/B9fqjFhsCT+nCvXvlbb4jcz6skzx69ramhU0IUQBmAhMA5IBnYJIVZJKWOspj0PLJdSfiCE6AGsBkLPZUFnCwm7FOnduzd79+692MtoES5We8KmkJZfyqbYDKYOCGrw30tcegF3fR5NTlY60x3ScAdu6+1KYqk98386THJOCfeO6khsWiE39lObyQ5GA49c1VW5IHZ8CAgCCg4x/7bO3PTRHoZ39sbT2c5yk8I6G4qgfL/WDYOtQwZDzfVHhisRtI728AyFPtNUWrxfT4uFamtXv+jTn6FuyKKdk/piAIt7xL+Pqj9i/Tl2GGZ53u922PRv9dx6zebrmC10F9/zr/PtFtDwuJNXkxpMX+405dMfDMRJKeOllOXAMqCus1YCZsekO3DqXBbj4OBAVlbWJS0klwtSSrKysnBwaFrxpgvNR5vjeWrFfr7emVTv2Iaj6UxeGEVRWRWjvSyx/Ff55vL+jP7cOeI0qHoAACAASURBVDyMz6JOMvl9JcLDOtbxy+5dqjIfRz4OVWX0tz3Bgun9eO66cBWF8uUU1TCh7oYi1A6xOxNmsawbvjfyMUBY3C0tjavJfTTy8fouDmdvtY52nS2uI6j9q8KMg4d6dPGtf0xzQWmKyyUQsP5fkwzUSQNjHrBWCPEQ4Axc1dCFhBD3AvcCdOhQPxY1KCiI5ORkMjIymrAsTUvj4OBAUFATBOoiEHVchX2+/GMMnk5Ggr2ccHWw5YttCXy69QTd/d34aOZAsrccBlPnvn6OaTgYDbxwQw/6dvDg8eV7cbYz0CvQvfbF0w6qWOxhD6iU84St3DDKlAxz9BflpigvUrWyAQz2qvmCs6+lBvfZ8AqDyYvr1zvx7gK3fK6ShC4EvaYoV1D4xIaPT3xXJfm0s/rF0VAThxoL/ezJdpqWp7miXKYDn0kp3xBCDAOWCCF6SSlrBfJKKRcDiwEGDhxYzww3Go01GY4aTV0Ss4rZnZjNFV19iTmdz+1DO/DzgdSaHpWgDM3pgzvw/HXhONnZ0t6YSjlGJALn/PiaeRMjAgjxciKvpAKjoc4PVfPmn5OXEldzmzMplcCD6o7jG6426hy9IOtYw2J3JiKmNTzeo/E6Qc2Gk5cKmTwT5rriUiorvKzAYtVb42iy0M8W4aK5IDRF0FMA63+pQaYxa+4CJgBIKbcJIRwAbyAdjeYM/LHiVYSsou/UZ5o0/5XVMaw5lMadw9WX/uR+gTx5dXfi0gvJLCwjq7CciGB3egZYLG6brFjw7oJA1GvmG5H5E6Qdgq51GhvkJak4clCbg/v/q+LAk7arqA/fHpAeo8518VPJNVnHmuZuaY0IoXpn5p8GmwaaYdRY6FrQLzZNEfRdQBchRBhKyG8FbqszJxEYC3wmhAgHHADtN9GcESklDoeW4SuzkFP+D1FnMy2/tIKHlv5BSXkV/UM8uXN4KL8dVvbBJ1tP4GxnoE+QB0aDDQNCzpIYlXEUu8ABSpTMIXigrM01zypfec/JEDzIvDAVytd1gnodEgnR/1GJNUd/Vu6VK5+HZbeZ6qSMtPiVG/IvtxWGP6zi4RvC0VNVFmyBHpmaP0ejm6JSykrgQWANcBgVzXJICPGSEMLsfHscuEcIsQ/4Gpgl9c6m5izEZxbhWp1HO3JJjDtY7/hbv8ay+VgG5VXVfLjpODM/3UVltWRWZCgAg8O86rtK6lJerLIbfbqpDb7cJDUGsOs/SsyNzhY3CqhMzcpSy4aluZBU4ja18Rk0UEWFgKqo5+JncbWcqUZJW6D7dSrpqCGEgLF/szSf0Fw0muRDN8WUr64z9oLV8xjgDDUxNZr6RMVlMgWVLp6ybx3BnXuzZGsccuO/iQmaxorYcm4b3IH5N/ZizpJoOhz9hM5BV/HsteEkZhdzy8AmWMNZxwCpaogIU53uzFjw6a4aMHe6UqW6b5gPp/ep7jl1+2G6BaiQwtg1as7Ix5RrxegMFUXKb2xOU2/LFrqmVaBT/zUXlGdXHsDJaCA9O4c7RBkAIiGKuctGk3BgKz/Y/4//ncziN6e/8uTV3RBC8NqE9rjFLyXZzxU72yl8MmtQ026WYUqe8umuaoMDnN6rXAdF6TDkfhVLHfWu6gV5yxdWHeutxDlkuOpIDyrkUAgVkXJ6r4rsCB2u5gQ1cV0aTQuhBV3T4hxJzcfTyQ4hYNnORKoldLDJBDuowkBQwV5+3H+ad/s5wWG42bCFK+98Aw8nJcJu5SojM6iyfsz5Wck8qmqRtOukBN3ZR7lN3INVVmNIJNi7qHT8LW+qTVNzZUNrazskUgm6MFiSaXy6mwTdV1nssy+LxGjNJY6u5aJpUcorq7l18Xbu/SKa1ftPUy2hs68LbjIfgGzvgQSLDK4LqeL6TiqCQlRX0G7fB5aL5JrcIOYolbjfLGVfj/2q0uX3fq02NCtKVd9KKdV8zzBV/0MIJcwJ25Q/vH2EEnOAoX9VXWe2vKksdHs3SygeWPzo7SMsBabMxbNcdey15tJBW+iaFuX3uAxyiyvILc7jZFYx3fxc+ezOQaz9/hjEg1vEDfDbDuYPrsTGLNLdr4eYVaquB1is5pwTqtP8VzfDgNlw9T9UO7ZKUzOP9n0gaQf8+KiKl86MVRuiZkKGqyqH+SmqYJYZZ291vR0fqpDEur5wzzAl5uE3WMZCR6kY9AuV1anRNAFtoWtalB/2ncbd0UgnH2fySiqY2DeA9u6OzIxQlq59iHJheFakqVR6Ry8VRVKYqqxtsPi1ZbWqgSKrlevk1B4l5uNfUccTouCkqabKiU2qAYN3V8tizCn3sqp+G7TIh1SMddqB+glCQsB9m02p+SaCB8FT8eDic74fkUbTbGhB1zQfWcfJzcvldF4JZJ+gtDCXtYdSuaaXP89dF467o5GJEabiS8WZ6tG7i6oRnptkamlmFQaYb8pfy0tS8d8Auz9TjxmH4fAP6nnf21RFwJO/W2qq7F2qSsZaW+h+PcHelHRkXXwKLCVsoe0mCGnaPNrlomkWCgvzMSyI5KvK8SyQt3LI9QEyPQdRVD6LGyICGN7Zm30vjrecUJylNhkdPExdeRJVOVpXP4ug5iaqDc3cJAgZprrn5CYoH3dZvhJ33x4qhT0kUnUBqihWx3NNrQKtXSI2Bug0Wl23ocp9wx9RXwQ+TetKpdFcamgLXdMsLF+5EkdKmeJxnAhjEobSHIJOr+V6/1yG1q1mCCqBx6mdKrfqHmyy0NNVGKDZh232neclKdeJOXGn/1/A1kGJt9l1EhKpXgMMvtdyH+8ute876X2447uG34RnCDy8X/nTNZpWiBZ0zblRXa260ANRxzPJO6J6T/oXHeGZLkqIS6WRf/j8isGmgfr2xVmWdmIewcpqLjRZ6G6BgFAp+CW5yhp3D7K4TzqOscR81wi6Ka/N0RMG3qmeuwWqdmrW2LvUjmCpi6tfw/05NZpWgBZ0TaNUVlWzaNNxcovLLYNbXof3h1JcVsH/fbOfUfaxSBsjyCoiUpaRaQwgofPtuMV9r7rz1KU4y9Lw1z1IdfGpKlc+dFs7FaWSm6REHZTV7tcTbGxVLHjoCECoTE9QFryzrxJ290DVxsy3R4t+LhrNpYYWdE2jRB3P4p8/H2HJtoSasfITWyH7OO/+dzVpOQX0FccQEdNA2CCKM/HuMZpuNz6tGiH//lb9ixZlWvzY1h3ezRX7zN3uzW4Xjw6qQNSda5XVPewBmP2z2swEFYlyx0pLqOP0ZXD9m838SWg0lzZa0DWNYm4m8fPBVKqrJe+sO0bmiQMA5B3dxNN9SjFUlUKX8SpeG5QrxNVf+bv3fm2xtM0UZ1n6T1qHCZoTddxNbphcq8xNR08IGqBe27uqjVJr/HtZWpj5dG3bxbI0mgbQgt6WOfQdfH6Dypr8s+QmwXuD4PQ+oo6rEMPI9K859v5UFq/bR4BQIv9Mj2xmtz+pzukwzOLLNvu2hz8MSFgwAN7sqa5bXQUlOVYuFytBt7bQ81NU+r7BXqXtazSas6IFvS1zYrP6U3D6T51WVllFxZFfIDOWinXzOZiSx5T+QUwxbKZLxjpu9jW1jLV3wy11OyL6PxB2haprMvSvcMM74NVRzfEIhsmL1EZlYRpsfVuJOdKyKeraXoUwgkXQ3YNVedo9S6Dr+PNvPqzRXAbo/yVtGXMT44wjTT5FSsmMj3bw68/fAmA8vpbunGR6bxfCbZKwEZJHvEwt2fpMU18WhWkw6kk15h6o2ppZNx3ufTNM+KdKANqzRPXsBIugG2xVRIrRyVIrxewuqSpTzRM0Gk2jaEFvaxxbB+vmqec1gh7b+Hlb34HoT/npwGmiE7IZajjK5uoI8qUjDxlXESEP10z1TFyrok36zVADwUNMUSeNMOIRlb35zT3qtZNVfLpHsLLOzV8EZjdM53EQ0Lfxa2s0Gp0p2ub44ws4/COMed5SkTDzaINTC0oryCwsx2gQBG5bCGUFLLL1YoxPKV4FWfQZ+yS7Dx5iQsaXiL0eqgStX0849YfKpvSPUEk8EdNrW+RnwqsjXDUPjm8A+6EQ2N9ybMh9tVucteusEnyGzDnnj0KjudzQgt7WyDiqik8VnFKJOtCghV5WWcW1724hKbsENwrZ76DEf1zJt4wfPhR2gEf4aMYMnApvrYDYX1TMd8gwJejeXZVf2xwm2FSGP2zaKK1D3W73Blu44e0/d22N5jJHu1wuFfZ+rVqcnQ9VlarCIEDqQZWoI2watND/uyuJpOwSnry6G2+McQSgyOjFA46/0f3EElX10LubikQZaEqFD4m0RK/46LKxGs2lhhb0S4WfHoNNr57fNXJOKB81WDrct4+Aogwozq6ZVlpRxXvr4xgc6sVfR3dinE8uAM5T3sPg0k5lbfb/iyWyJHIuBA6EnjdaQhO7XH1+a9VoNM2OdrlcCpQXq8JSCVEqZrwp/uiGyLCyxFOi1WPYFcpFkhkLHYay/kga//r5COkFZbw7vR9CCHWerQN0naC6u9fFrT3c85vltW63ptFckmgLvSWQEo6srile1Sjm2uAl2bVFuS6pByHtUP3xnJOQtMsSnmjnAil71POwkeoWKYfIL61gzpI92FcV8uOQIwxNXw6Zceqe7bqo8rIajabV0iRBF0JMEEIcFULECSGebuD4W0KIvaY/sUKI3OZfaisiPQaWTVftzpqCdXRHwtaG51SUqtZr395X/9iGf8AXE1WvTLdAFSFSXgjAr3nB5EgXjv3+Db8eSqO8qpoPu++n176X4Jen4Zs7lY/dp2v962o0mlZFo4IuhDAAC4FrgB7AdCFErTJ2UspHpZR9pZR9gQXAty2x2FZD9gn1mHOyafOLrAQ9cVvDc/Z+pZJ40g6aMi2tKExTLpu4daa64SqGu9rWkUdXneDL6quJKNrKhs0bCfRwJCDvD2WRX/em2ojNTdS9MTWaNkBTLPTBQJyUMl5KWQ4sAyadZf504OvmWFyrpaYxQ2LT5pstdP8+qo1a/EZVBxwg/5R6vfVtVZwKCYk7ap9v9YVw2i6EbVlOACRXuGFvayByxvMUSgfGZ3/J9b19EYnbIXS42vg0J/DoqBWNptXTFEEPBJKsXiebxuohhAgBwoD1Zzh+rxAiWggRnZGR8WfX2nowVwjMTTr7PDNmH3qvKcoK/2ISrDal0n91i3qdm6hqpBjs6rtlijMhoB9SGFh4xIm1p+zUsH07fnhoBAO6d2Sr541cZ7Od6a77oCxPRaoYjKbGxwL8e5//+9ZoNBeV5t4UvRVYIaWsauiglHKxlHKglHKgj08brp5ntszzmijoRZkqlX7YA3DXOlWG9sRmNZ52QGVj3rdZJd8E9IeEKKJPZrPhaLragC3OojpkJHe5f8wPjOL+iaMB6Na5CwEeKsa8x5RnkAY7QqKeVfc0N0keMBvm/qF6d2o0mlZNUwQ9BbCqb0qQaawhbuVyd7eAxTLPS25a6VpzOzaDEYIHqfDBwlTlNwfodXOtOuPy9F6eWrqNh5b+QVFBDlSVc6LEkfWp9syb1BvfYNVHU7j419wiODgU24GzEKW5qqGEuQa5EOAV1lzvXKPRXESaIui7gC5CiDAhhB1KtFfVnSSE6A54AmfY1buMyEtSFndlqUrqaQzr/ppgqSke9Z6KDw/oV+uYqK6kU2E0hWWVrNutimbtSLPBzcGWa3u3B48QlSHqXsczNnyu6iAUOvw836BGo7kUaVTQpZSVwIPAGuAwsFxKeUgI8ZIQYqLV1FuBZVKeSzeFNkR5sRLo9qYKgU3xo9cVdJ9u6nVRumqGbGtXc0iGjSTNxoeHHVcT7u/K+t0xAGxOqeba3u2xtzWoJsgzf6zfvd49CGb9BGNfPN93qdFoLkGa5EOXUq6WUnaVUnaSUr5iGntBSrnKas48KWW9GPXLDnOrNXPNk6ZEuhRl1hZ0ISw+7pDa1vSGuFzeK7uOXlVHeLxrBgXZqgDX6QpnJvYNsEwMHV6/4z1AhyGWPpwajaZNoTNFmxuzgJuFuKkWurkdmxnzF4JV38zqaslra2LZ5nYN0sWPMVlfc2UHld1p5+rDkLB2aDSayxddy6W5MQu4X0+wd2s80sXcX9Opjhj3vQ2qKiDE0jjixwOnOXw6n7en9UUkX4Mh5ntuHzESUmHR/RMw2JxjDRiNRtMm0BZ6c5OXpPpjurY3da5vRNCLs1H9NetY6I6eqsOPQX3nZhaW8cpPMXT3d2ViRIBqMFGSo+qwGOzw8vBsmfej0WhaDdpCby4KM+D7B1QqvVugEmKPYJX5+flEGP8y+PaAnx6HATMhcIA6z5wl6uRV75IVVdXM+GgHuSXlOBoN5BZX8MmsQdjYCJXiDyrJyMn73Cs0ajSaNoMW9OZi69sQ96vq6tPVVCu8721QVqjK1677u2qWvOdzJb41gm7KEq3rQwc+2HicnSez6eDlRGxaIa9O6UPPAHd10Jyqn3NSZ3lqNBpAC3rzUJQF0Z9C76lw02LLeI9J6s/vb6nGzakH1HhClGVOjYVeW9D3JeXy7m/HuCEigHdv7cupvFICTVmfgPoVYOeiqirW9b9rNJrLEu1Dbw52fAAVRTDisYaPD7wLHNxVXHngQNVsotCUcFRkstCtRDkhq4i7Pt+Fv7sDL03siRCitpiDsvK9u5jOrW/dazSayw8t6OdLaR7sWAzhE8G3e8NzHNxgzPPQ+SoYP1+NJZqs9GNrVf9OZ1Xbpqpacu8Xu6mslnx+52A8ne0aviZYSt5qC12j0aBdLufPzo9U9cJRT5x93pB71Z/KcrB1hIRt4BkGsb8osTdFs/y4/xRH0wp477Z+dPJxOfs1zU0pGvC/azSayw8t6OdDeRFsf19VRzQXz2oMWztVgCv2F9Wswt6NyoF3M/er3Xi72BN1PIuufi5c26sJ2Zw+pl8E2kLXaDRoQT8/dn+mNjVHNmKd16XL1bD2Ocg5wYmeD/LbnhxWH0hFCFWcccH0fio0sTEC+oHRSYVDajSayx4t6OdKRSlELYDQkao+yp9h2APsch/PfUt2k7PHFaPhKFeF+/L4+G5En8xWFRObglsAPJMCNnorRKPRaEE/d8w9Pid/+OfPFYJF0Xng7M3ELt5sjs1g3sSeBHk6Ed6+gYJaZ0OLuUajMaEF/VzZ9R/VPSjsij99anxGIesOpzN3bBceG9eVyqpqbA1amDUazfmhVeRcKMqC9EMQfv05pdy/te4YdrY23DE0BECLuUajaRa0kpiprm763ERTU6aQP9/5Z1NsBj/sO8X9V3TCx9X+T5+v0Wg0Z0ILOkBFCbzRDXZ93LT5CVFgsK/dGq4JJGUX89zKA3T0dub+0bops0ajaV60oANkHlNp+ZteVdErjZEYZWoN13QLe2tcJhPf+528kgpemxqBg9FwHgvWaDSa+mhBB1VTHKAwDf5Ycva5ZQWqRK65o1AjSCn5eEs8d/xnB94u9qx6cAQDQnTtco1G0/xoQQfIPArCRkWtbH1XZfeY+d8slUBkJiEKZHWTBf39jceZ/9NhxvfwZ+UDwwnzdm7WpWs0Go0ZHbYIykL3DIOBs2HVQ6oaok83VXfl0HcQvxF63Qz2LrBtIbj4WZo4N8Cp3BKe/vYA+SUV7E3KZXK/QN6YGtG07E+NRqM5R7SFDhYBN0etJGxVj/kpgFSt3nZ/Ckk74cQmiHwIjA4NXqq0oor7luxm98lsHIw2zIoM5dWb+2gx12g0LY620KsqIes4dJ0AXh2V9Z0QBQPvtDR4dvSETa+Bo7t6PmB2vctEHc/kuZUHySosI7+0ko/+MpBxPfwu8JvRaDSXM02y0IUQE4QQR4UQcUKIp88w5xYhRIwQ4pAQYmnzLrMFyTkB1RXKQhdC+cYTopQf3dzg+drXwa8nuPjD1f9UrhcrNsVmMPvTXQgB10cEsGB6Py3mGo3mgtOohS6EMAALgXFAMrBLCLFKShljNacL8AwwXEqZI4TwbakFNzvmCBdzj86Q4XBoJeQmWiz08BtUP9AGqK6WPLfyAKHtnPn63qF4na0hhUaj0bQgTbHQBwNxUsp4KWU5sAyYVGfOPcBCKWUOgJQyvXmX2YJkHFGP3qZmEebolYQoZaG7+J813nx3Yg7JOSXMGd1Ri7lGo7moNEXQA4Ekq9fJpjFrugJdhRBbhRDbhRATGrqQEOJeIUS0ECI6IyPj3FbcnEgJMd+rRhH2rmrMJxwcPNTGaF4ieASf9RLf/ZGCo9HA+B7+F2DBGo1Gc2aaK8rFFugCjAamAx8JITzqTpJSLpZSDpRSDvTx8WmmW58Hx36F1P0qasWMjY0KSUzcpix094YFvbSiiuMZhfx04DRX9/TD2V7vL2s0motLU1QoBbBWtSDTmDXJwA4pZQVwQggRixL4Xc2yypZAStj8mhLsPtNqHwuJhNifQRigx8QGTpXcsmgb+5PzAJjcP+hCrFij0WjOSlMs9F1AFyFEmBDCDrgVWFVnznco6xwhhDfKBRPfjOtsfnJOQvJOGDIHDMbax8zx6LKqQQt9e3w2+5PzuHtEGF/eNYRRXXSTZo1Gc/Fp1EKXUlYKIR4E1gAG4BMp5SEhxEtAtJRylenYeCFEDFAFPCmlzGrJhZ835s3QoEH1j7XvA0ZnqChqUNA/3XoCTycjT1zdTRfZ0mg0lwxNcvxKKVcDq+uMvWD1XAKPmf60DmrCFbvWP2YwQvBgiN9Qb1N0f3Iu6w6ncf/oTlrMNRrNJcXlu5OXGauyQh3PUPmw42hIiKLIMYDYxBziM4rYGpfJd3tT8HSy446hoRdwsRqNRtM4l6+gZxy1xJ43xNC/Ut7lGq75cC+J2cUAuDnYMmNICI+N64qnjjnXaDSXGJenoEupLPQ+t5x5jq0dP592ITG7mBeu78HILt508nHRRbY0Gs0lS9uvtph1HP4VoppSmCk4DWX54N3trKd+uT2B0HZOzIoMpYufqxZzjUZzSdP2Bf3YWijNhdg1lrEzbIjml1ZwLK0AgCOp+ew6mcOMISFayDUaTaug7btczLXNzY+g3C2gUv5NxKYVcPfn0ZzKLWHdY1eweFM8DkYbbh6gk4Y0Gk3roG0KevoR1XloykeqyBao5hR5yfD1rZCTCPbuKsoFKC6v5JZF2zAabDAabHhqxX6iE7K5e2RHvfmp0WhaDW3T5bLxHyoL9LsHoDgLOl8FFcXw7X2Qdgi6XQPjX1L1z4E9CbnkFlfw6pQ+zB4eys6T2TgYDdw3quNFfiMajUbTdNqehZ5xFGJWqfjyhN/V2MgnIG6det1nGty0qNYpO05kYSNgUJgX/UM8+d/uZO4YGkI7lzOXzdVoNJpLjbYj6NknYO3zStCNjnD7t/CfceDUDjoMhXadISsORtRPZt0Rn02vQHdcTBUTtz19JQa9EarRaFoZbUfQN7yiyuH6hsPYFyGwP1z5N5XGLwQMe1CFK/p2r3VaaUUVe5NymRkZUjNma2ibniiNRtO2aRuCnnUcDn4Dwx6A8fMt4yMesTwfWL+xM8DepFzKq6oZEtauhRep0Wg0LUvbMEW3vg02Rhj2UONz67D2UBpCwKBQrxZYmEaj0Vw4Wr+FLiUc/gF63QSufk0+raS8ii+2neSTrSe4qV8g7k7GRs/RaDSaS5nWL+hFmVCSA/59mnzKwg1xvL0ulooqyTW9/Pn3zU0/V6PRaC5VWr+gmxtV+Jy9LouZo6kFvPlrLCO7eDNzWCgju3jrTVCNRtMmaP2Cnmmuy9K4oEsp+dv3B3F1sOWtW/rqLFCNRtOmaP2maUYs2LmAW2CjU6MTcth5IpvHx3fTYq7RaNocrVfQS3KgqkJZ6N5datL4z8baQ6nYGWy4sW/ABVigRqPRXFhar8tl8RgIHaEs9LBRjU6XUrI2Jo3Izu1wddARLRqNpu3Rei30glTYuxQKTjXc6LkOR9MKSMgqZnwP/wuwOI1Go7nwtE4LXUqoLAWket1I56HSiiq+3pGIEHBVD9+WX59Go9FcBFqnoFdVABIM9lBVpuq3NEB1teTrXYm8+stR8koquCrcF19Xhwu7Vo1Go7lANEnQhRATgHcAA/CxlPJfdY7PAl4DUkxD70kpP27GddamslQ9Dn8YvLtCu04NTnvqm/2s2J1MZKd23D+6E8M66notGo2m7dKooAshDMBCYByQDOwSQqySUsbUmfpfKeWDLbDG+pgF3dUP+kxtcMrR1AJW7E7mzuFh/O36cEQTomA0Go2mNdOUTdHBQJyUMl5KWQ4sAya17LIawSzotmd2nyzcEIeznYGHruysxVyj0VwWNEXQA4Ekq9fJprG6TBFC7BdCrBBCBDd0ISHEvUKIaCFEdEZGxjks10RlmXo8g6AnZBXx4/5T3D4sRCcQaTSay4bmClv8AQiVUvYBfgU+b2iSlHKxlHKglHKgj4/Pud+txkJvuEXcj/tPUy1hVmToud9Do9FoWhlNEfQUwNriDsKy+QmAlDJLSmkym/kYGNA8yzsDNRa6Y4OH1x5KpW+wB+3dGz6u0Wg0bZGmCPouoIsQIkwIYQfcCqyyniCEaG/1ciJwuPmW2AAVJeqxAQv9dF4J+5LzGN+z6bXRNRqNpi3QaJSLlLJSCPEgsAYVtviJlPKQEOIlIFpKuQqYK4SYCFQC2cCsFlzzWX3o62LSAHRGqEajuexoUhy6lHI1sLrO2AtWz58BnmnepZ2Fs/jQVx9IpaOPM519XS7YcjQajeZSoHXWcjlD2OLBlDy2xWcxpX/QRViURqPRXFxat6Abawv6e+vjcHWw5Y5hIRdhURqNRnNxad2CbmWhH0sr4JdDqcyODMVNl8fVaDSXIa1U0M2bohYf+oo9ydjaCGbq2HONRnOZ0koFvbaFLqXkp/2nGdHFm3YuDScbaTQaTVundQp6RSkgwKDS+vcl55GcU8J1vduf/TyNRqNpw7ROQa8sVda5qejWT/tPYTQIHXuu0Wgua1qpoJfV8p//diSd4Z29cXfSY7mscwAACrpJREFUm6EajebypZUKemkt/3lKTglddCKRRqO5zGnFgq4s9PzSSsoqq/Fz063lNBrN5U3rFXSjqqSYnq8iXnxcdXSLRqO5vGmlgm7xoacXqJh03fxZo9Fc7rRSQbf40NMLlIXu56YtdI1Gc3nTOgW9wuJDT8s3Wejah67RaC5zWqegV5bWdCtKzy/Dyc6Ai32TKgFrNBpNm6WVCrq1D71UR7hoNBoNrVbQrXzo+WU6wkWj0WhotYJe20L31YKu0Wg0rVXQS6yiXMp0yKJGo9HQagW9DIwOFJZVUlxepUMWNRqNhtYo6FLW+NDTTFmivlrQNRqNphUKenUlyGqwtSc9X2eJajQajZkmCboQYoIQ4qgQIk4I8fRZ5k0RQkghxMDmW2IdKkrUo62DzhLVaDQaKxoVdCGEAVgIXAP0AKYLIXo0MM8VeBjY0dyLrEVNP1EHtsdn42RnIMjTqUVvqdFoNK2Bpljog4E4KWW8lLIcWAZMamDey8C/gdJmXF99TP1EK23sWX3gNON7+OFgNLToLTUajaY10BRBDwSSrF4nm8ZqEEL0B4KllD8149oaxmShH84oJ6+kgkl9Axs5QaPRaC4PzntTVAhhA7wJPN6EufcKIaKFENEZGRnndsNK5UPfkVSEp5OREV28z+06Go1G08ZoiqCnAMFWr4NMY2ZcgV7ARiHESWAosKqhjVEp5WIp5UAp5UAfH59zW7HJQt+XWspV4X4YDa0vUEej0Whagqao4S6gixAiTAhhB9wKrDIflFLmSSm9pZShUspQYDswUUoZ3SIrNvnQcysMtHPR0S0ajUZjplFBl1JWAg8Ca4DDwHIp5SEhxEtCiIktvcB6mAS9qNKAo94M1Wg0mhqaVERcSrkaWF1n7IUzzB19/ss6CxVK0Muww9FOu1s0Go3GTOtTRJOFXopRhytqNBqNFa1Q0NWmaJkWdI1Go6lFKxR0k8tF2mkfukaj0VjRegVdW+gajUZTi9Yn6EZHypwDKcOoLXSNRqOxovUJ+sA72TFpk45y0Wg0mjq0SkUsragCwN5WW+gajUZjplUKeolJ0B3ttKBrNBqNmVYp6GYLXfvQNRqNxkIrFfRqAB3lotFoNFa0SkEv0Ra6RqPR1KN1Cnq5eVO0VS5fo9FoWoRWqYillVXY29pgYyMu9lI0Go3mkqF1Cnp5lY5w0Wg0/9/e/cbIUddxHH9/cqUQK4qVhjZtj15JNSmaQNMgD4AHSmqvKoeakBITSyBpSGgCIUZragjxGRh5YNJIMDaiAUuMEu8BRtQQjQ/4U+qVtkDpUWtoc7SKxpp4512vXx/Mb8vsdPd6197O7CyfV7LZ2d/NdT/5zuz3ZmZ/27WCWjb08alpLvMcdDOzJrVs6BNTZ3yEbmZWUMuGPj417SmLZmYFtWzoE1PTXHZJLaObmXVMLbvi+OS056CbmRXUsqFPnHZDNzMrqmVDH5/0NXQzs6JaNvSJqTNu6GZmBTVt6NP+cgszs4JZdUVJGyUdkjQqaXuLn98rab+kEUl/lrR2/qO+zx8sMjM713kbuqQ+YCcwCKwF7mzRsJ+OiE9HxHXAo8Bj8540iQjGp/zRfzOzotkcod8AjEbEkYiYBHYDQ/kVIuJU7uEiIOYvYrPJ6TNE+P9CNzMrWjCLdZYD7+QeHwM+U1xJ0n3Ag8BC4LOt/iFJW4GtAP39/XPNCsDEpL/cwsyslXl7ZzEidkbENcC3gO+0WeeJiFgfEeuXLFlyQc/jL7cwM2ttNg39OLAy93hFGmtnN3D7xYSaydnvE/UsFzOzJrPpiq8AayQNSFoIbAaG8ytIWpN7+AXg8PxFbNY4QvcsFzOzZue9hh4RpyVtA34L9AG7IuKgpO8CeyJiGNgm6VZgCvgXsKVTgc82dM9yMTNrMps3RYmI54DnCmMP5Zbvn+dcbU34GrqZWUu1uxDdaOie5WJm1qx2DX08TVv0EbqZWbPaNfT3j9BrF93MrKNq1xU9D93MrLXaNfQJz3IxM2updg29f/GHGPzUUh+hm5kVzGraYjfZcO1SNly7tOoYZmZdp3ZH6GZm1pobuplZj3BDNzPrEW7oZmY9wg3dzKxHuKGbmfUIN3Qzsx7hhm5m1iMUEdU8sfR34G8X+OtXAv+YxzjzqVuzOdfcONfcdWu2Xst1dUS0/FLmyhr6xZC0JyLWV52jlW7N5lxz41xz163ZPki5fMnFzKxHuKGbmfWIujb0J6oOMINuzeZcc+Ncc9et2T4wuWp5Dd3MzM5V1yN0MzMrcEM3M+sRtWvokjZKOiRpVNL2CnOslPSCpNclHZR0fxp/WNJxSSPptqmCbEcl7U/PvyeNLZb0O0mH0/3HSs70yVxNRiSdkvRAVfWStEvSSUkHcmMta6TMD9I+95qkdSXn+p6kN9NzPyvpijS+StJ4rnaPl5yr7baT9O1Ur0OSPt+pXDNkeyaX66ikkTReSs1m6A+d3cciojY3oA94G1gNLAT2AWsryrIMWJeWLwfeAtYCDwPfqLhOR4ErC2OPAtvT8nbgkYq347vA1VXVC7gFWAccOF+NgE3AbwABNwIvlZxrA7AgLT+Sy7Uqv14F9Wq57dLrYB9wKTCQXrN9ZWYr/Pz7wENl1myG/tDRfaxuR+g3AKMRcSQiJoHdwFAVQSJiLCL2puX/AG8Ay6vIMktDwJNp+Ung9gqzfA54OyIu9JPCFy0i/gT8szDcrkZDwE8j8yJwhaRlZeWKiOcj4nR6+CKwohPPPddcMxgCdkfE/yLir8Ao2Wu39GySBNwB/LxTz98mU7v+0NF9rG4NfTnwTu7xMbqgiUpaBVwPvJSGtqXTpl1lX9pIAnhe0quStqaxqyJiLC2/C1xVQa6GzTS/wKquV0O7GnXTfnc32ZFcw4Ckv0j6o6SbK8jTatt1U71uBk5ExOHcWKk1K/SHju5jdWvoXUfSh4FfAg9ExCngh8A1wHXAGNnpXtluioh1wCBwn6Rb8j+M7ByvkvmqkhYCtwG/SEPdUK9zVFmjdiTtAE4DT6WhMaA/Iq4HHgSelvSREiN15bYruJPmg4dSa9aiP5zViX2sbg39OLAy93hFGquEpEvINtZTEfErgIg4ERHTEXEG+BEdPNVsJyKOp/uTwLMpw4nGKVy6P1l2rmQQ2BsRJ1LGyuuV065Gle93ku4Cvgh8LTUC0iWN99Lyq2TXqj9RVqYZtl3l9QKQtAD4CvBMY6zMmrXqD3R4H6tbQ38FWCNpIB3pbQaGqwiSrs39GHgjIh7Ljeeve30ZOFD83Q7nWiTp8sYy2RtqB8jqtCWttgX4dZm5cpqOmKquV0G7Gg0DX08zEW4E/p07be44SRuBbwK3RcR/c+NLJPWl5dXAGuBIibnabbthYLOkSyUNpFwvl5Ur51bgzYg41hgoq2bt+gOd3sc6/W7vfN/I3g1+i+wv644Kc9xEdrr0GjCSbpuAnwH70/gwsKzkXKvJZhjsAw42agR8HPgDcBj4PbC4gpotAt4DPpobq6ReZH9UxoApsuuV97SrEdnMg51pn9sPrC851yjZ9dXGfvZ4WveraRuPAHuBL5Wcq+22A3akeh0CBsvelmn8J8C9hXVLqdkM/aGj+5g/+m9m1iPqdsnFzMzacEM3M+sRbuhmZj3CDd3MrEe4oZuZ9Qg3dDOzHuGGbmbWI/4PH/kgFKNDLn8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOZO8WoksN-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b147e705-cc32-4d2f-a3ad-2b433c268368"
      },
      "source": [
        "predicted = model.evaluate(x_test,y_test) "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 0.8116 - accuracy: 0.8088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuUdDoAw7tW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "149c38ec-0d17-420d-e405-302617f4e990"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 875       \n",
            "=================================================================\n",
            "Total params: 20,287\n",
            "Trainable params: 19,865\n",
            "Non-trainable params: 422\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku0AbAb-2aO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d6d1102-3d61-446c-d1c9-32f262de4d6c"
      },
      "source": [
        "export_path = os.path.abspath(os.getcwd())+'/models/saved_model'\n",
        "model.save(export_path, save_format='tf')\n",
        "export_path"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/models/saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/saved_model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apKivJ06mkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "e4495877-1bc0-46bf-9eef-362d2d799403"
      },
      "source": [
        "test_data = pd.read_csv('testing_data.csv')\n",
        "ab = np.array(train_data)\n",
        "b = ab[:, -1:]\n",
        "a = ab[:, 0:-1]\n",
        "a = a/a.max(axis=0)\n",
        "print(a.shape)\n",
        "print(a)\n",
        "print()\n",
        "print(b.shape)\n",
        "print(b)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3668, 87)\n",
            "[[0.         1.         0.         ... 0.04481434 0.         0.19512195]\n",
            " [0.         1.         0.         ... 0.00640205 0.         0.0195122 ]\n",
            " [0.         1.         0.         ... 0.00640205 0.         0.29756098]\n",
            " ...\n",
            " [1.         0.         0.         ... 0.00256082 0.         0.01268293]\n",
            " [1.         0.         0.         ... 0.00256082 0.         0.        ]\n",
            " [0.         0.         1.         ... 1.         0.         0.        ]]\n",
            "\n",
            "(3668, 1)\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [4.]\n",
            " [4.]\n",
            " [2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2U7Ye147VpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "bb6f306a-88bb-4517-e673-1b3854e52c3a"
      },
      "source": [
        "import_path = os.path.abspath(os.getcwd())+'/models/saved_model'\n",
        "reloaded_model = tf.keras.models.load_model(import_path)\n",
        "reloaded_model.summary()\n",
        "reloaded_model.load_weights(checkpoint_path)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 875       \n",
            "=================================================================\n",
            "Total params: 20,287\n",
            "Trainable params: 19,865\n",
            "Non-trainable params: 422\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ffa3a097358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6W0kh__TIGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "31f9d9d6-357c-4a0e-875d-dc12fd5753de"
      },
      "source": [
        "non_trainable_layers = len(reloaded_model.layers)-1\n",
        "for i in range(1,non_trainable_layers):\n",
        "  reloaded_model.layers[i].trainable = False\n",
        "reloaded_model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 875       \n",
            "=================================================================\n",
            "Total params: 20,287\n",
            "Trainable params: 8,531\n",
            "Non-trainable params: 11,756\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT22E6FsT0rO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb59220c-b1e2-4143-c915-ca245b547909"
      },
      "source": [
        "reloaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "reloaded_model.fit(a, b, epochs=100, verbose=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9212\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.9076\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9130\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9193\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9174\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9155\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9220\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9185\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9261\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9226\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9204\n",
            "Epoch 12/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9207\n",
            "Epoch 13/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9248\n",
            "Epoch 14/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9179\n",
            "Epoch 15/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9201\n",
            "Epoch 16/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9223\n",
            "Epoch 17/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9218\n",
            "Epoch 18/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9283\n",
            "Epoch 19/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9269\n",
            "Epoch 20/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9275\n",
            "Epoch 21/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9245\n",
            "Epoch 22/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9250\n",
            "Epoch 23/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9253\n",
            "Epoch 24/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9174\n",
            "Epoch 25/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9294\n",
            "Epoch 26/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9308\n",
            "Epoch 27/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9308\n",
            "Epoch 28/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9278\n",
            "Epoch 29/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9234\n",
            "Epoch 30/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9288\n",
            "Epoch 31/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9253\n",
            "Epoch 32/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9278\n",
            "Epoch 33/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9294\n",
            "Epoch 34/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9215\n",
            "Epoch 35/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9245\n",
            "Epoch 36/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9256\n",
            "Epoch 37/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9288\n",
            "Epoch 38/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9291\n",
            "Epoch 39/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9327\n",
            "Epoch 40/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9294\n",
            "Epoch 41/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9310\n",
            "Epoch 42/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9291\n",
            "Epoch 43/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9335\n",
            "Epoch 44/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9286\n",
            "Epoch 45/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9348\n",
            "Epoch 46/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9327\n",
            "Epoch 47/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9220\n",
            "Epoch 48/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9272\n",
            "Epoch 49/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9261\n",
            "Epoch 50/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9305\n",
            "Epoch 51/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9318\n",
            "Epoch 52/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9288\n",
            "Epoch 53/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9272\n",
            "Epoch 54/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9256\n",
            "Epoch 55/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9297\n",
            "Epoch 56/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9250\n",
            "Epoch 57/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9286\n",
            "Epoch 58/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9340\n",
            "Epoch 59/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9269\n",
            "Epoch 60/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9357\n",
            "Epoch 61/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9278\n",
            "Epoch 62/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9310\n",
            "Epoch 63/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9286\n",
            "Epoch 64/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9324\n",
            "Epoch 65/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9327\n",
            "Epoch 66/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9291\n",
            "Epoch 67/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9411\n",
            "Epoch 68/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9283\n",
            "Epoch 69/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9348\n",
            "Epoch 70/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9299\n",
            "Epoch 71/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9373\n",
            "Epoch 72/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9346\n",
            "Epoch 73/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9384\n",
            "Epoch 74/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9357\n",
            "Epoch 75/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9387\n",
            "Epoch 76/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9340\n",
            "Epoch 77/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9302\n",
            "Epoch 78/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9324\n",
            "Epoch 79/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9368\n",
            "Epoch 80/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9378\n",
            "Epoch 81/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9324\n",
            "Epoch 82/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9357\n",
            "Epoch 83/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9351\n",
            "Epoch 84/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9318\n",
            "Epoch 85/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9318\n",
            "Epoch 86/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9348\n",
            "Epoch 87/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9340\n",
            "Epoch 88/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9321\n",
            "Epoch 89/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9288\n",
            "Epoch 90/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9392\n",
            "Epoch 91/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9376\n",
            "Epoch 92/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9305\n",
            "Epoch 93/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9354\n",
            "Epoch 94/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9373\n",
            "Epoch 95/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9430\n",
            "Epoch 96/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9335\n",
            "Epoch 97/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9376\n",
            "Epoch 98/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9332\n",
            "Epoch 99/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9359\n",
            "Epoch 100/100\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffa379b0c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgswjGCl74E0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fbe63082-996f-489f-fed5-f321307111d4"
      },
      "source": [
        "prediction_model_eval = model.evaluate(a, b) \n",
        "reloaded_model_eval = reloaded_model.evaluate(a, b)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "115/115 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9547\n",
            "115/115 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9716\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}