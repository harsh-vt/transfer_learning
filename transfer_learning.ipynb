{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmD2DFmQoLrWBkTwoq3Blj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-vt/transfer_learning/blob/master/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAdVC-s1kkjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb5ZIr2Olgmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('training_data.csv')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56-6kkoHs02f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "d18fd971-9416-4735-972a-6e61fb58ced8"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>U</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Z</th>\n",
              "      <th>AA</th>\n",
              "      <th>AB</th>\n",
              "      <th>AC</th>\n",
              "      <th>AD</th>\n",
              "      <th>AE</th>\n",
              "      <th>AF</th>\n",
              "      <th>AG</th>\n",
              "      <th>AH</th>\n",
              "      <th>AI</th>\n",
              "      <th>AK</th>\n",
              "      <th>AL</th>\n",
              "      <th>AM</th>\n",
              "      <th>AN</th>\n",
              "      <th>AO</th>\n",
              "      <th>AP</th>\n",
              "      <th>AQ</th>\n",
              "      <th>AR</th>\n",
              "      <th>AS</th>\n",
              "      <th>AT</th>\n",
              "      <th>AU</th>\n",
              "      <th>...</th>\n",
              "      <th>BD</th>\n",
              "      <th>BE</th>\n",
              "      <th>BF</th>\n",
              "      <th>BG</th>\n",
              "      <th>BH</th>\n",
              "      <th>BI</th>\n",
              "      <th>BJ</th>\n",
              "      <th>BK</th>\n",
              "      <th>BL</th>\n",
              "      <th>BM</th>\n",
              "      <th>BN</th>\n",
              "      <th>BO</th>\n",
              "      <th>BP</th>\n",
              "      <th>BQ</th>\n",
              "      <th>BR</th>\n",
              "      <th>BS</th>\n",
              "      <th>BT</th>\n",
              "      <th>BU</th>\n",
              "      <th>BV</th>\n",
              "      <th>BW</th>\n",
              "      <th>BX</th>\n",
              "      <th>BY</th>\n",
              "      <th>BZ</th>\n",
              "      <th>CA</th>\n",
              "      <th>CB</th>\n",
              "      <th>CC</th>\n",
              "      <th>CD</th>\n",
              "      <th>CE</th>\n",
              "      <th>CF</th>\n",
              "      <th>CG</th>\n",
              "      <th>CH</th>\n",
              "      <th>CI</th>\n",
              "      <th>CJ</th>\n",
              "      <th>CK</th>\n",
              "      <th>CL</th>\n",
              "      <th>CM</th>\n",
              "      <th>CN</th>\n",
              "      <th>CO</th>\n",
              "      <th>CP</th>\n",
              "      <th>CQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>305</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 88 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   A  B  C  D  E  F  G  H  I  J  ...  CH  CI  CJ   CK   CL  CM  CN  CO   CP  CQ\n",
              "0  0  1  0  0  0  0  1  0  0  0  ...   0   0   0  420  0.0   7  35   0  200   1\n",
              "1  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   40  0.0  11   5   0   20   1\n",
              "2  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   40  0.0  12   5   0  305   1\n",
              "3  0  1  0  0  0  0  1  0  0  0  ...   0   0   0  420  0.0  17  35   0  110   1\n",
              "4  0  1  0  0  0  0  1  0  0  0  ...   0   0   0   85  0.0  19  20   0   75   5\n",
              "\n",
              "[5 rows x 88 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMpYKRGsIGcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e501a7e9-d747-465b-8318-ed691bc1713f"
      },
      "source": [
        "train_data.CQ.unique()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 5, 3, 4, 2, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVFXkbk9Lpf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7244e83-8b61-485c-f679-ab6b0562050e"
      },
      "source": [
        "train_data['CQ'] -= 1\n",
        "train_data.CQ.unique()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4, 2, 3, 1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGw4qcSulrIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDE4zEpTmN9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xy = np.array(train_data)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axabB0RwmUYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e30f74fb-5a5a-49f3-9ae8-0251c9cc21d5"
      },
      "source": [
        "print(xy)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.   1.   0. ...   0. 200.   1.]\n",
            " [  0.   1.   0. ...   0.  20.   1.]\n",
            " [  0.   1.   0. ...   0. 305.   1.]\n",
            " ...\n",
            " [  1.   0.   0. ...   0.  13.   4.]\n",
            " [  1.   0.   0. ...   0.   0.   4.]\n",
            " [  0.   0.   1. ...   0.   0.   2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi_lCYjGmmxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(xy)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cJczYnVnAna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2e866c67-ee7d-44cd-f030-db3de7698c54"
      },
      "source": [
        "y = xy[:, -1:]\n",
        "x = xy[:, 0:-1]\n",
        "print(y)\n",
        "print(x)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.]\n",
            " [3.]\n",
            " [4.]\n",
            " ...\n",
            " [0.]\n",
            " [4.]\n",
            " [2.]]\n",
            "[[  0.   1.   0. ...  60.   0.   0.]\n",
            " [  0.   1.   0. ...   5.   0.  15.]\n",
            " [  0.   0.   1. ...  15.   0. 265.]\n",
            " ...\n",
            " [  0.   1.   0. ...  45.   0.   0.]\n",
            " [  0.   0.   1. ...  15.   0.   0.]\n",
            " [  0.   0.   1. ...  35.   0. 535.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKJHyyUcNuk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=x/x.max(axis=0)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGNOKtuKjGtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "610a5b67-bb79-4074-c32f-53f42c64abf7"
      },
      "source": [
        "x.shape "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3668, 87)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu8i1uLNRjmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training data split - 70& for training, 10% for validation, 20% for testing\n",
        "k = 2568\n",
        "l = 367\n",
        "x_train = x[0:k,:]\n",
        "y_train = y[0:k,:]\n",
        "x_val = x[k:k+l,:]\n",
        "y_val = y[k:k+l,:]\n",
        "x_test = x[k+l:,:]\n",
        "y_test = y[k+l:,:] "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRnk5wJvSZ6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "08f161a7-f050-4d49-8b86-8eedd6010de8"
      },
      "source": [
        "print(x_train.shape)\n",
        "# print(x_train)\n",
        "print()\n",
        "print(y_train.shape)\n",
        "# print(y_train)\n",
        "print()\n",
        "print(x_val.shape)\n",
        "# print(x_val)\n",
        "print()\n",
        "print(y_val.shape)\n",
        "# print(y_val)\n",
        "print()\n",
        "print(x_test.shape)\n",
        "# print(x_test)\n",
        "print()\n",
        "print(y_test.shape)\n",
        "# print(y_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2568, 87)\n",
            "\n",
            "(2568, 1)\n",
            "\n",
            "(367, 87)\n",
            "\n",
            "(367, 1)\n",
            "\n",
            "(733, 87)\n",
            "\n",
            "(733, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aYidakSVWzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_model():\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(87, input_dim=input_shape, activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(124, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(6,activation='softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Pl7cxMHH-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0a60704-6f01-4180-97cc-c4f3f52118a4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "\n",
        "input_shape = x_train.shape[1]\n",
        "\n",
        "model = baseline_model()\n",
        "\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "hist = model.fit(x_train, y_train, epochs=200,  validation_data=(x_val, y_val), callbacks=[cp_callback])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.show\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.legend([\"val_loss\", \"loss\"], loc =\"best\") \n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.show\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.legend([\"accuracy\", \"val_accuracy\"], loc =\"best\") \n",
        "plt.show()\n",
        "print(input_shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 1.5805 - accuracy: 0.4119\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 1.5752 - accuracy: 0.4132 - val_loss: 1.3730 - val_accuracy: 0.5450\n",
            "Epoch 2/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 1.2670 - accuracy: 0.5188\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.2675 - accuracy: 0.5187 - val_loss: 1.1852 - val_accuracy: 0.5232\n",
            "Epoch 3/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 1.1601 - accuracy: 0.5621\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1527 - accuracy: 0.5615 - val_loss: 1.0928 - val_accuracy: 0.5722\n",
            "Epoch 4/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 1.1223 - accuracy: 0.5861\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1255 - accuracy: 0.5853 - val_loss: 1.0907 - val_accuracy: 0.5749\n",
            "Epoch 5/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 1.0873 - accuracy: 0.5813\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0844 - accuracy: 0.5837 - val_loss: 1.0333 - val_accuracy: 0.6376\n",
            "Epoch 6/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 1.0459 - accuracy: 0.6006\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0433 - accuracy: 0.6024 - val_loss: 1.0388 - val_accuracy: 0.6022\n",
            "Epoch 7/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 1.0273 - accuracy: 0.6181\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0357 - accuracy: 0.6145 - val_loss: 1.0032 - val_accuracy: 0.6267\n",
            "Epoch 8/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 1.0238 - accuracy: 0.6134\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0244 - accuracy: 0.6118 - val_loss: 1.0357 - val_accuracy: 0.6022\n",
            "Epoch 9/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 1.0087 - accuracy: 0.6168\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.0090 - accuracy: 0.6188 - val_loss: 0.9813 - val_accuracy: 0.6512\n",
            "Epoch 10/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.9571 - accuracy: 0.6313\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9601 - accuracy: 0.6301 - val_loss: 1.0109 - val_accuracy: 0.6076\n",
            "Epoch 11/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.9665 - accuracy: 0.6438\n",
            "Epoch 00011: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9553 - accuracy: 0.6480 - val_loss: 1.0236 - val_accuracy: 0.6403\n",
            "Epoch 12/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.9712 - accuracy: 0.6302\n",
            "Epoch 00012: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9671 - accuracy: 0.6343 - val_loss: 0.9868 - val_accuracy: 0.6512\n",
            "Epoch 13/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.9383 - accuracy: 0.6354\n",
            "Epoch 00013: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9381 - accuracy: 0.6375 - val_loss: 0.9573 - val_accuracy: 0.6376\n",
            "Epoch 14/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.9206 - accuracy: 0.6480\n",
            "Epoch 00014: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9147 - accuracy: 0.6507 - val_loss: 0.9280 - val_accuracy: 0.6730\n",
            "Epoch 15/200\n",
            "65/81 [=======================>......] - ETA: 0s - loss: 0.9052 - accuracy: 0.6654\n",
            "Epoch 00015: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9054 - accuracy: 0.6674 - val_loss: 0.9361 - val_accuracy: 0.6594\n",
            "Epoch 16/200\n",
            "64/81 [======================>.......] - ETA: 0s - loss: 0.8719 - accuracy: 0.6685\n",
            "Epoch 00016: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.9022 - accuracy: 0.6620 - val_loss: 0.9296 - val_accuracy: 0.6757\n",
            "Epoch 17/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.8841 - accuracy: 0.6719\n",
            "Epoch 00017: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8893 - accuracy: 0.6698 - val_loss: 0.9263 - val_accuracy: 0.6567\n",
            "Epoch 18/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.8593 - accuracy: 0.6638\n",
            "Epoch 00018: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.8608 - accuracy: 0.6636 - val_loss: 0.9340 - val_accuracy: 0.6540\n",
            "Epoch 19/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.8431 - accuracy: 0.6913\n",
            "Epoch 00019: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8523 - accuracy: 0.6869 - val_loss: 0.9573 - val_accuracy: 0.6294\n",
            "Epoch 20/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.8485 - accuracy: 0.6683\n",
            "Epoch 00020: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8543 - accuracy: 0.6706 - val_loss: 0.8972 - val_accuracy: 0.6866\n",
            "Epoch 21/200\n",
            "64/81 [======================>.......] - ETA: 0s - loss: 0.8549 - accuracy: 0.6782\n",
            "Epoch 00021: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8440 - accuracy: 0.6768 - val_loss: 1.0051 - val_accuracy: 0.6485\n",
            "Epoch 22/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.8426 - accuracy: 0.6810\n",
            "Epoch 00022: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.8396 - accuracy: 0.6826 - val_loss: 0.9326 - val_accuracy: 0.6730\n",
            "Epoch 23/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.8262 - accuracy: 0.6924\n",
            "Epoch 00023: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8247 - accuracy: 0.6881 - val_loss: 0.9091 - val_accuracy: 0.6621\n",
            "Epoch 24/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.8128 - accuracy: 0.7020\n",
            "Epoch 00024: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8265 - accuracy: 0.6935 - val_loss: 0.9066 - val_accuracy: 0.6621\n",
            "Epoch 25/200\n",
            "61/81 [=====================>........] - ETA: 0s - loss: 0.8084 - accuracy: 0.7008\n",
            "Epoch 00025: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8000 - accuracy: 0.7029 - val_loss: 0.9093 - val_accuracy: 0.6785\n",
            "Epoch 26/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.7872 - accuracy: 0.6976\n",
            "Epoch 00026: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.6928 - val_loss: 0.9316 - val_accuracy: 0.6839\n",
            "Epoch 27/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.7864 - accuracy: 0.7076\n",
            "Epoch 00027: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7873 - accuracy: 0.7076 - val_loss: 0.9272 - val_accuracy: 0.6812\n",
            "Epoch 28/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.7720 - accuracy: 0.7085\n",
            "Epoch 00028: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7699 - accuracy: 0.7122 - val_loss: 0.8767 - val_accuracy: 0.6894\n",
            "Epoch 29/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.7818 - accuracy: 0.7064\n",
            "Epoch 00029: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7798 - accuracy: 0.7060 - val_loss: 0.9298 - val_accuracy: 0.6485\n",
            "Epoch 30/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.7624 - accuracy: 0.7104\n",
            "Epoch 00030: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7683 - accuracy: 0.7060 - val_loss: 0.9051 - val_accuracy: 0.6703\n",
            "Epoch 31/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.7802 - accuracy: 0.6995\n",
            "Epoch 00031: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7712 - accuracy: 0.7048 - val_loss: 0.9685 - val_accuracy: 0.6322\n",
            "Epoch 32/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.7382 - accuracy: 0.7212\n",
            "Epoch 00032: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.7196 - val_loss: 0.8622 - val_accuracy: 0.7112\n",
            "Epoch 33/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.7343 - accuracy: 0.7273\n",
            "Epoch 00033: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.7227 - val_loss: 0.9163 - val_accuracy: 0.6894\n",
            "Epoch 34/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.7412 - accuracy: 0.7260\n",
            "Epoch 00034: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7334 - accuracy: 0.7262 - val_loss: 0.8581 - val_accuracy: 0.6894\n",
            "Epoch 35/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.7472 - accuracy: 0.7148\n",
            "Epoch 00035: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7447 - accuracy: 0.7153 - val_loss: 0.9195 - val_accuracy: 0.6757\n",
            "Epoch 36/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.6981 - accuracy: 0.7373\n",
            "Epoch 00036: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.7348 - val_loss: 0.9177 - val_accuracy: 0.6812\n",
            "Epoch 37/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.6910 - accuracy: 0.7444\n",
            "Epoch 00037: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.7414 - val_loss: 0.8994 - val_accuracy: 0.6785\n",
            "Epoch 38/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.7021 - accuracy: 0.7230\n",
            "Epoch 00038: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.7212 - val_loss: 0.8485 - val_accuracy: 0.6948\n",
            "Epoch 39/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.7037 - accuracy: 0.7342\n",
            "Epoch 00039: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.7360 - val_loss: 0.8928 - val_accuracy: 0.6866\n",
            "Epoch 40/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.6881 - accuracy: 0.7413\n",
            "Epoch 00040: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.7410 - val_loss: 0.8970 - val_accuracy: 0.7030\n",
            "Epoch 41/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.7066 - accuracy: 0.7192\n",
            "Epoch 00041: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7124 - accuracy: 0.7177 - val_loss: 0.8877 - val_accuracy: 0.6975\n",
            "Epoch 42/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.6452 - accuracy: 0.7571\n",
            "Epoch 00042: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.7527 - val_loss: 0.9004 - val_accuracy: 0.7084\n",
            "Epoch 43/200\n",
            "65/81 [=======================>......] - ETA: 0s - loss: 0.6762 - accuracy: 0.7341\n",
            "Epoch 00043: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.7426 - val_loss: 0.8962 - val_accuracy: 0.7003\n",
            "Epoch 44/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.6704 - accuracy: 0.7470\n",
            "Epoch 00044: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.7453 - val_loss: 0.8910 - val_accuracy: 0.7030\n",
            "Epoch 45/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.6762 - accuracy: 0.7337\n",
            "Epoch 00045: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.7313 - val_loss: 0.8706 - val_accuracy: 0.7057\n",
            "Epoch 46/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.6665 - accuracy: 0.7441\n",
            "Epoch 00046: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.7465 - val_loss: 0.9004 - val_accuracy: 0.7030\n",
            "Epoch 47/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.6441 - accuracy: 0.7645\n",
            "Epoch 00047: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7605 - val_loss: 0.8990 - val_accuracy: 0.6921\n",
            "Epoch 48/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.6578 - accuracy: 0.7540\n",
            "Epoch 00048: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.7535 - val_loss: 0.8950 - val_accuracy: 0.6839\n",
            "Epoch 49/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.6576 - accuracy: 0.7551\n",
            "Epoch 00049: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.7543 - val_loss: 0.8886 - val_accuracy: 0.6921\n",
            "Epoch 50/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.6352 - accuracy: 0.7680\n",
            "Epoch 00050: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.7691 - val_loss: 0.9033 - val_accuracy: 0.6948\n",
            "Epoch 51/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.6624 - accuracy: 0.7500\n",
            "Epoch 00051: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7500 - val_loss: 0.9647 - val_accuracy: 0.6594\n",
            "Epoch 52/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.6406 - accuracy: 0.7621\n",
            "Epoch 00052: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7590 - val_loss: 0.8832 - val_accuracy: 0.6894\n",
            "Epoch 53/200\n",
            "55/81 [===================>..........] - ETA: 0s - loss: 0.6069 - accuracy: 0.7602\n",
            "Epoch 00053: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7601 - val_loss: 0.8789 - val_accuracy: 0.7112\n",
            "Epoch 54/200\n",
            "54/81 [===================>..........] - ETA: 0s - loss: 0.6262 - accuracy: 0.7587\n",
            "Epoch 00054: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7648 - val_loss: 0.9606 - val_accuracy: 0.6866\n",
            "Epoch 55/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.6254 - accuracy: 0.7591\n",
            "Epoch 00055: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.7574 - val_loss: 0.8956 - val_accuracy: 0.7030\n",
            "Epoch 56/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.6400 - accuracy: 0.7620\n",
            "Epoch 00056: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.7593 - val_loss: 0.8877 - val_accuracy: 0.7030\n",
            "Epoch 57/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.6283 - accuracy: 0.7597\n",
            "Epoch 00057: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.7629 - val_loss: 0.9149 - val_accuracy: 0.6948\n",
            "Epoch 58/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.6263 - accuracy: 0.7640\n",
            "Epoch 00058: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.7625 - val_loss: 0.8892 - val_accuracy: 0.6785\n",
            "Epoch 59/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5893 - accuracy: 0.7707\n",
            "Epoch 00059: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7710 - val_loss: 0.8936 - val_accuracy: 0.6975\n",
            "Epoch 60/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5808 - accuracy: 0.7779\n",
            "Epoch 00060: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7769 - val_loss: 0.9332 - val_accuracy: 0.7193\n",
            "Epoch 61/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.5869 - accuracy: 0.7763\n",
            "Epoch 00061: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7784 - val_loss: 0.8881 - val_accuracy: 0.7003\n",
            "Epoch 62/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.5809 - accuracy: 0.7817\n",
            "Epoch 00062: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7823 - val_loss: 0.9023 - val_accuracy: 0.7057\n",
            "Epoch 63/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.5823 - accuracy: 0.7816\n",
            "Epoch 00063: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7808 - val_loss: 0.8843 - val_accuracy: 0.7193\n",
            "Epoch 64/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.5967 - accuracy: 0.7771\n",
            "Epoch 00064: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7788 - val_loss: 0.8779 - val_accuracy: 0.7030\n",
            "Epoch 65/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5758 - accuracy: 0.7812\n",
            "Epoch 00065: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7815 - val_loss: 0.9634 - val_accuracy: 0.7030\n",
            "Epoch 66/200\n",
            "65/81 [=======================>......] - ETA: 0s - loss: 0.5545 - accuracy: 0.7933\n",
            "Epoch 00066: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7839 - val_loss: 0.9503 - val_accuracy: 0.6866\n",
            "Epoch 67/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.5713 - accuracy: 0.7899\n",
            "Epoch 00067: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7866 - val_loss: 0.9064 - val_accuracy: 0.7003\n",
            "Epoch 68/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5549 - accuracy: 0.7830\n",
            "Epoch 00068: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7870 - val_loss: 0.9404 - val_accuracy: 0.6948\n",
            "Epoch 69/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.5445 - accuracy: 0.7918\n",
            "Epoch 00069: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7897 - val_loss: 0.8955 - val_accuracy: 0.7139\n",
            "Epoch 70/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5527 - accuracy: 0.7931\n",
            "Epoch 00070: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7924 - val_loss: 0.9425 - val_accuracy: 0.6921\n",
            "Epoch 71/200\n",
            "63/81 [======================>.......] - ETA: 0s - loss: 0.5881 - accuracy: 0.7812\n",
            "Epoch 00071: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7831 - val_loss: 0.9380 - val_accuracy: 0.7057\n",
            "Epoch 72/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5390 - accuracy: 0.7904\n",
            "Epoch 00072: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7905 - val_loss: 0.9106 - val_accuracy: 0.6948\n",
            "Epoch 73/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.5242 - accuracy: 0.8013\n",
            "Epoch 00073: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8022 - val_loss: 0.9397 - val_accuracy: 0.7084\n",
            "Epoch 74/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5658 - accuracy: 0.7804\n",
            "Epoch 00074: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7812 - val_loss: 0.9445 - val_accuracy: 0.6785\n",
            "Epoch 75/200\n",
            "66/81 [=======================>......] - ETA: 0s - loss: 0.5322 - accuracy: 0.8040\n",
            "Epoch 00075: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8022 - val_loss: 0.9248 - val_accuracy: 0.7112\n",
            "Epoch 76/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.5105 - accuracy: 0.8094\n",
            "Epoch 00076: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.8057 - val_loss: 0.9785 - val_accuracy: 0.6921\n",
            "Epoch 77/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5365 - accuracy: 0.7990\n",
            "Epoch 00077: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.8006 - val_loss: 0.9511 - val_accuracy: 0.6839\n",
            "Epoch 78/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.5353 - accuracy: 0.8111\n",
            "Epoch 00078: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.8088 - val_loss: 0.9296 - val_accuracy: 0.6975\n",
            "Epoch 79/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5206 - accuracy: 0.7960\n",
            "Epoch 00079: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7963 - val_loss: 0.9711 - val_accuracy: 0.6921\n",
            "Epoch 80/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.5235 - accuracy: 0.8018\n",
            "Epoch 00080: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.8033 - val_loss: 1.2931 - val_accuracy: 0.6921\n",
            "Epoch 81/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.5270 - accuracy: 0.7966\n",
            "Epoch 00081: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7921 - val_loss: 1.0516 - val_accuracy: 0.6894\n",
            "Epoch 82/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.5347 - accuracy: 0.7937\n",
            "Epoch 00082: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7905 - val_loss: 0.9723 - val_accuracy: 0.6730\n",
            "Epoch 83/200\n",
            "63/81 [======================>.......] - ETA: 0s - loss: 0.5294 - accuracy: 0.7996\n",
            "Epoch 00083: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7971 - val_loss: 0.9893 - val_accuracy: 0.6703\n",
            "Epoch 84/200\n",
            "65/81 [=======================>......] - ETA: 0s - loss: 0.5226 - accuracy: 0.7957\n",
            "Epoch 00084: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7924 - val_loss: 0.9381 - val_accuracy: 0.6594\n",
            "Epoch 85/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.5166 - accuracy: 0.8121\n",
            "Epoch 00085: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8123 - val_loss: 0.9623 - val_accuracy: 0.6785\n",
            "Epoch 86/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.4934 - accuracy: 0.8092\n",
            "Epoch 00086: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8076 - val_loss: 0.9432 - val_accuracy: 0.7112\n",
            "Epoch 87/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.5139 - accuracy: 0.8101\n",
            "Epoch 00087: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.8100 - val_loss: 0.9538 - val_accuracy: 0.6866\n",
            "Epoch 88/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.5063 - accuracy: 0.8193\n",
            "Epoch 00088: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8178 - val_loss: 0.9359 - val_accuracy: 0.6975\n",
            "Epoch 89/200\n",
            "64/81 [======================>.......] - ETA: 0s - loss: 0.5073 - accuracy: 0.8203\n",
            "Epoch 00089: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.8139 - val_loss: 0.9367 - val_accuracy: 0.6894\n",
            "Epoch 90/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.5006 - accuracy: 0.8036\n",
            "Epoch 00090: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8045 - val_loss: 0.9526 - val_accuracy: 0.6730\n",
            "Epoch 91/200\n",
            "66/81 [=======================>......] - ETA: 0s - loss: 0.4793 - accuracy: 0.8130\n",
            "Epoch 00091: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8049 - val_loss: 0.9340 - val_accuracy: 0.6730\n",
            "Epoch 92/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.5224 - accuracy: 0.8009\n",
            "Epoch 00092: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.8030 - val_loss: 0.9502 - val_accuracy: 0.7003\n",
            "Epoch 93/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.5035 - accuracy: 0.8104\n",
            "Epoch 00093: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8084 - val_loss: 0.9641 - val_accuracy: 0.6703\n",
            "Epoch 94/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.4926 - accuracy: 0.8151\n",
            "Epoch 00094: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8146 - val_loss: 0.9900 - val_accuracy: 0.6621\n",
            "Epoch 95/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.8161\n",
            "Epoch 00095: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8158 - val_loss: 0.9267 - val_accuracy: 0.6948\n",
            "Epoch 96/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4596 - accuracy: 0.8299\n",
            "Epoch 00096: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8283 - val_loss: 1.0617 - val_accuracy: 0.6485\n",
            "Epoch 97/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.4623 - accuracy: 0.8324\n",
            "Epoch 00097: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8306 - val_loss: 0.9583 - val_accuracy: 0.6866\n",
            "Epoch 98/200\n",
            "66/81 [=======================>......] - ETA: 0s - loss: 0.4884 - accuracy: 0.8191\n",
            "Epoch 00098: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8213 - val_loss: 0.9546 - val_accuracy: 0.7003\n",
            "Epoch 99/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.4834 - accuracy: 0.8182\n",
            "Epoch 00099: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8189 - val_loss: 0.9349 - val_accuracy: 0.6948\n",
            "Epoch 100/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.4706 - accuracy: 0.8173\n",
            "Epoch 00100: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8217 - val_loss: 0.9868 - val_accuracy: 0.6948\n",
            "Epoch 101/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.4759 - accuracy: 0.8253\n",
            "Epoch 00101: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8267 - val_loss: 1.0032 - val_accuracy: 0.6975\n",
            "Epoch 102/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.4577 - accuracy: 0.8180\n",
            "Epoch 00102: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.8158 - val_loss: 0.9790 - val_accuracy: 0.7057\n",
            "Epoch 103/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.4683 - accuracy: 0.8204\n",
            "Epoch 00103: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8220 - val_loss: 0.9683 - val_accuracy: 0.6730\n",
            "Epoch 104/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.4681 - accuracy: 0.8189\n",
            "Epoch 00104: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8189 - val_loss: 0.9421 - val_accuracy: 0.7003\n",
            "Epoch 105/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.4513 - accuracy: 0.8306\n",
            "Epoch 00105: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8290 - val_loss: 1.0714 - val_accuracy: 0.6594\n",
            "Epoch 106/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.4829 - accuracy: 0.8150\n",
            "Epoch 00106: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8189 - val_loss: 1.0182 - val_accuracy: 0.6703\n",
            "Epoch 107/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.4384 - accuracy: 0.8358\n",
            "Epoch 00107: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8361 - val_loss: 0.9593 - val_accuracy: 0.6975\n",
            "Epoch 108/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.4448 - accuracy: 0.8371\n",
            "Epoch 00108: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8396 - val_loss: 0.9732 - val_accuracy: 0.6866\n",
            "Epoch 109/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.4585 - accuracy: 0.8245\n",
            "Epoch 00109: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8248 - val_loss: 1.0166 - val_accuracy: 0.6730\n",
            "Epoch 110/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.4423 - accuracy: 0.8300\n",
            "Epoch 00110: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8318 - val_loss: 1.0153 - val_accuracy: 0.6921\n",
            "Epoch 111/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.4526 - accuracy: 0.8273\n",
            "Epoch 00111: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8271 - val_loss: 0.9753 - val_accuracy: 0.6757\n",
            "Epoch 112/200\n",
            "66/81 [=======================>......] - ETA: 0s - loss: 0.4367 - accuracy: 0.8385\n",
            "Epoch 00112: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.8329 - val_loss: 1.0125 - val_accuracy: 0.6894\n",
            "Epoch 113/200\n",
            "64/81 [======================>.......] - ETA: 0s - loss: 0.4196 - accuracy: 0.8423\n",
            "Epoch 00113: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8333 - val_loss: 0.9866 - val_accuracy: 0.7166\n",
            "Epoch 114/200\n",
            "63/81 [======================>.......] - ETA: 0s - loss: 0.4369 - accuracy: 0.8388\n",
            "Epoch 00114: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8361 - val_loss: 0.9809 - val_accuracy: 0.6921\n",
            "Epoch 115/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.4379 - accuracy: 0.8340\n",
            "Epoch 00115: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8333 - val_loss: 0.9953 - val_accuracy: 0.6812\n",
            "Epoch 116/200\n",
            "65/81 [=======================>......] - ETA: 0s - loss: 0.4197 - accuracy: 0.8380\n",
            "Epoch 00116: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8400 - val_loss: 1.0034 - val_accuracy: 0.6975\n",
            "Epoch 117/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.4041 - accuracy: 0.8478\n",
            "Epoch 00117: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8411 - val_loss: 0.9766 - val_accuracy: 0.7112\n",
            "Epoch 118/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.4438 - accuracy: 0.8253\n",
            "Epoch 00118: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8259 - val_loss: 0.9793 - val_accuracy: 0.7003\n",
            "Epoch 119/200\n",
            "59/81 [====================>.........] - ETA: 0s - loss: 0.4191 - accuracy: 0.8411\n",
            "Epoch 00119: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8446 - val_loss: 1.0323 - val_accuracy: 0.6975\n",
            "Epoch 120/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.4055 - accuracy: 0.8534\n",
            "Epoch 00120: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8532 - val_loss: 0.9771 - val_accuracy: 0.7166\n",
            "Epoch 121/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.4184 - accuracy: 0.8315\n",
            "Epoch 00121: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8357 - val_loss: 0.9922 - val_accuracy: 0.6948\n",
            "Epoch 122/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.3906 - accuracy: 0.8540\n",
            "Epoch 00122: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8540 - val_loss: 1.0069 - val_accuracy: 0.6894\n",
            "Epoch 123/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.4288 - accuracy: 0.8369\n",
            "Epoch 00123: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8403 - val_loss: 1.0440 - val_accuracy: 0.6839\n",
            "Epoch 124/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.4164 - accuracy: 0.8371\n",
            "Epoch 00124: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8306 - val_loss: 1.0110 - val_accuracy: 0.6866\n",
            "Epoch 125/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.8462\n",
            "Epoch 00125: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8462 - val_loss: 1.0494 - val_accuracy: 0.7112\n",
            "Epoch 126/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.4152 - accuracy: 0.8380\n",
            "Epoch 00126: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8368 - val_loss: 0.9857 - val_accuracy: 0.6839\n",
            "Epoch 127/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.4179 - accuracy: 0.8442\n",
            "Epoch 00127: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8435 - val_loss: 0.9686 - val_accuracy: 0.7166\n",
            "Epoch 128/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.4122 - accuracy: 0.8384\n",
            "Epoch 00128: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8411 - val_loss: 0.9972 - val_accuracy: 0.7112\n",
            "Epoch 129/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3833 - accuracy: 0.8522\n",
            "Epoch 00129: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8462 - val_loss: 1.1098 - val_accuracy: 0.6730\n",
            "Epoch 130/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.4136 - accuracy: 0.8505\n",
            "Epoch 00130: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8442 - val_loss: 1.0498 - val_accuracy: 0.6921\n",
            "Epoch 131/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.4051 - accuracy: 0.8401\n",
            "Epoch 00131: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8392 - val_loss: 0.9923 - val_accuracy: 0.7084\n",
            "Epoch 132/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.4282 - accuracy: 0.8342\n",
            "Epoch 00132: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8400 - val_loss: 0.9827 - val_accuracy: 0.6975\n",
            "Epoch 133/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.4134 - accuracy: 0.8326\n",
            "Epoch 00133: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8349 - val_loss: 0.9988 - val_accuracy: 0.7139\n",
            "Epoch 134/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3986 - accuracy: 0.8513\n",
            "Epoch 00134: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8501 - val_loss: 0.9917 - val_accuracy: 0.6921\n",
            "Epoch 135/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.4042 - accuracy: 0.8433\n",
            "Epoch 00135: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8435 - val_loss: 1.0487 - val_accuracy: 0.7003\n",
            "Epoch 136/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.4275 - accuracy: 0.8324\n",
            "Epoch 00136: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8326 - val_loss: 0.9930 - val_accuracy: 0.6948\n",
            "Epoch 137/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3932 - accuracy: 0.8529\n",
            "Epoch 00137: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8532 - val_loss: 1.0266 - val_accuracy: 0.6921\n",
            "Epoch 138/200\n",
            "55/81 [===================>..........] - ETA: 0s - loss: 0.3931 - accuracy: 0.8517\n",
            "Epoch 00138: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8493 - val_loss: 1.0756 - val_accuracy: 0.6921\n",
            "Epoch 139/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3871 - accuracy: 0.8547\n",
            "Epoch 00139: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8532 - val_loss: 1.0216 - val_accuracy: 0.6839\n",
            "Epoch 140/200\n",
            "71/81 [=========================>....] - ETA: 0s - loss: 0.3894 - accuracy: 0.8495\n",
            "Epoch 00140: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8458 - val_loss: 1.0568 - val_accuracy: 0.6894\n",
            "Epoch 141/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.3749 - accuracy: 0.8546\n",
            "Epoch 00141: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8567 - val_loss: 1.0387 - val_accuracy: 0.7057\n",
            "Epoch 142/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.3814 - accuracy: 0.8634\n",
            "Epoch 00142: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8610 - val_loss: 1.0642 - val_accuracy: 0.7030\n",
            "Epoch 143/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3646 - accuracy: 0.8623\n",
            "Epoch 00143: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8579 - val_loss: 1.0192 - val_accuracy: 0.6730\n",
            "Epoch 144/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3767 - accuracy: 0.8554\n",
            "Epoch 00144: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8559 - val_loss: 1.0126 - val_accuracy: 0.6948\n",
            "Epoch 145/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.3715 - accuracy: 0.8535\n",
            "Epoch 00145: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8532 - val_loss: 1.0570 - val_accuracy: 0.6894\n",
            "Epoch 146/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3839 - accuracy: 0.8546\n",
            "Epoch 00146: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8551 - val_loss: 0.9926 - val_accuracy: 0.7166\n",
            "Epoch 147/200\n",
            "68/81 [========================>.....] - ETA: 0s - loss: 0.3466 - accuracy: 0.8681\n",
            "Epoch 00147: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8633 - val_loss: 1.0881 - val_accuracy: 0.6757\n",
            "Epoch 148/200\n",
            "55/81 [===================>..........] - ETA: 0s - loss: 0.3589 - accuracy: 0.8631\n",
            "Epoch 00148: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8649 - val_loss: 1.0380 - val_accuracy: 0.7248\n",
            "Epoch 149/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8517\n",
            "Epoch 00149: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8528 - val_loss: 1.0198 - val_accuracy: 0.7275\n",
            "Epoch 150/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.3767 - accuracy: 0.8609\n",
            "Epoch 00150: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8614 - val_loss: 1.0538 - val_accuracy: 0.6894\n",
            "Epoch 151/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.3555 - accuracy: 0.8643\n",
            "Epoch 00151: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8629 - val_loss: 1.0787 - val_accuracy: 0.6975\n",
            "Epoch 152/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3806 - accuracy: 0.8567\n",
            "Epoch 00152: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8563 - val_loss: 1.0657 - val_accuracy: 0.6921\n",
            "Epoch 153/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.3803 - accuracy: 0.8527\n",
            "Epoch 00153: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8551 - val_loss: 1.1325 - val_accuracy: 0.6757\n",
            "Epoch 154/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.3586 - accuracy: 0.8637\n",
            "Epoch 00154: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8633 - val_loss: 1.0570 - val_accuracy: 0.7193\n",
            "Epoch 155/200\n",
            "63/81 [======================>.......] - ETA: 0s - loss: 0.3520 - accuracy: 0.8750\n",
            "Epoch 00155: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8699 - val_loss: 1.1596 - val_accuracy: 0.7030\n",
            "Epoch 156/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.3640 - accuracy: 0.8604\n",
            "Epoch 00156: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8614 - val_loss: 1.1702 - val_accuracy: 0.6975\n",
            "Epoch 157/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3759 - accuracy: 0.8626\n",
            "Epoch 00157: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8606 - val_loss: 1.3115 - val_accuracy: 0.6975\n",
            "Epoch 158/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.8641\n",
            "Epoch 00158: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8641 - val_loss: 1.0831 - val_accuracy: 0.7057\n",
            "Epoch 159/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3466 - accuracy: 0.8718\n",
            "Epoch 00159: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8727 - val_loss: 0.9937 - val_accuracy: 0.7112\n",
            "Epoch 160/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3327 - accuracy: 0.8754\n",
            "Epoch 00160: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8738 - val_loss: 1.1241 - val_accuracy: 0.7057\n",
            "Epoch 161/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.3539 - accuracy: 0.8582\n",
            "Epoch 00161: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8571 - val_loss: 1.0253 - val_accuracy: 0.6921\n",
            "Epoch 162/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.3431 - accuracy: 0.8687\n",
            "Epoch 00162: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8668 - val_loss: 1.1058 - val_accuracy: 0.6839\n",
            "Epoch 163/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.3575 - accuracy: 0.8673\n",
            "Epoch 00163: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8676 - val_loss: 1.1039 - val_accuracy: 0.6948\n",
            "Epoch 164/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3419 - accuracy: 0.8661\n",
            "Epoch 00164: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.8668 - val_loss: 1.1262 - val_accuracy: 0.6894\n",
            "Epoch 165/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.3541 - accuracy: 0.8648\n",
            "Epoch 00165: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8649 - val_loss: 1.1196 - val_accuracy: 0.7030\n",
            "Epoch 166/200\n",
            "80/81 [============================>.] - ETA: 0s - loss: 0.3551 - accuracy: 0.8656\n",
            "Epoch 00166: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8657 - val_loss: 1.1254 - val_accuracy: 0.7057\n",
            "Epoch 167/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3548 - accuracy: 0.8666\n",
            "Epoch 00167: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8664 - val_loss: 1.1846 - val_accuracy: 0.6894\n",
            "Epoch 168/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3556 - accuracy: 0.8692\n",
            "Epoch 00168: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8723 - val_loss: 1.0798 - val_accuracy: 0.7084\n",
            "Epoch 169/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.3498 - accuracy: 0.8610\n",
            "Epoch 00169: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8579 - val_loss: 1.0034 - val_accuracy: 0.7139\n",
            "Epoch 170/200\n",
            "61/81 [=====================>........] - ETA: 0s - loss: 0.3158 - accuracy: 0.8765\n",
            "Epoch 00170: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8715 - val_loss: 1.1285 - val_accuracy: 0.6894\n",
            "Epoch 171/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.3455 - accuracy: 0.8826\n",
            "Epoch 00171: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8816 - val_loss: 1.0821 - val_accuracy: 0.7003\n",
            "Epoch 172/200\n",
            "72/81 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.8767\n",
            "Epoch 00172: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8789 - val_loss: 1.0878 - val_accuracy: 0.7084\n",
            "Epoch 173/200\n",
            "61/81 [=====================>........] - ETA: 0s - loss: 0.3775 - accuracy: 0.8668\n",
            "Epoch 00173: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8680 - val_loss: 1.1365 - val_accuracy: 0.6975\n",
            "Epoch 174/200\n",
            "63/81 [======================>.......] - ETA: 0s - loss: 0.3417 - accuracy: 0.8785\n",
            "Epoch 00174: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8781 - val_loss: 1.0940 - val_accuracy: 0.7166\n",
            "Epoch 175/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.3516 - accuracy: 0.8729\n",
            "Epoch 00175: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8731 - val_loss: 1.0803 - val_accuracy: 0.7057\n",
            "Epoch 176/200\n",
            "67/81 [=======================>......] - ETA: 0s - loss: 0.3359 - accuracy: 0.8792\n",
            "Epoch 00176: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8746 - val_loss: 1.1610 - val_accuracy: 0.6839\n",
            "Epoch 177/200\n",
            "64/81 [======================>.......] - ETA: 0s - loss: 0.3504 - accuracy: 0.8672\n",
            "Epoch 00177: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8715 - val_loss: 1.0929 - val_accuracy: 0.7221\n",
            "Epoch 178/200\n",
            "61/81 [=====================>........] - ETA: 0s - loss: 0.3587 - accuracy: 0.8622\n",
            "Epoch 00178: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8645 - val_loss: 1.1344 - val_accuracy: 0.7030\n",
            "Epoch 179/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.3432 - accuracy: 0.8687\n",
            "Epoch 00179: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8692 - val_loss: 1.1067 - val_accuracy: 0.6866\n",
            "Epoch 180/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8629\n",
            "Epoch 00180: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8629 - val_loss: 1.0970 - val_accuracy: 0.6839\n",
            "Epoch 181/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.3169 - accuracy: 0.8881\n",
            "Epoch 00181: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8789 - val_loss: 1.1213 - val_accuracy: 0.6921\n",
            "Epoch 182/200\n",
            "61/81 [=====================>........] - ETA: 0s - loss: 0.3095 - accuracy: 0.8893\n",
            "Epoch 00182: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8859 - val_loss: 1.1696 - val_accuracy: 0.6948\n",
            "Epoch 183/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.3413 - accuracy: 0.8763\n",
            "Epoch 00183: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8766 - val_loss: 1.1159 - val_accuracy: 0.7057\n",
            "Epoch 184/200\n",
            "73/81 [==========================>...] - ETA: 0s - loss: 0.3308 - accuracy: 0.8759\n",
            "Epoch 00184: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8777 - val_loss: 1.2023 - val_accuracy: 0.6567\n",
            "Epoch 185/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3389 - accuracy: 0.8704\n",
            "Epoch 00185: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8672 - val_loss: 1.0984 - val_accuracy: 0.6948\n",
            "Epoch 186/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3285 - accuracy: 0.8762\n",
            "Epoch 00186: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8769 - val_loss: 1.1007 - val_accuracy: 0.7003\n",
            "Epoch 187/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3381 - accuracy: 0.8721\n",
            "Epoch 00187: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8746 - val_loss: 1.1349 - val_accuracy: 0.6594\n",
            "Epoch 188/200\n",
            "59/81 [====================>.........] - ETA: 0s - loss: 0.3347 - accuracy: 0.8787\n",
            "Epoch 00188: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8785 - val_loss: 1.1456 - val_accuracy: 0.6975\n",
            "Epoch 189/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3365 - accuracy: 0.8734\n",
            "Epoch 00189: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8738 - val_loss: 1.1163 - val_accuracy: 0.6948\n",
            "Epoch 190/200\n",
            "70/81 [========================>.....] - ETA: 0s - loss: 0.3383 - accuracy: 0.8732\n",
            "Epoch 00190: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8773 - val_loss: 1.1305 - val_accuracy: 0.6894\n",
            "Epoch 191/200\n",
            "69/81 [========================>.....] - ETA: 0s - loss: 0.3146 - accuracy: 0.8813\n",
            "Epoch 00191: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8801 - val_loss: 1.1840 - val_accuracy: 0.6839\n",
            "Epoch 192/200\n",
            "79/81 [============================>.] - ETA: 0s - loss: 0.3113 - accuracy: 0.8900\n",
            "Epoch 00192: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8902 - val_loss: 1.2384 - val_accuracy: 0.6785\n",
            "Epoch 193/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3209 - accuracy: 0.8814\n",
            "Epoch 00193: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8793 - val_loss: 1.2264 - val_accuracy: 0.6921\n",
            "Epoch 194/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3439 - accuracy: 0.8738\n",
            "Epoch 00194: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8707 - val_loss: 1.2338 - val_accuracy: 0.6866\n",
            "Epoch 195/200\n",
            "74/81 [==========================>...] - ETA: 0s - loss: 0.3027 - accuracy: 0.8843\n",
            "Epoch 00195: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8820 - val_loss: 1.1598 - val_accuracy: 0.6785\n",
            "Epoch 196/200\n",
            "76/81 [===========================>..] - ETA: 0s - loss: 0.3055 - accuracy: 0.8865\n",
            "Epoch 00196: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8855 - val_loss: 1.0907 - val_accuracy: 0.6785\n",
            "Epoch 197/200\n",
            "75/81 [==========================>...] - ETA: 0s - loss: 0.3260 - accuracy: 0.8838\n",
            "Epoch 00197: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8801 - val_loss: 1.1832 - val_accuracy: 0.7003\n",
            "Epoch 198/200\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.8816\n",
            "Epoch 00198: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8816 - val_loss: 1.2316 - val_accuracy: 0.6921\n",
            "Epoch 199/200\n",
            "77/81 [===========================>..] - ETA: 0s - loss: 0.3141 - accuracy: 0.8791\n",
            "Epoch 00199: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8789 - val_loss: 1.1479 - val_accuracy: 0.7003\n",
            "Epoch 200/200\n",
            "78/81 [===========================>..] - ETA: 0s - loss: 0.3015 - accuracy: 0.8862\n",
            "Epoch 00200: saving model to training_1/cp.ckpt\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8875 - val_loss: 1.0685 - val_accuracy: 0.6921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOZO8WoksN-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8f9d53b-88d8-475d-de34-ce8fa7278174"
      },
      "source": [
        "testing_predicted = model.evaluate(x_test,y_test) "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 0s 1ms/step - loss: 1.1246 - accuracy: 0.7067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuUdDoAw7tW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "393f70b8-fe2e-460d-da4c-6def77c13113"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 750       \n",
            "=================================================================\n",
            "Total params: 20,162\n",
            "Trainable params: 19,740\n",
            "Non-trainable params: 422\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku0AbAb-2aO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "16f7f2ff-b05c-4218-9286-986e4051c8e1"
      },
      "source": [
        "export_path = os.path.abspath(os.getcwd())+'/models/saved_model'\n",
        "model.save(export_path, save_format='tf')\n",
        "export_path"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/models/saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/saved_model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqMI2xGRh2gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c5c61168-be1f-4649-fb40-c9a85381fb00"
      },
      "source": [
        "# testing data split - 30% from training, 70 % for testing\n",
        "test_data = pd.read_csv('testing_data.csv')\n",
        "test_data['CQ'] -= 1\n",
        "ab = np.array(train_data)\n",
        "np.random.shuffle(ab)\n",
        "b = ab[:, -1:]\n",
        "a = ab[:, 0:-1]\n",
        "a = a/a.max(axis=0)\n",
        "\n",
        "k = 1100\n",
        "a_train = x[0:k,:]\n",
        "b_train = y[0:k,:]\n",
        "a_test = x[k:,:]\n",
        "b_test = y[k:,:] \n",
        "\n",
        "print(a_train.shape)\n",
        "# print(x_train)\n",
        "print()\n",
        "print(b_train.shape)\n",
        "# print(y_train)\n",
        "print()\n",
        "print(a_test.shape)\n",
        "# print(x_test)\n",
        "print()\n",
        "print(b_test.shape)\n",
        "# print(y_test)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1100, 87)\n",
            "\n",
            "(1100, 1)\n",
            "\n",
            "(2568, 87)\n",
            "\n",
            "(2568, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2U7Ye147VpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "dd37a8a8-66f0-4a6d-c9b5-366681a413cf"
      },
      "source": [
        "import_path = os.path.abspath(os.getcwd())+'/models/saved_model'\n",
        "reloaded_model = tf.keras.models.load_model(import_path)\n",
        "reloaded_model.summary()\n",
        "reloaded_model.load_weights(checkpoint_path)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 750       \n",
            "=================================================================\n",
            "Total params: 20,162\n",
            "Trainable params: 19,740\n",
            "Non-trainable params: 422\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3f0d8429b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6W0kh__TIGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f2181012-986c-4c25-cfaf-22e1909a9ac0"
      },
      "source": [
        "non_trainable_layers = len(reloaded_model.layers)-1\n",
        "for i in range(1,non_trainable_layers):\n",
        "  reloaded_model.layers[i].trainable = False\n",
        "reloaded_model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 87)                7656      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 87)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 87)                348       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 124)               10912     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 124)               496       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 750       \n",
            "=================================================================\n",
            "Total params: 20,162\n",
            "Trainable params: 8,406\n",
            "Non-trainable params: 11,756\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT22E6FsT0rO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aabf9256-827d-41d0-d315-b5736df627a4"
      },
      "source": [
        "reloaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "reloaded_model.fit(a_train, b_train, epochs=200, verbose=1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.9018\n",
            "Epoch 2/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9045\n",
            "Epoch 3/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.9064\n",
            "Epoch 4/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9082\n",
            "Epoch 5/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9200\n",
            "Epoch 6/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9200\n",
            "Epoch 7/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9218\n",
            "Epoch 8/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9127\n",
            "Epoch 9/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9118\n",
            "Epoch 10/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9200\n",
            "Epoch 11/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9355\n",
            "Epoch 12/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9291\n",
            "Epoch 13/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9255\n",
            "Epoch 14/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9164\n",
            "Epoch 15/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9273\n",
            "Epoch 16/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9245\n",
            "Epoch 17/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.9209\n",
            "Epoch 18/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9236\n",
            "Epoch 19/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9227\n",
            "Epoch 20/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9155\n",
            "Epoch 21/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9182\n",
            "Epoch 22/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9264\n",
            "Epoch 23/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9355\n",
            "Epoch 24/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9345\n",
            "Epoch 25/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9127\n",
            "Epoch 26/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9227\n",
            "Epoch 27/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9327\n",
            "Epoch 28/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9255\n",
            "Epoch 29/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9245\n",
            "Epoch 30/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9236\n",
            "Epoch 31/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9336\n",
            "Epoch 32/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9309\n",
            "Epoch 33/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9282\n",
            "Epoch 34/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9427\n",
            "Epoch 35/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9364\n",
            "Epoch 36/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9309\n",
            "Epoch 37/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9409\n",
            "Epoch 38/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9364\n",
            "Epoch 39/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9291\n",
            "Epoch 40/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9182\n",
            "Epoch 41/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9309\n",
            "Epoch 42/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9327\n",
            "Epoch 43/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9491\n",
            "Epoch 44/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9491\n",
            "Epoch 45/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9427\n",
            "Epoch 46/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9282\n",
            "Epoch 47/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9227\n",
            "Epoch 48/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9391\n",
            "Epoch 49/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9345\n",
            "Epoch 50/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9255\n",
            "Epoch 51/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.9436\n",
            "Epoch 52/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9345\n",
            "Epoch 53/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9418\n",
            "Epoch 54/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9327\n",
            "Epoch 55/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9245\n",
            "Epoch 56/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9445\n",
            "Epoch 57/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9291\n",
            "Epoch 58/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9455\n",
            "Epoch 59/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9391\n",
            "Epoch 60/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9355\n",
            "Epoch 61/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9327\n",
            "Epoch 62/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9373\n",
            "Epoch 63/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9500\n",
            "Epoch 64/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9327\n",
            "Epoch 65/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9473\n",
            "Epoch 66/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9391\n",
            "Epoch 67/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9355\n",
            "Epoch 68/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9355\n",
            "Epoch 69/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9355\n",
            "Epoch 70/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9464\n",
            "Epoch 71/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9373\n",
            "Epoch 72/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9409\n",
            "Epoch 73/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9373\n",
            "Epoch 74/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9482\n",
            "Epoch 75/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9473\n",
            "Epoch 76/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.9464\n",
            "Epoch 77/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9245\n",
            "Epoch 78/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9436\n",
            "Epoch 79/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9500\n",
            "Epoch 80/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9500\n",
            "Epoch 81/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9318\n",
            "Epoch 82/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9382\n",
            "Epoch 83/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9273\n",
            "Epoch 84/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9355\n",
            "Epoch 85/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9491\n",
            "Epoch 86/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9527\n",
            "Epoch 87/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9545\n",
            "Epoch 88/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9473\n",
            "Epoch 89/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9436\n",
            "Epoch 90/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9355\n",
            "Epoch 91/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9418\n",
            "Epoch 92/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9382\n",
            "Epoch 93/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9418\n",
            "Epoch 94/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9500\n",
            "Epoch 95/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9400\n",
            "Epoch 96/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9409\n",
            "Epoch 97/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9527\n",
            "Epoch 98/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9527\n",
            "Epoch 99/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9545\n",
            "Epoch 100/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9536\n",
            "Epoch 101/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9473\n",
            "Epoch 102/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9491\n",
            "Epoch 103/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9491\n",
            "Epoch 104/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9409\n",
            "Epoch 105/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9509\n",
            "Epoch 106/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9545\n",
            "Epoch 107/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9573\n",
            "Epoch 108/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9527\n",
            "Epoch 109/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9409\n",
            "Epoch 110/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9482\n",
            "Epoch 111/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9391\n",
            "Epoch 112/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9509\n",
            "Epoch 113/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9436\n",
            "Epoch 114/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9373\n",
            "Epoch 115/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9491\n",
            "Epoch 116/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9436\n",
            "Epoch 117/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9400\n",
            "Epoch 118/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9391\n",
            "Epoch 119/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9573\n",
            "Epoch 120/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9436\n",
            "Epoch 121/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9518\n",
            "Epoch 122/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9509\n",
            "Epoch 123/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9618\n",
            "Epoch 124/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9555\n",
            "Epoch 125/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9555\n",
            "Epoch 126/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.9518\n",
            "Epoch 127/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9545\n",
            "Epoch 128/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9527\n",
            "Epoch 129/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9455\n",
            "Epoch 130/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9518\n",
            "Epoch 131/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9445\n",
            "Epoch 132/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1768 - accuracy: 0.9455\n",
            "Epoch 133/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9536\n",
            "Epoch 134/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9545\n",
            "Epoch 135/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9436\n",
            "Epoch 136/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9436\n",
            "Epoch 137/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9527\n",
            "Epoch 138/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9473\n",
            "Epoch 139/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9464\n",
            "Epoch 140/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9409\n",
            "Epoch 141/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9427\n",
            "Epoch 142/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9436\n",
            "Epoch 143/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9527\n",
            "Epoch 144/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9445\n",
            "Epoch 145/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9555\n",
            "Epoch 146/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9491\n",
            "Epoch 147/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9509\n",
            "Epoch 148/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9473\n",
            "Epoch 149/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9564\n",
            "Epoch 150/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9555\n",
            "Epoch 151/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9491\n",
            "Epoch 152/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9445\n",
            "Epoch 153/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9564\n",
            "Epoch 154/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9400\n",
            "Epoch 155/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9518\n",
            "Epoch 156/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9500\n",
            "Epoch 157/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9491\n",
            "Epoch 158/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9509\n",
            "Epoch 159/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9527\n",
            "Epoch 160/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9600\n",
            "Epoch 161/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9500\n",
            "Epoch 162/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9536\n",
            "Epoch 163/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9573\n",
            "Epoch 164/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9391\n",
            "Epoch 165/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9491\n",
            "Epoch 166/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9600\n",
            "Epoch 167/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9545\n",
            "Epoch 168/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9545\n",
            "Epoch 169/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9527\n",
            "Epoch 170/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9436\n",
            "Epoch 171/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9545\n",
            "Epoch 172/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9582\n",
            "Epoch 173/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9645\n",
            "Epoch 174/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9591\n",
            "Epoch 175/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9618\n",
            "Epoch 176/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9555\n",
            "Epoch 177/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9473\n",
            "Epoch 178/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9527\n",
            "Epoch 179/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9464\n",
            "Epoch 180/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9636\n",
            "Epoch 181/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9564\n",
            "Epoch 182/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9609\n",
            "Epoch 183/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9573\n",
            "Epoch 184/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9509\n",
            "Epoch 185/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9536\n",
            "Epoch 186/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9473\n",
            "Epoch 187/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9427\n",
            "Epoch 188/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9427\n",
            "Epoch 189/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9518\n",
            "Epoch 190/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9464\n",
            "Epoch 191/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9618\n",
            "Epoch 192/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9518\n",
            "Epoch 193/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9500\n",
            "Epoch 194/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9582\n",
            "Epoch 195/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9527\n",
            "Epoch 196/200\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9609\n",
            "Epoch 197/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9591\n",
            "Epoch 198/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9527\n",
            "Epoch 199/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9445\n",
            "Epoch 200/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3f0d77f588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgswjGCl74E0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "86c129e4-08ae-448b-bc43-2ec870b78483"
      },
      "source": [
        "training_predicted = model.evaluate(a_test,b_test) \n",
        "print(\"testing_predicted: \", testing_predicted)\n",
        "print()\n",
        "print(\"training_predicted: \", training_predicted)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81/81 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.8481\n",
            "testing_predicted:  [1.1245524883270264, 0.7066848278045654]\n",
            "\n",
            "training_predicted:  [0.5519579648971558, 0.8481308221817017]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}